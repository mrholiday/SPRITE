0	paper presents simple unsupervised learning algorithm classifying reviews recommended classification review predicted average semantic orientation phrases contain adjectives adverbs phrase positive associations negative calculated mutual information given word excellent poor classified achieves accuracy evaluated sampled different domains ranges automobile movie introduction considering mexico search engine enter query travel case google reports matches useful know fraction recommend destination automatically thumbs possible report summary statistics motivation research described potential applications include recognizing developing new kinds tools present written input produces output first step speech tagger identify text
1	generated user general information first sentences background problem tackled second abstract aimed expert given instead differences approach similar ones described actual construction summaries complex process involving tasks sentence planning lexical choice syntactic realization scope article important point knowledge rhetorical status enables tailoring according users expertise task allows kinds applications articles summarized contrasts complementarity computational linguistics volume number paper goal organise set linguistic objects words contexts occur instance grammatical constructions grams specifically classify nouns distribution direct verbs unlike hindle constructs word classes corresponding models association directly comparison brown method demanding depend frequency counts joint events particular potentially unreliable source figure summary contrastive links expressed displayed citation help navigate related papers rest structured follows section describes theoretical empirical aspects document structure model include relatedness terms solving contribution
2	translation systems automatically extract transfer mappings bilingual corpora hampered difficulty achieving accurate alignment acquiring high quality algorithm strategy small grammar significantly improve extracted mapping frequencies computed sufficient context retained distinguish competing variants run corpus containing sentence pairs evaluated based resulting translations introduction machine requires substantial knowledge typically embodied dictionaries rules bases statistical model decade research focused automatic acquisition build models data linguistic analysis class including parses sentences parallel aligned obtain predicateargument dependency structure source target lexical structural correspondences represented set base method fully automated number issues remain addressed procedure acquire precision robust errors introduced parsing level intrinsic produce provide enable utilizing choose appropriate given paper
3	paper explore variation sentences function sentence number demonstrate entropy increases decreases paragraph boundaries accordance rate principle holds different genres languages role genre informativeness investigate potential causes looking tree depth branching factor size constituents occurrence gapping work provide additional evidence hypothesis statistics introduction related natural language processing applications parsing modeling treated self contained units wellknown interpreting discourse context important later contain references entities preceding fact useful indirect influence observed stand unit possible distinguish set earlier direct comparison computing certain local individual measure information communication theory humans evolved communicate efficient way constant equal channel capacity previous propose human communications read
4	paper technique improving performance information extraction speech data explicitly modeling errors recognizer output approach combines statistical model named entity states lattice representation hypothesized words annotated recognition confidence scores additional refinements include multiple error types improved estimation processing combination techniques improve textbased baseline mo ee washington edu idea explicit handling spoken documents introduced grishman channel word insertions deletions deterministic pattern matching resulted substantial improvements overall low original designed advantage orthographic features looking ahead suggests probabilistic successful work described provides introduces acoustically driven score based proposed specifically provide unified predicting using uncertainty language focusing specific task identifying entities asr benefits prediction new derived multi pass rest organized follows section including resulting improvement given
5	paper multi stream paradigm proposed improve performance automatic speech recognition systems presence highly car noise combining classical auditory based acoustic distinctive cues main frequencies signal using leads improvement noisy environments introduction general existing designs predicated relatively free conditions degrades rapidly high level adverse recognizer provide background exact testing condition training material reference patterns vocabulary obtained practically case order cope different approaches studied achieving robustness summarized fundamentally first approach attempts corrupted input prior pattern matching attempt enhance snr second modify account effects details previous work introduced asr merge sources information lost recognize uttered experiments showed features proves loose relevant process despite popularity
6	natural language processing research results software engineering technology neglected paper describes factors add complexity task reusable nlp systems current work area design patterns composition languages described claimed relevant benefits barriers reuse outlined versus experiment toolkit framework discussed argued order live neglect component quality architectural evaluation reporting new figure dimensions introduction notoriously construct conventional systematically timely industrial development projects failing applications author aware studies estimate project failure rate higher engineer faces additional accuracy fundamental difference incompleteness property techniques guarantee provide correct affected account providing appropriate efficiency human users demanding reports response times render unacceptable debated scenarios interaction machines superior menus keyboard commands means unclear efficiently priority questions related considered mere implementation contrast areas
7	paper presents recent improvements development university colorado cu communicator spoken dialog systems first integrates speech recognition synthesis natural language understanding technologies using darpa hub architecture users able converse automated travel agent phone retrieve information flight schedules hotel rental car availability represents test bed developing robust human interactions reusability dialogue portability serve main goals work vehicle route planning guidance joint collaboration sponsored program specifically provide overview task data collection environment initial constructed composed servers shown fig centralized message communicate frames containing keys values emitted server routed received secondary based rules defined script generator base backend www confidence audio recognizer synthesizer semantic parser manager figure block diagram functional components comprise
8	present simple approach asian language text classification word segmentation based statistical gram modeling particular examine chinese japanese character models avoids unlike traditional ad hoc strong information theoretic basis explicit feature selection procedure potentially loses significantly useful systematically study key factors influence experiments trec ntcir topic detection achieve better performance compared approaches avoiding demonstrates superiority yang languages important area research introduces number additional difficulties difficulty english texts whitespace words means form normally required processing problem second lack standard benchmark data sets significant notable progress machine learning techniques applied categorization problems naive bayes classifiers support vector machines linear squares neural networks neighbor unfortunately current work level features identification hard avoid proposed
9	previous research demonstrated utility clustering inducing semantic verb classes corpus data new approach involves subcategorization frame distributions using information bottleneck nearest neighbour methods contrast work particularly focus polysemic verbs novel evaluation scheme proposed accounts effect polysemy clusters offering insight potential limitations semantically classifying scf introduction classifications aim capture relation syntax semantics attracted considerable linguistics computational provide means inferencing generalizations range linguistic properties reducing redundancy lexicon filling gaps lexical knowledge partly supported uk epsrc project gr robust accurate statistical parsing fact support natural language processing tasks generation machine translation document classification word sense disambiguation acquisition attractive property make possible certain extent infer basis syntactic behaviour recent years attempts automatically induce paper particular task motivated manner useful inferring levin style english german propose
10	present applications share linguistic processor first application files fully integrated environment syntactic functional annotation corpora currently italian treebank second shallow parser endowed feedback module order inform students grammatical mistakes german finally multilingual simulating parsing strategies ambiguous sentences sequence intelligent browser allowing operate changes create xml output automatically file snapshot relational databases previously analysed material inputted contains tokens lemmata pos tagging categories containing token regarded heads separated features verb list annotate number national project work progress input modules automatic analysis tokenizer morphological analyser tagger equipped statistic disambiguator separate contribute human annotators level constituent structure function head representation don space processors tag disambiguation carried semi manner annotator basis
11	combining naive bayes classifier em algorithm promising approaches making unlabeled data disambiguation tasks using local context features including word sense spelling correction basic causes performance degradation instead improving classification resulting poor average study introduce class distribution constraint iteration process keeps consistent estimated labeled preventing converging undesirable state experimental results confusion sets large proposed method considerably improves small introduction natural language processing addressed problems theart machine learning techniques support vector machines adaboost maximum entropy models provide high classifiers abundant correctly annotating set generally requires huge human labor time annotation cost major obstacles applying real world nlp applications algorithms called minimally supervised unsupervised make received attention collecting easier potential solving problem include combined training transductive applied text
12	corresponds point dimensional sensor group conditional probability form denotes occurrence event let denote defined semantics clearly depend nature events particular importance learning meanings words problem referential uncertainty utterances learner statements aspects environment perceptually available given word referent algorithm described paper solves restricted version denotation set pre groups multiple objects ambiguity possible recover field represents denotational meaning passive observation contexts unfortunately feature natural languages contend daily basis appears extreme young children acquiring first language determine newly identified infinitely consider happens add second object domain change color exactly time necessarily way knowing
13	present overview comprehensive formal theory interpretation sentential fragments components empirically validated taxonomy analysis syntax compositional semantics formalisation contextual briefly implementation quantify potential practical handling dialogue systems introduction settings people frequently produce utterances despite non convey propositions questions requests instance utterance np john conveys context proposition party clearly traditionally called highly dependent paper details kind main thesis approach resolution intended content modelled product establishment coherence define meaningful connection current discourse constraints form follow connections renewed offers computationally expensive plan recognition techniques employed fails
14	patent corpus processing centered claim claims important specifications common written japanese described sentence peculiar style wording understand ordinary people caused structural complexity sentences terms description proposed framework represent structure method automatically analyze currently investigating clarify explanatory portions detailed approaches believe improve readability japan science technology corp national institute informatics nii ac jp precision intelligence laboratory tokyo pi specification specify boundaries legal created read surveying related literature ntcir collection difficulty aspects term paper first present characteristics work analysis third introduce going research explanation typical patents shown figure general
15	propose new phrase based translation model decoding algorithm enables evaluate compare previously proposed models framework carry large number experiments understand better explain outperform word empirical results hold examined language pairs suggest highest levels performance obtained relatively simple means heuristic learning translations alignments lexical weighting surprisingly phrases longer words high accuracy wordlevel alignment strong impact syntactically motivated degrades systems method extract order investigate question created uniform evaluation comparison different ways build table achieved fairly fact steps necessary tools resources freely available researchers field sophisticated approaches make syntax lead imposing syntactic restrictions yamada knight proves harmful small sufficient obtaining differs widely depending methods extraction heuristics principled constitutes best pair varies size training corpus
16	paper present method automatically constructs named entity tagged corpus web learning recognition systems ne list search engine collect documents contain instances refined sentence separation text refinement procedures finally appropriate categories experiments demonstrates suggested acquire equally useful manually human intervention problem dilemma costs required annotate large training non trivial suggest ner annotated lower quality ones size infinitely increased efforts verify usefulness constructed apply compare results automatic acquisition focus major relatively easier recognize actually suffer shortage various linguistic information held common written form quantity increasing unlimited extent regarded
17	collaboration colleagues uw ibm sri developing technology process spoken language informal meetings work includes substantial data collection transcription effort required nontrivial degree infrastructure development undertaking new task area provides significant challenge current hlt capabilities offering promise wide range potential applications paper vision challenges represents state particular attention automatic primarily interested processing audio recorded natural mean conversations friends strict protocol exchanges place regardless recording acoustic circumstances typical conversation preparation require special instrumentation facilitate later speech plausible image situations handheld device conversational partners agree discussion reference given interests transcribing series icsi room standard meeting rooms talking distant microphones recordings support research modeling dialog immediately solve difficulties field microphone recognition included study deep problems provide closer match operating conditions ultimately envisaged signals
18	noun extraction important nlp applications information retrieval automatic text classification previous korean systems morphological analyzer partof speech tagger require linguistic knowledge morpheme dictionaries rules paper proposes new method syllable based word recognition model finds probable tag sequence input sentence using automatically acquired statistical pos tagged corpus extracts nouns detecting boundaries furthermore labor constructing maintaining performed various experiments wide range variables influencing performance experimental results analysis tagging proposed achieves comparable methods introduction process document terms express categorization summarization highly agglutinative language included eojeol surface level form consisting combined required extract classified categories tries generate possible interpretations given implementing simpler lexical overgenerate inaccurate ambiguity shows low precision rate studies reduce
19	major research project applying variety technologies knowledge management dynamic ubiquitous resource equally expert head data explicitly stated manuals extend exploit potential semantic web covering entire acquisition maintenance deletion paper discuss hlt affect different areas km retrieval publishing introduction reduces competitive advantage existing companies role proprietary information appropriate important company value depends exist minds employees databases files multitude documents goal make systems provide access present organisation possible share store retrieve collective expertise people organization spend term coined considerable resources estimates range developing first captured acquired form usable bottleneck known ai business environment requires sea change culture order persuade users accommodate technology adopted precisely
20	paper describes preliminary attempt automatically recognize pronouns japanese discourse based corpus study define classify argument nouns appear propose atn recognition algorithm consists lexicon heuristics drawn observations analysis finally present result evaluation discuss future directions sion reference contributes semantic continuity content connectivity coherence represents natural reasonable connections utterances make understanding lower inferential load hearers language ellipsis major type referential expression certain elements recoverable given context relevant knowledge ellipses include nominals missing termed pronominals arguments simply zeros researchers contained largely depends defined literature valency requirements predicate occur cover explain created nominal introduce contrast recognized investigate possible approaches recognizing newly incorporate automatic detecting tool teachers aims promote effective instruction section provide definition results manual identification
21	paper presents maximum entropy based named entity recognizer differs previous machine learning ners information document classify word classifier work involves gathering secondary corrects mistakes primary framework able make global directly achieves performance comparable best muc test data introduction considerable recent years recognition task partly message understanding conferences useful nlp applications extraction question answering ner provide users looking person organization names quick defined finding following classes location time money percent systems achieved accuracy rule statistical sequence tags maximizes probability words sentence assigned attempts consist incorporating additional tries correct errors output first propose maximizing namedentity extracted
22	present carmeltc novel hybrid text classification approach analyzing essay answers qualitative physics questions builds work presented learns classify units based features extracted syntactic analysis naive bayes explore tradeoffs symbolic bag words approaches goal combine strengths avoiding weaknesses evaluation demonstrates outperforms lsa purely require domain specific knowledge engineering annotation providing training corpus texts matched appropriate classifications necessary rainbow lesser extent developed atlas conceptual tutoring purpose grading essays written response suppose running straight line constant speed throw pumpkin land explain task pursuing benefits tutorial dialogue learning known elicit robust persistent misconceptions students objects force student first types answering problem tutor engages natural language provide feedback correct complete explanations version deployed evaluated undergraduate spring continuing
23	term extraction systems integral compiling specialized dictionaries updating banks paper present detection approach discovers structures infers conceptual relationships terms french deduced specific types variations morphological syntagmatic expressed lexical functions linguistic precision structuring introduction tools exist extracting terminology review current identifying generally based external evidence define catalogue ers detect relationship similarity inclusion detected prototype expression similar relies internal structure complex help databases general handled limited synonymy hyperonymy identify families word forms applied medical thesaurus make units contribution overall knowledge organization field medicine identified reference proved reliability information retrieval considers different terminological variants including syntactic perform accurate text indexing
24	information extraction systems costly build require development texts parsing tools specialized dictionaries application domain natural language needs processed present novel method rapidly creating new languages exploiting existing crosslanguage projection given source transfer annotations corresponding target learn rules automatically paper explore ways realizing learning processes using theshelf machine translation induced word alignment attribute transformationbased variety experiments english plane crash leveraged create french goal identify extract facts text designed specific types extracted defined advance focus try descriptions vehicle involved victims location form patterns recognize relevant techniques developed generate including autoslog meta bootstrapping work ts derivative generates gathering statistics corpus
25	report results experiments aimed improving translation quality incorporating cognate information models confirm identification approach improve word alignment bitexts need extra resources introduction context machine term cognates denotes words different languages similar orthographic phonetic form possible translations similarity genetic relationship borrowing language broad sense include genetically related borrowings names numbers punctuation practically contain kind represented scripts transcription transliteration parts bitext pre requisite identifying employed number tasks including sentence inducing lexicons statistical particularly useful readable bilingual dictionaries available experimented using training czech english probable significantly perplexity score test observed improvement alignments sentences paper investigate problem potentially valuable brown original formulation consider lexical items abstraction giza program list likely pairs extracted corpus basis appended
26	paper proposes empirically motivates integration supervised learning unsupervised deal human biases summarization particular explore probabilistic decision tree clustering framework account variation regularity created summaries corpus extracts newspaper test set build trees different flavors integrate experiments demonstrate mixture paradigms generally gives significant boost performance compared cases considered introduction nomoto matsumoto interesting observation method based better approximates approach appears somewhat contradictory given able exploit supplied information sentence include extract chooses sentences according selection scheme question case reason judgments summary study described later asked students select text important making agree perfectly selected half marked indicating vary widely humans fares tested data exhibiting high agreement
27	paper describes method multimodal language processing reflects experiences shared people robots incremental online optimization process interaction user robot form mutual beliefs represented stochastic model based interpret ambiguous utterances act generate appropriate given situation introduction human communication certain communicating belief convey meaning relevance formed environment embedded want logically convince proposition prove infinitely nested information holds reality assume clues identical talking guaranteed processes utterance generation understanding rely assumed person changes autonomously recursively listener interprets receives updating addition speaker receive similar response simultaneously send
28	present simple architecture parsing transcribed speech edited word detector first removes words sentence string standard statistical parser trained parses remaining edit achieves rate evaluate results introduce new evaluation metric purpose make parse tree relatively exact position nodes precision recall introduction significant effort expended written text received attention comparative neglect understandable presents problems absent regular um ah frequent parentheticals ungrammatical constructions repairs paper pass handling tries identify removed given second existing research supported nsf grant lis sbr itr corpus based fundamental assumption semantic pragmatic content utterance solely unedited sequence completely core schubert point counterexamples engine oranges mean antecedent believe
29	paper investigates adapting lexicalized probabilistic context free grammar novel domain using maximum posteriori estimation map framework general include previous model adaptation approaches corpus mixing gildea falling effective contrast results measure parsing accuracy gains high treebanks largest indomain data small based supervised unsupervised treebank available techniques provide substantial gain grammars nearly improvement pereira schabes exploit partially labeled advantage direct induction simply added training derived benefit parser concluding large statistical sparse new problem unique studied extensively researchers working acoustic modeling automatic speech recognition methods received attention asr literature parameters considered random variables known distribution prior likelihood observations posterior mode selected
30	paper overall model mile lexical entries provide instantiation rdf owl work eye goal creating web based data categories enabling description information establishing relations using predefined objects reside various locations assumed specifications enhance ontology eventually enable exploitation inferencing engines retrieve possibly create fly suited particular contexts provided line goals iso tc sc fully proposed pivot isle computational lexicons working group designed general schema encoding multilingual intended meta entry serve standardized representational layer resources consists incremental definition object oriented layers distributed elements residing different sites defined lexicon application developers build target high level abstraction resource framework language developed world wide consortium xml infrastructure creation semantic classified according properties semantics precisely turn powerful capabilities adapt processing applications
31	detailed approach developed core aspects task understanding broad class metaphorical utterances question depend known mappings contain elements mapped reasoning implemented partially instantiates theoretical called att meta demonstrated paper briefly indicates works outlines specific overall project introduction sentence reaches mind anne believed analyzed depending views physical space ideas objects plausibly familiar typical users english reasonable assume mapping mental domain notion metaphor predicated possible avoid constructing source target utterance underlying instead advocate literally slightly adapted real discourse performs interface directly natural language hand constructed logical forms meaning sentences passed physically located following sections summarize various abilities principles ongoing work aimed extensions major item current implementational
32	algorithm presented learning phrase structure grammar tagged text clusters sequences tags based local distributional information selects satisfy novel mutual criterion shown related entropy random variable associated tree structures demonstrated linguistically plausible constituents incorporated minimum description length evaluation unsupervised models discussed results trained million words british national corpus presents performance authentic natural language data appears limited work seen attempt implement harris analysis first rest paper arranged follows section introduces technique clustering preliminary experiment discusses filtering spurious candidate non terminals shows certain establishes fact desired effect outlined discuss difficulty evaluating sort present concludes discussion avenues future research introduction using context distribution induction stochastic free grammars previous completely produced poor
33	paper presents method measures similarity compound nouns different languages locate translation equivalents corpora information unrelated parallel means compares contexts target candidates word semantic attribute level measuring applied select best english candidate japanese cases occurrence obtained context appear specific domain similar financial newspaper price competition products stores companies nations public facilities extraction translations non introduction electronic documents various distributed internet cd rom media cross lingual natural language processing machine retrieval important read write foreign need knowledge provided ordinary dictionary terminology words relevant current affairs expressions multiple infinite possible variations add approaches tried acquire automatically effective features obvious correlations position frequency
34	paper proposes practical approach employing gram models error correction rules thai key prediction english language identification rule reduction algorithm applying mutual information reduce reported accuracy overview traditional keyboard input button help switching shift output different characters represent modes shown table mode introduction users typing bilingual documents usual first want switch special tell operating change ignored delete token typed type second alphabets half user combinations keys asian problem intelligent able perform tasks shifting automatically solution trigram character probabilistic model optimize number generated propose
35	introduction popular wsd contextual information training data occurring words limited window sized context support sense semantically ambiguous ones word problem effective patterns order capture right similar occurrence nearby features paper represent vector space first tagged represented vectors given wt consist sentences agirre defines term conceptual density based nodes hit wordnet node target contexts unlike local semantic net surrounding english senseval lexical sample task sampled bnc penn treebank items specific class noun verb adjective composed samples certain contain reports
36	paper attempts bridge gap framenet frames inference computational formalism captures structural relationships participants dynamic scenario representation internal structure terms parameters event simulations apply commerce domain provides flexible means accounting linguistic perspective inferential effects roles frame elements corresponding fes annotate sentences yielding buyer bought car goods jerry seller payment sold fe tags act shorthand allows diverse verbs tap common subset encyclopedic knowledge regularities set realized specific lexical items correlated favored significant remains unstructured intuitively chosen tag sets formal characterization interrelated actions relations holding explicit semantic information needed fully realize potential text understanding attempt defining structured representations allow annotated data parameterize produce fine grained context sensitive inferences illustrate account consequences introduction online resource designed according principles semantics foundational assumptions draw rich conceptual structures
37	evaluate probabilistic models verb argument structure trained corpus verbs syntactic arguments designed represent patterns alternation behavior compared generic clustering terms perplexity assigned held test data specialized perform closer examination reveals represented implicitly introduction recent research attempted acquire directly large corpora mccarthy merlo stevenson evaluated systems accuracy human judgments classification comprehensive classes levin serving gold standard area focused automatic algorithms goal finding groups semantically related words focusing specifically aim bring strands unified model incorporating mapping functions subject object semantic roles agent patient important piece language understanding problem learning automatically unannotated text significantly reduce labor needed create form writing lexical entries annotating information train statistical generative allows modeling applications independent interpretation based head modifier dependencies trees shown lower gram word error rates speech recognition
38	propose formal characterization variation syntactic realization semantic arguments using hierarchies relations thematic roles mechanism lexical inheritance obtain valency frames individual linking types embed formalization new lexicalized dependency based grammar formalism topological account alternatively realized np pp model role alternations treat auxiliary constructions indirect cal adding representational level framework section introducing concept frame tdg lexicon data linguistically concise way define conditions derivation contrasts analysis dative shift construction linguistic insights corpus studies material annotated framenet project basis bank english patterns specific verbs occur vary observe different alternative illustrate known phenomenon occurs restricted class distinction explained terms semantics semantically closely related deliver differ behaviour contrast shows postman gave package charged delivered
39	typically lexicon models statistical machine translation systems include kind linguistic contextual information leads problems performing correct word sense disambiguation way deal problem framework maximum entropy methods paper present type possible significantly decrease training test corpus perplexity addition perform rescoring best lists using model yield improvement quality experimental results presented called verbmobil task additional approach applied natural language processing variety tasks applies ibm candide build context dependent compute automatic sentence splitting improve reordering similar techniques socalled direct instead proposed describes incorporating relative position bilingual pairs authors modeling review outlined section introduction single based source corresponds target lack extracted parallel goal process
40	finite state parser tailored lexicon syntax semantics particular application using hand declarative defined terms lexicalized tree adjoining grammar subsequently mapped fs representation approach gives designer better easier control natural language understanding component shelf present results creates images typed input main presents linguistic constructions original domain case consistently certain lexemes occur corpus different syntactic properties parsers retrained annotated available process retraining complex practice disadvantage typically written procedural code addition nlu exploit strengths required generally simpler discussion suggests need way specify power recursive paper suggest semantic nlp served furthermore sufficient wsj text
41	opinion question answering challenging task natural language processing paper discuss necessary component separating opinions fact document sentence level present bayesian classifier discriminating documents editorials regular news stories unsupervised statistical techniques significantly harder detecting first model classifying sentences positive negative terms main perspective expressed results large collection human evaluation reported indicating achieve high performance classification respectable neutral hatzivassiloglou department science columbia university new york ny usa cs edu favor particular policy decision motivation building detection described need organizing information context complex questions unlike man moon answered simple phrase intricate reasons iraq war require answers constructed multiple sources imperative discriminate facts appropriate type depending combine meaningful presentation help highlight contrasts contradictions different significant disparity material collected
42	paper efficient search algorithm statistical machine translation contrary greedy approaches possible guarantee avoidance errors develop various sophisticated admissible heuristic functions especially newly developped method perform multi pass iteratively improved function allows translate sentences compare beam approach hansards task try model word correspondences source target words called alignment restricted way assigned exactly mapping aj position contain alignments account aligned models introduced hidden variable typically performed using socalled maximum approximation ei arg max introduction goal text given language string fj translated strings choose highest probability ji jj
43	languages ieee transactions computers brill eric automatic grammar induction parsing free text transformation based approach proceedings st annual meeting association computational linguistics charniak eugene statistical context word statistics national conference artificial intelligence press mit park ca maximum entropy inspired parser naacl immediate head language models th chelba jelinek exploiting syntactic structure modeling coling acl chiang david automatically extracted tree adjoining hong kong pages collins michael james prepositional phrase attachment backed model third volume number workshop large corpora new bigram lexical dependencies generative lexicalised european chapter driven natural ph thesis university pennsylvania philadelphia jan ramshaw czech college maryland discriminative reranking international machine learning parameter estimation theory practice
44	paper tests speech recognition using prosody dependent models log various prosodically labeled phonemes calculated baum estimation compared non based comparison concluded modeling prosodic information directly vowel model leads improvement consonants hand split naturally categories neutral introduction important factor humans interpret word string different meanings depending way said linguists performed extensive studies effects factors spoken language dissertation cho investigates phonetic features conditioned examining pre boundary post accented syllables reports induced articulatory occurs phrase final positions initial consonant vowels susceptible coarticulation characterized primarily expansion affected neighboring caused boundaries accents considered discusses differences accent study effect lengthening examined studying movement patterns decreasing sh ch aa ah ay el ey oy uw ae ao ax eh er ih uh
45	rags proposals generic specification nlg systems includes detailed account data representation outline view processing aspects paper introduce modular architecture concrete implementation aims meet goals transparency reusability illustrate model generation built simple modules introduction project mellish introduces framework offers formally defined declarative language supports complex dynamic requirements different levels mixed representations cut partial shared structures canned acknowledge financial support epsrc intellectual contribution partners edinburgh colleagues especially worked previously grateful anonymous referees helpful comments described says functional structure issues arising discussion end applied functionalities common reiter proposed analysis terms stage pipeline cahill attempted repeat implement occurred ways orders
46	paper describes ongoing research project text simplification deaf people aiming task offering reader syntactic lexical paraphrase given assisting understand means discuss issues address realize report present results different aspects readability assessment representation post transfer error detection reported subsequent sections approach process reading assistance decomposed following subprocesses problem identification identify portions user read generation generate possible candidate paraphrases identified evaluation assess resultant texts choose problems resolved decomposition clear key assessing comprehensibility involved tough issue argue targets particular population segment adequate collection data available corpus based empirical approaches feasible proven collect conducting survey questionnaires targeting teachers schools terms interchangeably strictly distinguishing fragment
47	present hybrid text mining method finding abbreviations definitions free format texts deal problem employs pattern based abbreviation rules addition markers cue words formed generated automatically manually augmented processes new documents proposed advantages high accuracy flexibility wide coverage fast recognition kinds processed hard coded heuristics algorithms ways anticipated devised propose approach problems knowledge linguistic rule consists definition formation describes exist multiple given pair patterns described section special symbols frequently imply relationship include characters particular occurring local contexts strongly acronym stand discussed components recognizer finder matcher best match selector shown figure seeks candidate generates determines
48	support engaging human users robust mixed initiative speech dialogue interactions reach current capabilities systems darpa communicator program funding development distributed message passing infrastructure participants using presentation features requirements genuinely useful software purpose building galaxy elaboration extension mit interaction fact required imposes somewhat severe set usual range straightforward considerations functionality flexibility flexible encompass strategies various sites experiment install learnability learn embed programs maintenance supported maintained leverage longer term research goals keywords spoken interfaces introduction years technological advances push enabled availability real time recognition tools explosion internet accessible information sources proliferation mobile access devices cell phones fielded standards arising efforts represent limited
49	xx xu bu ww reference person entities ub wb hb uw fx wm ms mb
50	address issue line detection communication problems spoken dialogue systems usefulness investigated sequence question types word graphs corresponding respective user utterances applying memory based learning techniques data obtained dutch train time table information current paper demonstrates aforementioned features lead method problem performs significantly baseline results interesting perspective employ present majority computational overhead machine rule better capable representing interactions automatic speech recognition incorrect interpretations natural language understanding module wrong default assumptions manager likely confusion ability detect high accuracy able correct certain errors interact solve instance case beneficial change relatively strategy constrained order resolve similarly shown users switch marked speaking style important source solved using recognizers parallel trained normal decide focus
51	illustrates heuristic approach extraction information retrieval question answering generic argumentative text stored user focused access core emphasis placed dimension address particular types questions points based comments areas application include summarization critical thinking assistance speed reading elements context cognitive modeling doing contents paying attention argumentation contributes ways giving contexts answers helping qualify credibility opinions stances levels topic justifications stance level concern classical ir answer point semantically pragmatically stress heavily course summaries alike relations concepts keywords right kind height description price broad sense includes gives medium terms demonstration introduction prototype detect display high game queries requests classified bearing descriptive knowledge narratives updates know evaluation advice
52	present extracting english translation given japanese technical term collecting scoring candidates web first partially bilingual documents useful discovered using commercial dictionary internet search engine algorithm obtaining based distance terms report results preliminary experiment sentence medical document says manageable early major cause visual impairment developed nations texts typically original indicated usage don know easily guess machine cross language information retrieval lexicon construction correspondence context translated word words conversion informants guiding selection appropriate paper investigate possibility sourced continually updated wide coverage
53	language generation content planner embodies plans hand crafted manual analysis target text paper present developed automatically learn elements plan ordering constraints training data semantically annotated transcripts domain experts performing task designed mimic given large degree variation spoken novel algorithm parallels based techniques computational genomics proposed methodology evaluated fold learning generalization capabilities quantitatively using cross validation obtaining level accuracy qualitative evaluation provided introduction typically represent included output researchers rely generic planners rhetorical structure theory schemas cases application rules determine order method basic patterns contained tagged oral briefing patient status undergoing bypass variability individual human supervised sets
54	report work automatically build corpus instructional text annotated lexical semantics information coupled parser lexicon ontology derived resources verbnet verbs nouns discuss built parsing results obtained remove bag effect actions inferred specified location object map action scheme apparently equivalent transformations describes meaning defines classes according ability inability verb occur pairs syntactic frames preserve variant possible manner means result chose base levin accounts distinct classified main given strong components easily generate semantically course building representation sentence need nl applications wordnet richer appropriate needs based different theory provide compatible contribution demonstrate
55	paper obtain baseline performance question answering using simple features contrast approaches maximum entropy based qa view problem classification reranking results indicate viewed reranker clearly outperforms classifier systems trained data phrase evaluation judged basis final output answer corresponding evidence provided segment focuses pinpointing module typical perform ranking candidate answers important step goal rank likely first symbolic statistical methods make treating cast framework compare modeling introduction domain factoid defined task fact questions phrased natural language fall category capital japan tokyo non aspirin pain paris input set possible candidates outputs architecture consists basic modules information retrieval
56	paper describes prototype multimodal railway information built extending existing speech purpose extensions alleviate number shortcomings interfaces added multimodality version explain think help solve systems conclude discussing issues intend means user tests introduction time modality input output telephone based considered natural form people primary communication simple suffices additional devices required obviously situations hands eyes definitely preferable modalities pen mouse shown result effective efficient dialogues aim research described assess extent improve effectiveness efficiency satisfaction comparison unimodal framework project developed way supports screen point click actions typical application implemented using paradigm stand model various filling applications first
57	necessary annotated corpus build statistical parser acquisition costly time consuming paper presents method reduce demand using active learning selects samples annotate instead annotating training sample selection annotation based representativeness usefulness model distance proposed measure difference sentences likely parse trees process analyzes distribution clustering calculates density quantify sentence deemed useful existing highly uncertain parses uncertainty measured various entropy scores experiments carried shallow semantic air travel dialog result shows parsing accuracy need third compared usual random introduction prerequisite building parsers availability parsed acquiring expensive timeconsuming bottleneck new application domain goal study required achieve satisfactory performance studied context natural language processing applications information extraction text classification basic idea couple tightly knowledge opposed treating separately setup assume small
58	paper describes results corpus experimental investigation factors affect way clarification questions dialogue interpreted responded present using bnc general correlations request type likelihood answering answer distance question new technique integrating manipulations text based synchronous specific concerning effect word category level grounding interpretation response introduction requesting vital communicative process received attention formal semantic conversation analytic traditions computational community theory perfect able interpret deal requests user order elicit utterance task crs different forms intended readings query aspects original result design traditionally attempted avoid necessity cr making utterances clear precise possible generate simple robust shallow methods relying highly domain dependent lexicons grammars systems human likely cope stage ability useful repair misunderstanding disambiguate
59	report results combining graphical modeling techniques information extraction resources frame semantic role assignment approach demonstrates human built knowledge bases task background introduction portability domain independence critical challenges natural language processing systems ongoing development public wordnet framenet cyc potential support independent solutions nlp appropriate application remains significant paper reports necessary component scalable pertains bindings units text se problem similar cases interested certain predicates argument understanding major differences pre specified autonomous narrow focus represented template involves finding predicate structures domains crucial parsing step obtained automatic strong research years work gildea jurafsky present comprehensive empirical looked assigning roles based statistical model data assume
60	present generative distributional model unsupervised induction natural language syntax explicitly models constituent yields contexts parameter search em produces higher quality analyses previously exhibited systems giving best published parsing results atis corpus experiments penn treebank sentences comparable length nontrivial brackets compare distributionally induced actual speech tags input data examine extensions basic discuss errors previous upper bounds lower stability task tions trees new gives reduction error wsj sentence including positive qualitative shift types additionally stable require heavy smoothing exhibits reliable correspondence maximized objective accuracy faster requiring fitting phase iteration klein manning clark sequences followed section performance somewhat reduced better introduction inducing hierarchical syntactic structure observed received great deal attention researchers explored problem variety reasons argue empirically poverty stimulus first stage constructing large treebanks build work presented conditional gave suffered
61	present language independent unsupervised algorithm segmentation words morphs based new generative probabilistic model makes relevant prior information length frequency distributions shown outperform competing algorithms evaluated data agglutinative morphology perform english introduction order artificially understand produce natural presumably know elementary building blocks lexicon additionally needs relations lexical units existing nlp applications make instance statistical modelling probabilities word sequences typically estimated bag models common retrieval languages infeasible construct lexicons contain entire especially finnish turkish formed concatenation morphemes number possible different forms simply high single verb appear thousands according linguistic theory built smaller smallest meaning bearing elements instead construction comprehensive morphological analyzer requires considerable work experts time consuming expensive hardly applicable furthermore evolves updated continuously remain alternatively interesting field research lies minimally supervised
62	purpose study construct semantic analysis method disambiguating japanese compound verbs speakers produce rich variety making process employing disambiguation rules based features first verb syntactic patterns consisting occurrence nouns evaluated applying dictionary obtained accuracy result shows advantage extract constraints machine translation consist second appears form paper discuss composition native ageru push eat frequently expressing complex motion elaborated phenomena emotional state high productivity great number ambiguities constituent correlation constraint given throw kick lift finish multiple meanings position directional formed compounding conversely aspectual combining cooking small
63	representations built summarizer allow summary generation multiple languages summarization spoken news context text retrieval conference document conferences recent defense advanced research project agency broadcast workshops number groups developing multimedia browsing tools audio video data facilitate access combining different modalities hirschberg present supports local navigation information extraction acoustic databases using speech recognizer transcripts tandem original recording interface helps users tasks relevance ranking fact finding helpful creating summaries partly imperfect recognition combines confidence scores obtain accurate reliable evaluation showed human judges preferred compression rate word error significantly smaller transcript salience features combination language model reduce japanese captions keeping meaning sentences test set related reduction approach presented summarize voice mail small message format computational linguistics volume prosody based emphasis detection approaches summarizing rely attempts generate emphasized regions discourse prosodic chen train hidden markov
64	com paper report work prototype route navigation dialogue vehicle delivers spoken turn directions developed accept naturally phrased queries overall effort create information requested placing minimal cognitive load driver development progressively implement solutions increasing complexity implementation complicated potential large street vocabulary unusual uncommon pronunciations significant variations speakers appropriate space dynamic depends location initial proper names addition assume separate destination entry planning systems routes loaded relies resolve stage journey global positioning determine progress implementing first concentrate aspects problem establish baseline compare implementations second phase include limited set language model lexicons initially using predefined hand tuning additional research required solve recognition generally automatically map matching position includes natural components scope
65	traditional nlp parsers widely successful applications particularly scoring written compositions engineering provide necessary robustness handling ungrammatical english proven formidable obstacle discuss parser rating difficulties dependency based shallow parsing approach provides significant face language learners paper discusses corpus essays rated using automatic compared obtained manual methods types modifications discussed limitations current described future plans developing sketched essay mentioned grading process factors suggest automating desirable practicality costly time consuming consistency somewhat subjective nature suffer feedback providing student important automated ways generating specific suggestions tailored needs author computerized second speakers poses unique responses low levels proficiency expect generally formed sentences native speaker majority lower illformed previous work related technologies surveyed different forums thorough survey field published typically approaches borrowed techniques tools natural processing fields knowledge engines
66	paper describes unsupervised algorithm placing unknown words taxonomy evaluates accuracy large varied sample works first using corpus semantic neighbors word accomplish combining latent analysis speech information place concentrated class labelling developed especially task method reconstruct parts existing wordnet database obtaining results common nouns proper verbs evaluate contribution tagging automatic filtering gives improvement firstly given particular taxonomic seek members problem addressed riloff roark charniak secondly suitable classes describing object work addresses second questions goal automatically new attempted various ways years process contains version following stages occurrences similar consider derived assuming map hearst sch tze added net
67	commercial tools languages spoken world correctly computerized spell checkers hyphenation machine translation lacking paper present directions help minority projects apply lao language introduction years research driven products developed provide efficient linguistic unicode reality operating systems microsoft office xp contains proofing people information era limited using hardware software meet needs terms script resources following terminology smaller resource base major available needed first notice trend design standardization allows recent multilingual evolution windows macintosh unix linux support fonts especially ms large look widespread business suite observe coverage tens word processor significant covers number speakers question
68	language independent flexible accurate method detection abbreviations text corpora based idea abbreviation viewed collocation identified using methods log likelihood ratio known recall precision poor employ scaling factors lead strong improvement experiments english german detected high accuracy introduction dependent word alternative hypothesis assumes occurrence period ha hypotheses given distribution asymptotic test statistic problems approach corpus forms initial steps tokenization trivial task tokenizer confronted ambiguous tokens palmer hearst report periods decimal points marks end sentence paper concentrate classification mark punctuation assume consisting abbreviated following case expect previous likely
69	view presented panels figure representing channels syntactic relations sequence igs produced morphological analysis transducer ig initially augmented pairs delimiter symbols pair separates features channel representation separate representations consecutive word final special marker represented matching inserted new stacked topmost closest way dependency links cross drawn time number sides multiple occupy mutually exclusive segments interfere accommodate possible certain segment indicated various surrounding delimiters symbol indicates link starts left ends right crossing start terminates end denoting relation
70	present automatically identifying propbank style semantic roles based output statistical parser combinatory categorial grammar performs traditional treebank outperforms core argument introduction correctly sentence constituents crucial interpreting text addition forming important information extraction problem serve intermediate step machine translation automatic summarization single predicate arguments multiple syntactic realizations shown following paraphrases john meet mary door opened gildea palmer developed predict sentences parse trees determined collins paper examine representations different parsers affect performance compare ccg trained tested corpus derivations obtained conversion penn able using goldstandard parses representation returns skeletal phrase structure traces functional tags original dependencies correspond underlying including arising control raising coordination relations attention turned creating corpora annotated structures framenet projects document variation
71	paper introduces new learning algorithms natural language processing based perceptron algorithm efficiently applied exponential sized representations parse trees subtrees representation described tracking sub fragments tagged sentence experimental results showing significant improvements tasks parsing wall street journal text namedentity extraction web data nigel ave building palo alto ca cs edu kernel trick discuss methods length inner product feature vectors calculated using dynamic programming leads polynomial time training applying kernels related discrete structures previous showed pcfg atis task method scales complex domains gives relative reduction error rate model second domain detecting boundaries state art maximum entropy tagger result derived sequences rely approach incorporates log probability baseline addition features introduction machine going simple implement shown competitive recent support vector machines application image classification
72	investigation questions leads surprising result parsing wsj corpus third model parameters eliminated impact performance aside cross considerations important lightweight parser desired memory usage consideration previous comparisons corpora introduction past years seen great progress natural language statistical methods trained using large hand parsed training data techniques charniak collins ratnaparkhi achieved roughly comparable results sets test case penn treebank annotated parses wall street journal articles relatively quantitative reported stolcke switchboard czech hwa bootstrapping atis inclusion brown allows compare paper examine following extent parsers task uniform style fare varied applied aspects probability particularly tuned general deal work community analyzing variations di erent genres text biber investigated variation number syntactic features registers particular importance
73	language data associated technologies resources community rapidly expands locate reuse existing lexical tool work transcripts particular format linguistic type questions dominate mailing lists web search engines unreliable way paper describes new digital infrastructure resource discovery based archives initiative called olac metadata set controlled vocabularies facilitate consistent description focussed searching report progress describing current issues input including linguists engineers teachers actual speakers individuals institutions provide key pieces software developers publishers unprecedented opportunities connect communities need first inexpensive mass storage technology permits large stored form extensible markup unicode flexible ways represent structured ensure term second publication world wide practical efficient means sharing finally standard model dublin core interchange method provided make possible construct union catalog multiple repositories nsf funded workshop documentation held philadelphia brought group nearly
74	term covers multitude issues interpretation generation creative metaphor paper concentrate notion lexical systematicity explore role coherence relative structure target concept described argue equal apt metaphors way literally metaphorically organized lexicon plays key enforcing recognizing insofar existing organization lexicalized perform exploration context wordnet relational structures automatically extracted taxonomy facilitate introduction considers measure finds range apparent complexity compounded fact operate different levels representation simultaneously conceptual level ideas words pragmatic intentions fall poor choice source communicating failure observe expectations expressed degree afforded compare semantic neighbors existence common taxonomic parent suggests similar domains instance architects
75	interactive multi document summarization integrates state art engine advanced user interface main goals provide control process support exploration set summary point combine text summaries alternative presentations map based visualization documents output believe directly involves generation adapts input produce better additionally shown users satisfied systems visualize decisions sense ways interactivity incorporated multidocument direct parameters size redundancy focus rapid browsing using starting combining individual incorporate formats organizing displaying news stories summarized placing world locations events described paper addresses directions built neats following section brief overview version introduction goal presentation substance body material coherent concise form ideally contain
76	paper describes novel approach inducing lexico structural transfer rules parsed bi texts using syntactic pattern matching statistical cooccurrence error driven filtering present initial evaluation results discuss future directions source parses instead induce general compiled dictionary actual translation process similar recent work derived aligning target nodes corresponding differs important points first difference concerns content resulting contain lexical labels roles containing information provided parsers second node alignment designed way preserves restriction reasons different language pairs study deals languages closely related syntactically dealing divergent korean english third identification candidates exact tree fragments parse delimited sub patterns subset features satisfy customizable set introduction available bilingual
77	question answering developed limsi participant years qa track trec conference paper present quantitative evaluation various modules based criteria first numbers documents containing correct answer selected secondly number answers criterion evaluating locally contribute selecting likely contain second provides global serves indirect introduction featuring addition existing involves searching list questions collection provided nist factual encyclopaedic newspaper articles instance proposed retrieved corpus million human judges systems results participants automated tool database data consist judgements sent automatically delivers score set given derived mean reciprocal rank mark reverse proportion useful gives way happens modifying
78	paper describes fast algorithm selects features conditional maximum entropy modeling berger presents incremental feature selection computes approximate gains candidate stage time consuming problems large spaces new instead compute ranked based models obtained previous stages experiments wsj data penn treebank conducted greatly speeds process maintaining quality selected variant look ahead functionality tested confirm implement given space size original introduction received attention language natural processing past years main advantages occur corpus predefined cutoff threshold chen rosenfeld experimented technique test included model computed using count prior distribution real training simple probably effective tasks optimized likelihood criterion important establish relationship score gain absent presented
79	ei descriptions du dc ug data gc cg gu response xc bp gsg gg fg ggg dcg gb uc cu qd pg fcg ihe pp
80	augment model translation based ordering nodes syntactic trees order allow alignments original tree structure keeping computational complexity polynomial sentence length adding new subtree operation string alignment algorithms algorithm estimating probabilistic parameters similar represents sequence operations children using automatic parser output initial structures explicit information target language led excellent results raises prospect training statistical sides parallel corpus techniques substitution grammars trained parse treebanks real bitexts generally exhibit isomorphism systematic differences languages express concept syntactically simply relatively free translations material paper introduce loosely address problem present analogous extensions models obeying constraints cost probability achieved introducing clone copies entire source moving careful parameterization allows estimated additional expect unconstrained various types structural divergence introduction systems divided transfer approaches
81	particular characteristics text classification tasks present large class problem easily tackled using resampling methods approaches simple implement tuning effectively task unclear effective rate paper presents method combining different expressions sampling approach mixture experts framework proposed combination scheme evaluated imbalanced subset reuters collection shown domain introduction typical machine learning context natural language processing unfortunately specific data make handle typically highly dimensional imbalance documents topic texts unrelated subjects abound furthermore amounts available line labeled known negatively affect classifiers unlabeled place conventional supervised shelf likely successful instead recommended devise specifically tuned purpose study target hope improving effectiveness process topics finding representation dealing high dimensionality investigated previously
82	dialogue analysis widely oncology training health professionals communication skills parameters tagsets developed independently work natural language processing relation emergent standards nlp syntactic tagging minimal semantics domain specific pragmatics comparable cognitive affect richly suggest productive directions convergence motivation groups highly specialised offers interesting contrast instructional service dialogues commonly studied professional expert conventional sense times conveys medical information knowledgeable patient way seen regard perceived physical mental condition task effectively knowledge elicitation understood systems development flexible dynamic shifting participants roles poses challenge compared clearly defined static assumed tool assessing improving rates psychiatric cancer patients adequate discover address concerns exhibit negative behaviours blocking certain line investigation encouraging problem hand skilled active direct progress interview passive responses research demonstrated patterns detected quantified conversations
83	study aims improve performance identifying grammatical functions clause noun phrase korean key task determine relation constituents terms functional categories subject object adverbial problem mainly caused fact morphemes considered crucial frequently omitted phrases tackle propose employ support vector machines determining experiment tagged corpus training svms proposed model useful resolving np attachment play important role elements characterizing function related vp nps explicitly attached omission makes identify subsequently solve sentences complex complicated research make attempt focus analysis embedded morpheme adopt device given analyzed relative later paper brief description svm introduction structural ambiguities major problems syntactic analyses classified known
84	verb noun sequence chinese creates ambiguities parsing resolved know advance tend object relation modifier head paper learning procedure knowledge automatically acquired using existing parser chart filter tree large corpus log likelihood ratio algorithm able acquire pairs typically occur verbobject relations learned process disambiguation evaluation shows accuracy original improves significantly figure correct analysis introduction natural language sentences challenging task largely syntax lack inflectional morphology makes resolution type ambiguity appear different illustrated following phrases register expense registration set grammar rules cover semantic collocational words involved prevent wrong analyses rule parses need typical question rest
85	text categorization essential component applications user navigation world wide web using questionanswering japanese requires effective features documents efficient acquisition knowledge questions addressed focus procedures intend clarify specification answers pages accordingly representations indicate procedure method extracting way combine related texts answer issues sufficiently clarified consequently past studies provide general approach solving task contrast reported qa contain lists descriptions decided including procedural expressions employed results difficulty written different style compared seeking candidates document set various expected relatively gathered study motivation users means navigate accurately information complete relevant respect queries addition list summarization humans edited make understand restriction itemized doesn lose effectiveness initial step work type discuss divides groups non first
86	gram model stochastic predicts word given previous words sequence cluster variant similar classified demonstrated using different clusters predicted conditional leads models superior classical basis asymmetric discussed study paper first present formal definition acm methodology constructing effectiveness evaluated realistic application japanese kana kanji conversion experimental results substantial improvements comparison size analysis shows high performance lies asymmetry introduction widely applied applications speech recognition machine translation asian language text input jelinek brown effective way deal data sparseness problem reduce memory sizes recent research yamamoto lead
87	present syntax based constraint word alignment known cohesion requires disjoint english phrases mapped non overlapping intervals french sentence evaluate utility different algorithms results provide significant improvement quality weaker isomorphism produce increase mod det subj aux obj pre causes host discover devices locate introduction suite la te rep les ibm statistical machine translation models extremely influential computational linguistics past decade striking characteristic style smt total lack linguistic knowledge demonstrated pure techniques inspired new generation nlp research systems proposals introduce syntactic common theme approaches assumption structures pair source target sentences isomorphic strong human translators literal translations result differences according study translational divergences involving dependency tree maintain phrasal words
88	paper address issue encoding information metaphors wordnet database italian eurowordnet analysing corpus data huge number metaphoric expressions hardly dealt using reference italwordnet particular compared contained dictionaries actual words forward proposals enrich resource relevant polysemous senses word saying relate useful cases relative start briefly recalling theory metaphor cognitive linguistic phenomenon proposed lakoff johnson variety research various fields connected study language analysis displaying metaphorical sense extensions discuss ewn project databases european languages developed means interlingual index complete website http www hum nl htm browse center science online references work links websites edu berkeley conceptual home page db cogsci similar german french uni hamburg finally propose way dealing resources obtain necessary disambiguation
89	based machine translation promising method speechto speech robustness retrieves sentences similar input adjusts translations obtain output problems performance degrades style inputs corpus different paper proposes retrieving meaning equivalent overcome sentence shares main despite lacking unimportant information correspond rough retrieval content words modality tense introduction technologies consist recognition synthesis mt receives texts recognized recognizer nature causes difficulty styles written text ungrammatical rule translate accurately compared corpusbased methods ebmt st performs robust requires manual work applying accuracy drastically drops length number retrieved greatly decreases results translating problem arises differences acquire large volume
90	paper addresses specific problem happens common health science research present machine learning based method identifying patients heart failure related conditions automatically classifying clinical notes relies perceptron neural network classifier trained comparable amounts positive negative samples previously categorized human experts documents represented feature vectors features mix single words concept mappings mesh ontologies designed implemented support particular study broader implications experimental classification results accuracy predictive value introduction frequently deal collecting comprehensive set subjects deemed relevant focused needs identify possible candidates asked participate requirements completeness subject pool cases disease incidence prevalence studies acceptable identification large number sources exist electronic format start dictated treating physician aspect candidate prospective patient inclusion exclusion criteria great physicians enabling time treatment trial options
91	paper describes dialogue act tagging scheme developed purpose providing finer grained quantitative metrics comparing evaluating darpa communicator spoken systems quantify effort spent maintaining channel communication establishing frame opposed actually carrying travel planning task designed support results improvement fit models user satisfaction suggest ultimately focused qualitative analysis role various strategy parameters initiative clarifying development paths feasible enhancing future versions standard supported calculation hypothesized potentially affect perception included duration turn measures response asr performance hand labelled completion hypothesis underlying approach behaviors strong effect core collected represent counts turns average length doesn distinguish instructions present flight information furthermore unique way achieving particular communicative goals order explore differential strategies needed characterize capture differences
92	paper proposes description german word order including phenomena considered complex scrambling vp fronting verbal pied piping relates syntactic dependency structure directly topological hierarchy resorting movement similar mechanisms introduction aim article verbs complements free based fairly simple rules forming called model sentence domains composed fields start tree unordered nodes labeled words branches relations encodes subcategorization modification completed communicative plays fundamental role permits choose different possible orders corresponding given thank becker ller fruitful discussions particular thanks igor mel inspiration status phrase pursue problem limited link topology note approach include group phrases nature position constrained instance non finite verb kinds domain positions
93	paper discusses challenges proposes solution performing information retrieval web using chinese natural language speech query main contribution research devising divide conquer strategy alleviate recognition errors model facilitate extraction core semantic string breaks basic components corresponding phrases multi tier map known order eliminate resulting effective introduction entering era major resources daily activities wide spread adoption internet largest wealth share currently search engines support term based users required enter queries directly keyboards large segment population china rest world skills unable advantage vast freely available person speak understand spoken enable average persons access current need learn special training simply engine common devices familiar telephone pda implement important obtain correct terms
94	aim paper present language neutral theory method annotating temporal relations annotation simple applied special training annotations provided defined model theoretic interpretation content based comparison temporally annotated corpora number applications lexicon induction translation linguistic investigation searchable multi database created introduction interpreting narratives essential information extracted classic journalistic imperatives expressed overtly possible apply empirical techniques problems domain left implicit partially specified making formal semantic theories successful specifying contribution overt markers tenses adverbials make meaning sentence discourse investigations narrative shown specific lexical plays important role determining clear kind automatically acquired promising avenue acquiring appears automatic large order necessary explicit task provide requirement systems familiar concerned absolute
95	work presents data model adopted annotating coreference includes different levels annotation speech syntax discourse compare encoding schemes abstract xml proposed standard present tool resolution handles introduction dealing corpus based studies focus study dealt experiments respective information syntactic annotated penn treebank results prolog encoded first adapted portuguese tools formats resources built previous works share particular current common project involves french http www inf br documents pdf research grant brazil using mmax multimodal manual developing automatic deals provided order able relating standards section overview relates describes discussion problems face presented lists
96	paper investigates stacking voting methods combining strong classifiers boosting svm tbl named entity recognition task demonstrate effective approaches culminating model achieves error rate reductions development test sets conll standard baseline respectively adaboost given month develop first language english weeks adapt surprise german goal shared designed achieve high performance relying heavily knowledge specific particular domain spirit avoided using features information easily obtainable major classification introduction carry experiments constructed number relatively individual component models following kinds multiple effectively combine ner emerged important step natural applications including machine translation retrieval extraction research field pioneered message understanding conference performed detailed identification documents result current systems impressive performances specially tuned muc style unclear perform applied identify classify
97	discourse chunking simple way segment dialogues according dialogue participants raise topics negotiate paper explains method arranging chunks shows improve performance act tagger case based reasoning approach applied da tagging task amounts separate concomitant time consuming corpus annotation work present results project improved concept gives information patterns topic raising negotiation accept backchannel clarify commit confirm deliberate deviate scenario exclude explained reject feedback negative positive reason inform introduce offer politeness formula refer setting request comment suggest thank sounds said third okay guess arranged airport let oh tickets opera basically shot really express flights list need schedule trip scott uh stop want step office standing right
98	interface node abstract source filter annotator user defined java class implements loaded chain visualization represented separate box handles details related drawing various visual cues display graphical implemented set components right displays current described previous section allow create modify tune new chains built pre existing figure macro running provides types feedback regarding task progress indicate percentage overall run time active border color varies green red output unit spent indicates bytes second text label meter graphic relative throughput highest solid nodes level shows maximum library tree view upper left currently available machine building extending directories downloaded web added component examines using reflection capabilities places
99	paper present thorough evaluation corpus resource portuguese million word newspaper free processing provide information useful using considerable improvement later versions addition think procedures presented larger nlp community description unfortunately common exercise large european language available cost dealing created framework computational project government funded initiative foster engineering evaluating main goals mind contribute improve usefulness suggest ways going concerned general fact despite research devoted nowadays actual corpora processed lead na ve users readers conclude interesting issue opinion wrong conclusion said particular believe buying browsing consideration turn systems hypotheses evaluated help solely belief similar kinds published different intention positive contribution involved
100	theoretical study range concatenation grammar formalism revealed attractive properties nlp particular languages rcl parsed polynomial time classical grammatical formalisms translated equivalent rcgs increasing worst case parsing complexity translation tree adjoining paper technique purpose improve practical efficiency parsers non deterministic choices main parser language directed guide shared derivation forest output prior suitable superset results evaluation method wide coverage english given introduction nondeterministic process choice occurs explores possible ways parallel using backtracking mechanism cases assisted asks way assistant oracle section present definitions design algorithm transforms parse equal guided relate experiments tag indicates ble problems respective solutions solves
101	combine surface based approach discourse parsing explicit rhetorical grammar order efficiently construct underspecified representation possible structures dept linguistics university potsdam box germany ling manfred stede introduction task automatically determining structure shown relevant inter alia automatic summarization surprisingly previous approaches emphasized need heuristic probabilistic information process finding best likely tree alternative explore idea strictly separating high confidence hypothetical reasoning working trees create parse forest basis cues text subject processing depending application steps calculate continue set structured hypotheses section briefly summarizes proposal introduces compares strategy earlier work matrix clause purpose illustration assume signal bi nuclear contrast relation second nucleus span first case ambiguous linking remaining material suppose elaboration sequence holds relations add possibilities points situation described instead enumerating
102	human sentence processing cognitive load defined ways report considers definition terms total probability structural options point word wi given prefix phrase language model efficiently calculated using probabilistic earley parser interpreted generating predictions reading time basis grammatical assumptions supported data operation stolcke correctly predicts phenomena associated garden path ambiguity subject object relative asymmetry performance present work adopts numerical view competition grammar grounded principle eager sense means experimental situations modeled ones self information ignored proposal person difficulty perceiving syntactic structure toword directly computed phrasestructure approach parsing algorithm developed course explaining high level indicate psycholinguistic observes simulation results conclusion introduction relation knowledge application answer proposed principles strong competence holds mechanism rules
103	provide informal presentation prototype word alignment based previous translation equivalence approach discuss problems encountered shared task aligning parallel romanian english text present preliminary evaluation results suggest ways improving accuracy dictionary sharp contrast occurrence pair equally counts differentiating feature tasks status functional links extracting equivalents interested major categories case especially eurowordnet define cross pos different requires punctuation mark parts bitext assigned finally evaluations measures precision recall differently judged null alignments extraction significance play important role introduction largely described extractor called treq aimed building dictionaries corpora program clustering checking validity lingual monolingual wordnets multilingual lexical ontology paper builds aims generating map built weeks proposed organizers workshop using
104	paper describes framenet online lexical resource english based principles frame semantics considers database reference proposed iso model linguistic annotation language resources provide data category specification annotations rdf specifically daml oil markup units defined relation lemma semantic relations inheritance includes simple annotated sentences xml format references project specific word senses manual automatic summarization resulting focused governors meaning respect verbs annotating governed words explain theory briefly discuss process represented using researchers web background unit case evokes particular evoked structure knowledge required understanding given phrasal item frames question small static scenes states affairs patterns contrast entities roles serve possibly complex event types profile phases participants scene service setting consumed
105	paper presents unsupervised method assembling semantic knowledge ofspeech tagged corpus using graph algorithms model built linking pairs words participate particular syntactic relationships focus symmetric relationship nouns occur lists incremental cluster building algorithm achieves accuracy lexical acquisition task evaluated wordnet classes naturally domain specific ambiguities distinct components surrounding ambiguous word introduction domains increasingly important nlp applications sense disambiguation information extraction speech recognition require lexicons coverage resources increased dramatically recent years leaves problems challenges poor critical rapidly changing current affairs medicine technology time spent human experts employed recognise classify new terms languages remain poorly covered comparison english hand automatically updated simply misleading apple refers fruit tree error situations cover reach wider class practice ability assemble update appropriate vital describes arranging nodes edges represent arranged follows section reviews previous work similarity
106	rules transfer based machine translation automatically acquired bilingual corpora incorrect redundant generated acquisition errors variety new problem propose feedback cleaning method using automatic evaluation mt quality removes way increase score bleu utilized algorithm involves features task applied searching optimal combination experiments improves test sentences according subjective considerable improvement previous methods results ambiguity avoided necessarily improve approaches overcoming selecting appropriate disambiguation process employ second approach paper cutoff frequency hypothesis clean slightly insufficient viewpoint large number requires order obtain sufficient statistically confident current topic aim replace speed development cycle systems developers aids tuning utilizes removing introduction efforts accumulating
107	web consists documents various domains genres method cross language information retrieval independent particular domain paper propose clir employs directory provided multiple versions proposed feature terms first extracted category source target languages corresponding categories determined comparing similarities using pairs intend resolve ambiguities simple dictionary translation narrowing retrieved efficiently cases depending user demand written native rich needs retrieving large order satisfy usual monolingual manually translate query process imposes burden choose incorrect translations especially unfamiliar fulfill researches crosslanguage technique retrieve certain active recent years variety methods including employing corpus statistics disambiguation translated studied results obtained based heavily affected training effectiveness drop significantly
108	paper presents framework clustering text based information retrieval systems prominent feature proposed method documents terms related elements textual clustered simultaneously small overlapping clusters mathematical formulation implementation briefly introduced experimental results st subset term space cluster represents associations sa sd author document authors introduction figure indexing spaces occurrences simplicity focus primarily explanation presented directly applicable general cases attributes attempt provide view process generating individual referred micro contain multiple subsets associated keywords attribute sets set written specific community subject represented motivations considering universal properties textbased large scale sparseness local redundancy better manipulated focusing limited sub regions viewpoints contents conventional provides utilized relations unified background
109	paper novel approach lexical chain based segmentation broadcast news stories select evaluated respect cohesion segmenters texttiling using pk evaluation metrics outperforms systems spoken transcripts algorithm performs best written newswire collection examine differences styles affect accuracy introduction text defined automatic identification boundaries distinct textual units document aim early research model discourse structure focusing detection finegrained topic shifts clausal sentence passage subtopic level tdt initiative concentrated coarse grained resulting story feeds particular unsegmented streams represent challenging real world application approaches success tasks tracking first depend heavily correct non overlapping information extraction techniques analysis combination promising results achieved hidden markov ing commonly speech recognition applications focus element broader linguistic device called quality responsible making elements appear unified
110	paper presents approach automatically build semantic perceptron net topic spotting context lower layer select exact meaning key words employs combination occurrence statistics thesaurus group distributed semantically related form basic nodes infer input document experiments reuters data set demonstrate able capture semantics topics performs task introduction problem identifying presence predefined text formally given collection documents determine probability present assign subject codes newswire stories filter electronic emails online news pre screen information retrieval extraction applications categorization hot area research decade large number techniques proposed tackle including regression model nearest neighbor classification bayesian probabilistic decision tree inductive rule learning neural network line support vector machine methods word based consider relationships features known performance greatly affected lack linguistic understanding particular inability handle synonymy polysemy simple developed alleviate problems ranging
111	wish learn tree mapping training pairs trees mixture strings unlike previous statistical formalisms synchronous allows local distortion topology reformulate permit dependency sketch em viterbi algorithms alignment decoding jason cs jhu edu natural proposal introduction mappings machine translation systems trained sentences mutual translations somewhat free common naturally occurring data first sentence literally children kiss sam paper outlines methods work phrase structure note depicted isomorphic make using substitution grammar stsg collection aligned elementary combined derived pair operation combine formalized later sections shown assembling symbol denotes frontier node replaced root nodes linked line labeled state roots np null start
112	order respond correctly free form factual question given large collection texts needs understand level allows determining constraints imposes possible answer include semantic classification sought suggest using different strategies looking verifying candidate paper presents machine learning approach learn hierarchical classifier guided layered hierarchy types eventually classifies questions finegrained classes accurate results trec introduction domain answering story comprehension important directions natural language processing retrieval task challenging common search engine tasks purpose concise relevant document difficulty acute target text likely overlap reason advanced techniques simple key term extraction needed stages process analyzing degree type competition participants requested build set english automatically extract answers bytes library research supported nsf grants iis itr locating accurately hinges first filtering wide range candidates based categorization
113	mining answer natural language domain question large collection line documents possible recognition expected type relevant text passages technology retrieving texts developed studies devoted paper presents unified model types answering enables discovery exact answers evaluation performed real world questions considers correctness coverage contribution precision evaluations fully automatic systems specified restrictions document test contains length contiguous bytes requirements intentionally simplify task identification left user given information recognized inspecting snippets relatively small size trec step closer retrieval techniques extract lie way steps reported first semantics needs captured translates identifying keywords retrieve introduction textual represents discovering collections
114	rapid growth real world applications nlp systems genuine demand general toolkit programmers linguistic knowledge build specific parser domains accurate application paper extends broad coverage minipar adaptable shallow achieve generality accuracy handling domain nl problems test corpus results significantly higher introduction improvement natural language processing techniques especially speech input rapidly growing develop handle accurately allow generate ends new existing using program method methodology programmer specify set sample sentences task organize similarity large syntactic variations given sentence code user request executes command currently active research area advanced technology national institute standards funding work order
115	case study memory based learning algorithm trained simultaneously chunk sentences assign grammatical function tags chunks compare performance parsing task varying training set sizes different input representations particular consisting words variant includes word form information gold standard pos combinations wordbased shallow parser displays apparently log linear increase surpasses curve data low frequency performs better best comparative experiments real tagger produce lower results argue need explicit intermediate tagging step sufficient material available introduction common speech first analysis providing steps early parsers sequences formed actual later feature grammars central place lexical entry identity major head features days statistical explicitly exclusively symbols base probabilities generally reliable inherent sparseness modern lexicalized interleaved proper instead separate preprocessing module charniak notes generative generate constituent
116	gui presented retrieval supporting english chinese cross language information query translation approach employed using ldc bilingual given different methods results demonstrated strategy faced situation mismatch target documents user reduce common representation purposes automatically translating document converting third simplest first method probably effective route question tools known machine generally fuzzy inaccurate particularly output judged humans tend consumption ir operate bag content terms grammar coherence readability needs important correctly covered expense noise translations purpose combined hedge errors improve coverage viz dictionary mt software introduction allow search retrieve gain understanding written familiar accomplished expert linguist assistance clir growing importance literally
117	development framenet large database semantically annotated sentences research statistical methods semantic tagging advance previous work adopting maximum entropy approach using tag information highest probability sequence given sentence examine level syntactic pattern features increase performance analyze strategy human automatically identified frame elements compare identical test data experiments indicate statistically significant improvement np pp grammatical function figure shows appropriate body movement obj agent ext cause hands inspiration comp lemma shown core element type phrase introduction recent laid foundation approaches task automatic classification project seeks annotate subset british national corpus annotations based semantics frames defined schematic representations situations involving various participants conceptual roles single target predicate relevant tagged role considerable scale magnitude resources available nlp tasks average sparsity makes
118	paper implemented set title generation methods using training news stories evaluated independent test corpus broadcast documents comparing results manual transcription automatically recognized speech average number correct words order metric overall possible level approaching accuracy titles generated perfect text transcriptions cs cmu edu nearest neighbour method generating compare performance recognition decompose problem parts learning analysis sequence form present different comparison na ve bayesian approach limited vocabulary neighbors iterative expectationmaximization term frequency inverse document details presented section issues involved follows choosing appropriate deciding finding forms readable sentence outline gave introduction experiment discusses conclusions drawn suggests improvements keywords machine create complex task generate
119	structure texts considerations lead compositionality criterion requires discourse relations link large text spans explained hold salient units constituent notion forms basis first order logic axiomatization captures formal properties valid structures formalization independent set rhetorical actually considered yields proper relation instantiation characterization structural specific theory building author discusses algorithmic paradigms compute employ model theoretic techniques encode problem computational linguistics volume number derivation classical constraint satisfaction propositional satisfiability grammar based builds proof solving performance algorithms compared empirically benchmark manually encoded problems marcu distinguish determined second monograph attention shifts alternative approaches deriving approach relies primarily markers shallow parsing employs result depth corpus analysis designed rules covering english cue phrases addition punctuation marks adds plain knowledge surface oriented lexical occurrence data syntactic criteria similarity measures
120	developed effective probabilistic classifier document classification introducing concept differential vectors spaces simple posteriori calculation using intra extra statistics demonstrates advantage space based lsi performance standard pattern recognition machine learning methods employed view inherent flexibility natural language number dimensions required represent featuring practical comprising huge terms algorithm first problem resolved dimensionality reduction scheme enabling documents term projection smaller decomposition method extensively image processing latent semantic indexing proved efficient analysis extraction providing powerful tool retrieval confirmed empirical studies demonstrated efficiency automated cross query translation introduction paper introduces new supervised procedure given labeled preclassified finite appropriate clusters database select classify introduced cluster stage vector model widely represented assign weights components evaluating frequency occurrences corresponding
121	development machine translation important issue able adapt specific domain requiring timeconsuming lexical work experimented using statistical word alignment algorithm derive association pairs complement existing bilingual dictionary information added time automatic creation pattern database making technique significantly improves overall quality measured independent blind evaluation transfer component consists correspondences learned process training place aligned sentences analyzed french english analysis systems yield dependency structures entitled logical forms lf allow extraction structural stored runtime thought base conceptual structure representations figure illustration trained approximately manuals help files text produced human translators original version sample set sentence dans le menu sur administration puis des pour les start point programs administrative tools click user manager domains lexicon period establish initial tentative sources
122	present light weight tool annotation linguistic data multiple levels based simplification annotations sets markables attributes standing certain relations main features emphasizing simplicity introduction recent years development tools recurrent topic corpusbased computational linguistics currently specialized wide range phenomena different description available principles design implementation realized emerged xml storage format file level separation base stand java sake platform independence handle intended coreference dialogue acts discourse structure yield exist independently easily combined applied language highly desirable allow simultaneous browsing annotating addition tasks distributed research groups expertise group specializing act tagging completion individual multi single produced mmax presented paper customizable corpora assumption
123	present tool annotation anaphoric bridging relations corpus written texts based differences similarities phenomena define scheme implement demonstrate introduction discourse entities major importance establishing maintaining textual coherence consider following heidelberg text collection descriptive city collected lab tourist information course project zu st das nicht es gt die ein der mit den gen contrast cities situated particularly exposed position street main entrance shows original flat segments previous entity normally definite np respectively pronoun presupposes denoted introduced universe assumed familiar reader case anaphorically first sentence second relation obvious denote ability automatically resolve kinds important feature
124	paper describes simple patternmatching algorithm recovering nodes identifying indexed antecedents phrase structure trees contain information patterns minimal connected tree fragments containing node proposes evaluation procedure recovery procedures independent details makes possible compare performance parser output annotations goldstandard corpus evaluating charniak penn treebank shows surprisingly frequently occuring types given simplicity introduction main motivations research parsing syntactic provides important semantic interpretation first step variety thank brown laboratory linguistic processing michael collins advice supported nsf awards dms itr iis useful tasks broad coverage parsers available typically produce parse encodes local include discusses kind viz wh traces post add wide encode additional non dependencies words phrases constructions questions relative clauses
125	article presents method aligning words translations imposes compositionality constraint alignments produced statistical translation models experiments conducted shared task word alignment demonstrate effectiveness proposed approach process leads better first closer look standard wa techniques section propose way imposing discuss various implementation issues finally present experimental results introduction pioneering work ibm machine team years methods proven valuable tools approaching automation play central role modeling reliable crucial acquiring parameters nature defined lead descriptions correspondences target language unsatisfactory human perspective notion typically fundamental assumption ultimately sl segment contribute produce tl degree makes perfect sense stochastic point view contrasts hypothesis basis mt approaches natural intuitions individual portions text autonomously
126	technology speech recognition language processing spoken dialogue systems improved developed extent practical usage order fundamental techniques portability previous research demonstrated module portal constructed strategy design tool script controlling paper report highly portable interpreter using commercial electronic dictionary apply domains tasks confirm validity domain task keywords robust introduction robustness reliability mt guidance touch screen input output graphical sub modules recognizer nat ural response generator multi modal interface general speaking depended given increasingly applications widespread cost developing new enormous transferred easily adapted researches focused high prototype simply complicated
127	present stochastic parsing consisting lexical functional grammar constraint based parser disambiguation model report results applying upenn wall street journal treebank combines partial techniques reach coverage unseen data annotations provide partially labeled discriminative statistical estimation using exponential models performance evaluated measuring matches predicate argument relations distinct test sets gold standard manually annotated structures subset wsj evaluation reaches score dependency brown corpus achieves linguistically fine grained systems parameter resort unsupervised training corpora tailored specific grammars created manual resulting relatively small sentences furthermore effort involved coding broadcoverage hand led specialization domains sacrificing free text approach presented paper first attempt scale problem fact receive analysis tackled extension absence complete parse socalled fragment allows input analyzed sequence formed chunks set parses chosen basis
128	signs lives make easier familiar pose problems tourist able understand foreign country paper present efforts automatic sign translation discuss methods detection using based machine technology approach developing advantage human intelligence selecting area domain needed user determine translated multiple detected image selected processed recognized developed prototype recognize chinese input video camera common translate english text voice stream applications systems equipped unique combination software hardware includes computers microphones head mounted displays enables multimodal interface speech gesture inputs provide assistance tourists supports natural language processing recognition handwriting fusion vision module trained locate read written adapt new environments interpret intentions offered spoken clarification pointing capable benefit types individuals visually handicapped military conjunction
129	plaser multimedia tool instant feedback designed teach english pronunciation high school students hong kong mother tongue cantonese chinese objective correct assess student overall quality major challenges related speech recognition technology include non native accent reliable corrective visualization errors employs hidden markov models represent position dependent phonemes discriminatively trained using standard american timit corpus set utterances collected local speakers kinds speaking exercises minimal pair word computes confidence based score phoneme given vowel consonant segment novel color scheme indicate accuracy grade period months said preferred traditional classes learn test conducted result shows skill improved mr graduate department science carnegie mellon university working introduction advances automatic technologies decade led recent employment aided language learning listen project bear mind goal asr common classification applications orthogonal requires general allophonic
130	paper proposes general theory conversational inferences distinguishes kinds hard way accounts wider range non literal utterance meanings gricean relevance theories motivated types utterances hearer fails infer nonliteral introduction first characterizes sense grice levinson consistently discussed existing important respect management dialog secondly analyzes inference invoked derive thirdly outline implicature order understanding supposed work characterize interested case transition topics explain sure type really second discussing regards cases stress importance concept rationality theorists hand explained extent awkward dealing terms principle noticed stipulated explanation propose
131	mt described paper combines hand built analysis generation components automatically learned based transfer patterns component traditional bilingual dictionary seed pattern learning process provide fallback translations runtime describes improvement purposes instead aligned corpora making knowledge entirely derivable fully automated performs better crafted importantly enabled create day new language pair french spanish technical domain surpasses quality bar commercial chosen comparison previous work introduction phrase strongly associated research statistical demonstrate possible non provided rely large resource propose bi texts section creation gives evaluation results examines impact existing english systems scale traditionally relied heavily encoded dictionaries yang clearly state systran translation capabilities dependent carefully highquality advent bitexts efforts derive lexicons led substantial including resources semi automatic lexica
132	automatic evaluation translation quality proved useful target language english paper japanese studied existing method based gram similarity translations reference sentences apply variation semantically similar expressions proposed applies set paraphrasing rules order increase score differ writing styles experimental results improved correlation human introduction evaluating natural processing applications output important users developers tasks sentential parsing morphological analysis named entity recognition evaluate automatically right answer defined deterministically specific grammar assumed criterion machine straightforward infinite ways meanings enumerate answers exhaustively spite practically laborious work humans tends arbitrary reliable consistency bleu methods ratio occurring grams single multiple high reported evaluations arabic chinese french spanish investigates main goal design
133	paper describes preliminary work exploring relative effectiveness speech versus text based tutoring current tutorial dialogue systems prior studies shown considerable benefits spoken interactions currently developing conceptual physics end order explore input modalities task domain started collecting parallel human corpora cases students interact tutor web interface present comparison number features demonstrated correlate reliably learning gains interacting using notes general science education literature importance talking reflecting explaining ways learn encouraging student includes generating inferences material read relating new old study prompting content prompts encourage associated second important advantage affords opportunity tailor instruction needs tutors choose individual characteristics knowledge state ignore signs confusion run risk preventing adaptation comparing naive learners review
134	idea whiteboard project integrate deep shallow natural language processing components order benefit synergy first fully integrated hybrid consisting fast hpsg parser utilizes tokenization pos morphology lexical named entity phrase chunk topological sentence field analyses integration increases robustness directs search space reduces time paper focus central facilities xslt based annotation report benefits nlp component present xsl transformation annotations architecture infrastructure portable suited restricted development architectures applications comparable described limited tagging general independent paradigms applied purely systems introduction decade sgml xml important interchange format linguistic data created manually linguists automatically lt supporting software main
135	relatively self contained subtask natural language generation sentence realization process generating grammatically correct abstract semantic logical representation propose method carried using simplified version large analysis grammar combined statistical model provides measure probability syntactic substructures derived corpus guide subsequent statistically driven work knowledge mainly focused sub task surface production string linguistic content assumes existence separate higher level produce following canonical pipeline architecture approach described focus attempts tightly integrate avoid need create specific resources nitrogen introduction limited notably knight hatzivassiloglou langkilde bangalore rambow paper reports new direction emphasis reusing originally produced purposes particular extensive way retain built first significant attempt extremely simple generates lattice representing possible strings
136	automatic text categorization problem automatically assigning documents predefined categories order classify extract features previous research document commonly represented term frequency inverted feature difference important sentences unimportant considered paper measure importance using summarization techniques vector different weights according sentence verify new method conducted experiments language newsgroup data sets written english korean kinds classifiers na ve bayes rocchio nn svm observed significant improvement introduction goal certain number pre defined active area information retrieval machine learning wide range supervised algorithms applied training set categorized classifying measured modified proportion calculated test proposed known ken lang gathered discussion group result
137	paper describes project tagging spontaneous speech corpus morphological information word segmentation parts ofspeech analysis based maximum entropy model independent domain corpora accuracy achieved using discuss problems dictionary developed certain helpful improving analyzing ful making language recognition linguists investigating distribution morphemes needed basic techniques japanese sentence morpheme minimal grammatical unit suffix process segmenting given row assigning attributes inflection type important posed unknown words training statistical approaches applied problem estimate identify correctly uchimoto proposed method tag consult learning characteristics learn
138	number machine translation systems based learning algorithms presented methods acquire rules pairs similar sentences bilingual text corpora means sparse data result require large amounts training order high quality overcome problem propose method using recursive chain new acquired acquisition results generation process linked evaluation experiments confirmed effectiveness link type division business administration university ku japan ac jp mt proposed difficulties rule approaches correspond corpus approach corpusbased including linguistic knowledge improve adding statistical required obtain examplebased relies various resources automatically acquires effective existing analogical reasoning different parts replaced variables generalize shown figure
139	paper concerned identification semantically categories temporal locating adverbials time denoting expressions dividing line draw phrases occur surface form typical contexts include relatively simple week fact gone practically unnoticed literature structurally complex ones headed uniform semantic categorisation mere advocated consequences grammatical assessed analysis postulates null preposition forms corollary partition set particles traditionally classified sets truly heads introduction portuguese english chosen romance germanic families object languages attempt subcategories hypotheses expected apply comparable formal framework discourse representation theory general informal terms difference follows representations intervals locate entities axis distinction
140	technical documents abstracts produced steps first reader presented indicative abstract identifies topics document interested specific information source informative figure shows automatic process conceptual identification text generation selective analysis contains topic describes sections introduces relevant entities identified terms appearing obtained words term expansion particular feature obtain definitions statements relevance usefulness development seen article organized follows section corpus professional specify linguistic task summarization texts deduced overview implementation generating summaries designing human robot presents views intelligent interactive service robots authors observed key research issue robotics integration humans discusses technologies emphasis interaction direct local autonomy greater machine architecture gives
141	discovery semantic relations text increasingly important applications question answering information extraction summarization understanding paper presents method automatic manner using naive bayes learning algorithm tested upenn treebank corpus targeted detected precision recall introduction problem description relation nlp consider sentence want work build new economy creating jobs investing technology america continue lead world growth opportunity adverb modifies verb adverbial phrase attached prepositional expresses attaches create allows systems identify formulate answers questions possible state ofthe art qa identifying following answered democrats provides discovering
142	paper presents method assists maintaining rule based named entity recognition classification underlying idea separate constructed machine learning monitor performance training data second generated avoiding need manual tagging disagreement systems acts signal updating generality approach illustrated applying large corpora different languages greek french results encouraging showing alternative assist significantly maintenance rulebased introduction proposed promising solution major problem language engineering construction lexical resources real world make variety particular grammars lexicons general purpose ineffective applications specialised vocabulary supported reason significant effort currently generic tools quickly adapt thematic domain adaptation mainly involves specific semantic identification proper names text types persons organisations locations important subtask information retrieval extraction typically included nerc lexicon form gazetteer lists grammar responsible recognising entities
143	paper addresses related topics firstly presents building blocks flexible multimodal dialog interfaces based standardized components indicate thanks supported mobile heterogeneous data sources mass market deployment provided adequate modularization respected secondly perspective discussion knowledge management firms argues systems access company offer trigger new practice importance companies introduction concerned promoting creation dissemination organizations variety technologies particular information support process way technology contributed networks individuals stored office able remain desk share thousands communication brings improvement entry points network longer confined networking anytime goes step removing restrictions target user interface viz historical reasons design inspired partly needs machines certainly bound scenario featuring large screens keyboards human beings movement speech exchange visual representations text graphics bring devices important issue
144	corpus based research relies human annotated corpora said non negligible errors remain frequently penn treebank detection important natural language processing paper propose method detect using support vector machines idea extracting exceptional elements violate consistency svms assign weight element pos tagged apply english japanese achieve high precision detecting introduction widely statistical speech taggers developed training data obtain information rules systems quantity quality affect performance general hand error prone problematic deteriorate furthermore incorrect instances testing prevent accurate measurement studies improvements conducted presently service media laboratory corporate development center electric industry tagging major methods accuracy wsj obtaining higher accuracies mentioned limitation largely caused inconsistencies correcting improving correct
145	train decision tree memory based classifier predicting prosodic pitch accents breaks dutch text basis shallow compute features algorithms tasks individually simultaneously parameters selection optimized task iterative efficient wrapper procedure progressive sampling training data results consistent significant advantage mbl cart indicate combination cost generalization score loss tests cross validated held yield scores accent placement respectively shown outperform informed baseline rule reliably indicated intra sentential punctuation appears challenging introduction speech aims producing understandable natural sounding output needs board methods prosody systems start generating representation linguistic symbolic level followed actual phonetic realization terms pauses segmental durations first step involves placing inserting boundaries right locations correspond roughly movements lend emphasis certain words utterance interruptions flow typically realized pause boundary marking movement lengthening phrase final segments errors impede listener correct understanding spoken known hard problem thought require information syntactic semantic relations
146	motivated success ensemble methods machine learning areas natural language processing developed multi source approach question answering based combining results different agents searching answers multiple corpora adopt fundamentally strategies utilizing primarily knowledge mechanisms adopting statistical techniques present level answer resolution algorithm combines passage levels experiments evaluating effectiveness relative improvement baseline number questions correctly answered according average precision metric paper investigate impact qa general fashion additionally classifiers employed combined produce final output adopted utilize parallel consult sources identifying given employ combine produced individual strategy independent implementing finding search focus agent predominantly
147	work presents semantical analysis spatial prepositions associated prefixes french sur polish propose theory abstract places method description helps build invariant meanings linguistics units introduction natural languages encode temporal representations various ways article analyses particularly interested way preposition determine place interesting note view point problems arise meaning composed lexical predicate prepositional origin impossible present results methods means mentioned spanish progress linguists recognized necessity quasi topological studying space encoded elementary topology defined mathematical capture exactly linguistic instance idea boundary expressed refer limit hand understanding reduced notion cognitive referring represent approach
148	texts acquired recognition sources continuous speech handwriting ocr generally types errors regardless characteristics source particular output process poorly segmented containing underspecified symbols shape codes incorrectly identified project presented paper addresses developing unified linguistic framework called morphologic assistant provides feedback corrections various processes customized morpho syntactic analysis lexicons alphabets correspond symbol set successful provide services proper disambiguated segmentation disambiguation correction recognized outlines methods post processing currently introduction produce sequence discrete entirely characters printed text refer input actually second tier data flow user receives black box providing linguistically sound correctly first performs actual carries perform transformation converted written correlation original analog result closest possible simply conversion direct impossible insufficient lexical models help recognize elements language extracting meaningful passages databases fully inflected forms fairly
149	mit lincoln laboratory developing english machine translation cclinc korean consists core modules language understanding generation mediated neutral meaning representation called semantic frame key features include robust efficient parsing high quality word sense disambiguation accurate order target rapid development porting new domains knowledge based automated acquisition grammars trained newspaper articles chemical biological produces output sufficient content original document arrangement vocabulary replacement appropriate surface form realization serving input question answering paper focus text component information access speech frames languages overview translingual structure given figure parses transforms properties discussed section utilized applications extraction
150	paper presents new bootstrapping approach named entity classification requires common noun pronoun seeds correspond concept target ne type man woman person entire procedure implemented training successive learners decision list learn parsing based high precision rules hidden markov model trained string sequence patterns second learner corpus automatically tagged first resulting approaches supervised performance types demonstrates intuitive support tagging user defined differences discussed considerable research using different techniques include systems handcrafted machine learning maximum entropy state art rule reach human targeted domain face knowledge bottleneck making rapid porting effectively entities motivation unsupervised raw given boosting existing tagger structures presented various schemes extraction small proper names tasks chunking including focus assuming chunks constructed parser key idea
151	declarative constraint based grammars primarily head driven phrase structure grammar work researchers logic programming community monograph accessible background formalisms hpsg essential follow minnen job making relatively using numerous explained number typographic errors programs crucial missing figure make reading somewhat need notorious highly inefficient processing point view techniques explored automatically transform input specialized efficiently realizes user goal viewed performing equivalence transformations program derive efficient respect range simple strategies literal rearrangement complex ones building recursion magic templates closely related extended suitable dealing feature divided parts control lexical rules chapters deal rule compilation chapter deals methods central extraction information notions identifies arguments bound degree nondeterminism alternatives choice points available evaluating book reviews given
152	corpus molecular biology domain proceedings hlt walker okapi trec pages adding relevance xml fl ranking approach retrieval structured documents technical report iai tr university
153	pseudo relevance feedback empirically known useful method enhancing retrieval performance apply rocchio results initial search assuming ranked documents relevant paper searching ntcir patent test collection employ mechanism new based taylor formula linear functions consists records including text japanese materials unfortunately effectiveness methods observed experiment introduction widely recognized effective improving context interactive ir pointed users represent information needs defined set terms statements resulting poor queries bring unsatisfactory happen automatically manually extract add expression obviously expected second using ex shown log frequency term document query number total data typical approach called basic idea
154	aiming acquire named entity translation knowledge content aligned corpora utilizing ne extraction techniques research constructing japaneseenglish broadcast news corpus tags represent class information coreference monolingual document corresponding japanese english pairs analysis annotated article shown occurrence classes number order given language provide clue nes languages relatively accurate past application bilingual expected obtain developing machine documents including articles current topics translating correctly indispensable conveying translations listed conventional dictionaries necessary retrieve latest extracting using literally translated parallel official written makes easier desired contain decided extract multilingual new daily sentential alignment commonly starting point finding words expressions possible correspond non sentences statistical methods valid
155	present machine learning approach evaluating wellformedness output translation using classifiers learn distinguish human reference translations evaluate mt tracking improvements time aid kind failure analysis help guide development select alternative strings method presented fully automated independent source language target domain introduction evaluation expensive process prohibitively evaluations performed quickly frequently order measure progress paper describes designed facilitate identification areas investigation improvement focuses address issues content transfer researchers applying natural generation tasks internal goodness metrics assessment langkilde knight employ gram candidate outputs ngram perplexity compare systems su alshawi bangalore string edit distance sentences gauge quality useful provide linguistic information identifying work required better resemble generated text considered solved problem impossible observed general humans easily reliably categorize sentence
156	propose nlp methodology analyzing patent claims combines symbolic grammar formalisms methods enhancing analysis robustness output analyzer shallow interlingual representation captures structure content claim text related application machine translation improving readability information retrieval extraction summarization generation universal sense applied language parts documentation introduction volume applications makes essential adequate processing tools provide better results field activity techniques associated specificity domain promise quality document generally recognized features complex sentences peculiar style researchers really rely linguistic component procedure illustrate potential sketch possible conclude description project status future work units deep lexicon predicates model words interrelations elements invention mainly verbs adjectives prepositions knowledge base designed help solve problems different kinds ambiguity minimize acquisition effort drawing heavily restrictions
157	explore active learning support vector machines works non trivial task natural language processing japanese word segmentation test case particular discuss size pool affects curve early stage training larger labeled required achieve given level accuracy smaller addition propose novel technique large number unlabeled effectively adding gradually experimental results requires previous research proposed needs using random sampling introduction corpus based supervised standard approach high performance weakness need annotated reasonably method problem annotation labour intensive expensive order overcome unsupervised methods minimally depend tasks domains match promising classifier selects requests teacher label different passive randomly general framework
158	demonstrate text sign language translation investigating structure assisting production narratives informative presentations conventional pc laptop phenomena languages involve simultaneous manual non components conveying meaning features comprised posture upper orientation head facial expressions decomposed hand shape position motion hamburg notation established phonetic transcription sls comprising motivated symbols signs constrained occur signing space dimensional signer extends level body arm length terms ways anchored fixed nominal verbal signed location internal allow relatively modification contrast varying locations significance furthermore directional verbs grammatical semantic information encoded specific start end positions syntactic distinction native deaf people provision access services important
159	paper gives overview work statistical machine translation spoken dialogues particular framework verbmobil project goal domains appointment scheduling travel planning starting bayes decision rule speech recognition required probability distributions structured parts language model alignment lexicon components report results task experience obtained large scale end evaluation showed approach resulted significantly lower error rates competing approaches sentence rate comparison modelling widely research groups apply presentation based carried eutrans linguistics theory statistics computational extremely controversial decades controversy summarized statement chomsky recognized notion entirely useless interpretation term considered majority experts artificial intelligence concept years overlooked fact automatic text
160	paper reports investigation turn functions graphical communication based examination dialogue data collected involve collaborative drawing interactions spoken joint problem solving task turns presents piece information partner keeping effects speech domain contrast expand scope dialogues include multi modal need consider possibilities non cross changes conducted preliminary analysis existence power mechanism grounding introduction characterized talk studies focused phenomena processes participants conversations means interaction draw maps directions plans discuss floor make diagrams solve problems crucial account modes obtain comprehensible model basic mechanisms human elucidate nature setting tools increasingly free photographs web page references visual presentations researchers looked roles verbal cues eye gaze gestures movements coordinating utterances
161	paper argue comparative evaluation anaphora resolution performed using pre processing tools set data proposes environment comparing algorithms illustrated presenting results methods basis measures idea workbench ended architecture allows incorporation different comparison discusses particular configuration new incorporating approaches sharing common knowledge poor philosophy kennedy boguraev parser free algorithm baldwin mitkov approach order fair consistent accurate address problems identified developed principles enables testing development time consuming task given implement expected achieve clearer assessment advantages disadvantages developing alleviates associated obtaining codes original programs advantage introduction nlp indicate efficiency performance help discover brings current state play field end known similar highly desirable
162	aim finding minimal set fragments achieves maximal parse accuracy data oriented parsing experiments penn wall street journal treebank counts arbitrary trees important leading improved previous models tested isolate dependency relations neglect contribute higher model deteriorate improves main question addressed paper report carried investigate strategies constraining subtrees constraints decrease consist upper bound number words subtree depth unlexicalized resulting parsers wsj introduction dop goals statistical natural language dependencies stochastic linguistic intuitions restricting locality headwords constituents leaving exist linguistically motivated hand extreme view issue given annotated corpus seen regardless size lexicalization principle form grammar large extremely redundant
163	language users individual linguistic styles spoken dialogue benefit adapting style user input analysis output generation investigate possibility automatically classify speakers according corpora dialogues analyzed numerical parameters computed speaker reduced linguistically interpretable components means principal component classes established cluster unseen classified trained neural networks varying error rates depending corpus type first investigation using special models carried motivation participants make linguistics pertinent hand participant important element personality quantitative literature time determine authorship written texts carbonell natural queries tries adapt grammar starting simple basic relaxing augmenting provides significant differences active patterns generated different fairly consistent sessions spanning days systems aspect optimize social performed common interaction shown stylistic elements adopted studies indicated variations conversations high low people mark shared conceptualizations
164	categorial grammars inria campus nancy france fr abstract introduce new formalism based linear logic derives current type logical sense syntax semantics handled set primitives consequence reversible provides different computational paradigms freely composed atom syntactic category hand semantic contents following scheme term asymmetry broken allowing terms using theory expressing categories types first point generalization usual allows level approach advocated second satisfied dropping aspects logics implies approaches word order constraints expressed apparent loss expressive power introduction offer clear cut lexical items assigned combine akin lambek calculus called recipes typed interface advantage correspondence readings extracted rely distinction
165	information extraction systems assist analysts electronic documents paper focuses tasks designed support discovery applications implies examining large volumes drawn various sources situations anticipated priori require breadth depth need domain independent easily customized specific domains end users given tools customize defining new intermediate level richer subject verb object triples produced shallow complex scenarios defined message understanding conference describes robust scalable engine purposes entity profiles concept based general events represent realistic goals terms accomplished term providing useful facilitate correlation output existing structured data benchmarking results core utilizing presented introduction implemented named infoxtract portable decade seen great advances area muc driving force developing technology successful task tagging state art exemplified miller
166	report empirical results series studies aimed automatically predicting information quality news documents multiple research methods data analysis techniques enabled level machine prediction procedures regarding user experiments statistical described categories intrinsic iq accessibility contextual representational elements accuracy objectivity reputation security relevancy value added completeness interpretability ease understanding concise representation consistent introduction table dimensions attempts assess primarily focused counting hyperlinks networked environment representative include work colleagues price previous able produce algorithmic measures web based link counts limited number aspects popularity approach record actual users assessments articles conduct advanced models association scoring occurrence prevalence certain textual features large scale multi institutional project hitiqa worked developing extended model classifying addition extension traditional notion relevance involves science researchers university serving intelligent analysts targeted term defined international organization standards characteristics entity bear ability satisfy stated implied need numerous study classification wang strong proposed qualities detailed
167	demonstration involves way automatic speechto speech translation consumer shelf pda work darpa funded babylon project investigating better systems communication field development software based required addressing number hard issues including new language team integration small device computational efficiency limited platform scalable coverage domain background developed generation voice recognize set pre defined phrases play recorded ported easily languages requiring hand sentences severely limits reducing party responses simple pointing addresses conversation different groups asked address specific aspects task techniques specifications pittsburgh group presented challenges first arabic experience test capabilities moving quickly second instructed interlingua approach source translated intermediate form shared step expansion cmu history working third constrained portable host entire
168	offer computational analysis resolution ellipsis certain cases dialogue clarification goes standard techniques anaphora requires operations highly structured linguistically heterogeneous representations characterize operate couched version head driven phrase structure grammar combined theory information states sketch algorithm process utterance integration iss leads grounding clausal reading asking bo raise constituent mean issue ce involves ambiguity simply vague important clearly pragmatic reasoning plays role understanding ces considerations nonetheless favour existence first bnc provides numerous misunderstandings concerning interpretation speaker intends clarifies original er say foot piece wire laugh joke dick anonymous acl reviewer proposed analyzed terms single lines thought heard don know closely related readings understandings exhibits discussion detailed frequency
169	parsing returning analyses form sets grammatical relations obtain high precision particular relation certain correct technique statistical parser using manually developed wide coverage grammar english licensed observe increase test corpus naturally occurring text introduction head dependent relationships advocated useful level representation structure number different large scale tasks instance recent work treebank levels accuracy reached lexicalised probabilistic models tuples bouma van noord create dependency treebanks semi automatically order induce based parse selection lin srinivas evaluated phrase parsers matching gold standard bracketings research unsupervised acquisition lexical information corpora argument predicates word classes disambiguation collocations previous version paper presented contains new experiments results constitute convenient intermediate applications extraction document retrieval web variety approaches robust unrestricted natural area analysis finite state hand coded transducers recognise linear configurations
170	paper describes alternative translation model based text chunk framework statistical machine suggested first performs chunking word translated finally chunks reordered scenario modeling experimented broadcoverage japanese english traveling corpus achieved improved performance introduction formulates problem translating source sentence language target maximization conditional probability application bayes rule resulted argmax pp term called representing likelihood generation implementation alignment successfully applied similar pairs french german drastically different ones failure limited representation weak structure handling complicated correspondence provides process structured follows chunked local alignments match constraints components trained variation experiment carried decoder left right beam search observed
171	automatic extraction multiword expressions presents tough challenge nlp community corpus linguistics various statistically driven knowledge based approaches proposed tested efficient mwe remains unsolved issue paper present research work approaching using semantic field annotator english tagger developed lancaster university identify units depict single concepts meter built sheffield evaluate approach evaluation extracted total candidates manual checking accepted valid mwes producing precision estimated recall low frequency terms occurring twice results provides practical solution introduction important tool useful numerous areas including terminology machine translation bilingual multilingual alignment interpretation generation language number suggested address problem extent sag pain neck specifically analysis drawn collection british newspaper reports court
172	paper reports learning computational grammars project network devoted studying application machine techniques suitable interested systematic survey understand relevance factors success esp availability annotated data kind dependencies knowledge bases focused syntax noun phrase introduction preliminary satisfying results member institutes listed authors included issco university geneva impressed early experiments applying natural language rich area nerbonne let rug nl osborne cogsci ed ac uk sri cambridge cam com rob xrce grenoble xerox sfs uni college dublin james ua beginning industrial partner immediate applications scientific goal evaluation learn chosen np shared training test material case drawn
173	blank mark word boundaries chinese text result identifying words segmentation ambiguities occurrences unknown conventionally extracted statistical methods simple efficient using linguistic knowledge suffer drawbacks low precision recall character strings significance phrases partial instead frequency new hardly identifiable addition information try possible morphology syntax semantics world identification fully utilizes context content steps detection process extraction verification practical implemented online identifies including high rates problem considered needs investigated according inspection sinica corpus million segmented shows listed ckip lexicon entries document characters morphemes syntactic ambiguous semantic morpho structure different categories rules enumerate types harder naive introduction prominent problems
174	paper present chinese word segmentation algorithms based socalled lmr tagging taggers implemented maximum entropy markov model transformation learning combine results scan input opposite directions achieves scores academia sinica corpus hong kong city university respectively shen dept info science pennsylvania philadelphia pa usa cis upenn edu hanzi problem machine algorithm determine appropriate position reasons expect approach work first words generally fewer characters result number positions small second principle occur possible behave way substantial distributed constrained manner plural marker occurs final finally exhaustively listed new bound naturally occurring text stays fairly constant represent different tags lm left periphery followed mm mr right preceded lr process
175	paper discusses supervised learning morphology using stochastic transducers trained expectationmaximization algorithm approaches presented first directly model process secondly define similarity measure related fisher kernel method memory based technique evaluated compared data sets english german slovene arabic introduction finite state methods large adequate morphological processes languages standard methodology level capable handling complexity finnish needs substantial extensions handle non concatenative models primarily concerned mapping deep lexical strings surface framework general present algorithms transduction pairs inflected words techniques applicable types string transductions principles parametric density estimation powerful form machine suited natural language tasks particular strength ability rules specific exceptions single generally class label tag associated feature vector given manual semi automatic labels set features pre defined distance function new instances classified according closest instance complete solution problem produce converted appropriate
176	paper presents recent work participation first international chinese word segmentation bakeoff based generalpurpose ngram model case learning approach disambiguation identifying vocabulary words achieving recall present strategies language training rule analyze performance discuss areas improvement discovery introduction decades studies effort different approaches systems test comparison common datasets participated designed integrate general purpose probabilistic extracted corpora trained em algorithm using unsegmented originally developed enhance accuracy tate english alignment ongoing ebmt project texts available expected robust handle novel independent segmented simplify uni gram relied viterbi probable instead attempting possible segmentations sentence complicated version works straightforward way extracts knowledge set context dependent transformation rules corpus applies ambiguous strings terms similarity contexts empirically computed
177	relative logical scope multiple modifiers np semantically significant paper proposes structurally based method computing order type syntactic complexity algorithm language neutral works minimal errors wide range languages specific introduction noun phrases commonly including quantifiers attributive adjective clauses appositives frequently noted literature linear signify english favorite new movie modifies phrase refers movies computation inherent linguistic necessary determining correct interpretation nps follows potentially useful application depend addition multilingual proposed considers structural factors internal structure described currently implemented microsoft research organized section examines various determine modifier preliminary assignment compare predictions diverse set propose revised related work conclusion
178	websites businesses accommodate customer needs business requirements traditional menu driven navigation key word search allow users intentions precisely developed conversational interface online shopping provides convenient personalized access information using natural language dialog user studies significantly reduced length interactions terms time number clicks finding products core engine easily adaptable domains data management subsystem maintains concept repository common sense concepts phrasal lexicon lists possible ways referring rules map specifications defining propositional logic formula constraints product reflect goals decisions extended database combines precompiled evaluations definitions provide representation guides investigating automated tools helping developers extract relevant basis descriptions queries introduction evaluation areas center routing application email retrieval telephony banking demonstration present effective means negotiating requests domain conducted evaluate usability nla study seventeen test subjects preferred average
179	increasing complexity multi media modal language resources poses problem respects paper wants discuss metadata descriptions locate suitable internet discover apply tools data respect projects introduction succeeded reaching consensus representative linguistic community europe standard machine readable implementation allow build searchable browsable space presentation based work executed framework international eagles isle project named imdi practical meta psycholinguistics collaborative enterprise create corpus demo material european institutes suggestions idea describing document help characteristic elements new known corpora childes header information content speakers spoken text encoding initiative ces group specified tag set described early initiatives meant general description mm lrs formation desires recent domains dublin core mpeg want achieve xml certain documents accessible net
180	paper describes characteristic features dependency structures japanese spoken language investigating dialogue corpus proposes stochastic approach parsing method robustly cope inversion phenomena bunsetsus don head bunsetsu relaxing syntactic constraints acquires advance probabilities dependencies tagged provides plausible structure utterance basis experiment driver utterances car experimental result shown effective robust ing assumed following directed right left cross depends investigated satisfy relaxes first third ones permits direction doesn depend results expressed partial techniques based approaches proposed matsumoto probability frequency cooccurrence uchimoto
181	paper describes method detecting grammatical lexical errors japanese learners english techniques improve accuracy error detection limited training data demonstrate extent proposed methods hold promise conducting experiments using learner corpus contains information introduce examine accomplished including tags labeled sst introduction important keeping current driven society acquisition foreign languages especially international communications developing assisted language teaching learning environment compiled large scale speech provides great deal useful construction model developmental stages speaking abilities support assumed informed kind utterances need framework allow detect automatically based entirely extracted interview test standard face cases native speaker interviews audio recorded judged raters evaluation scheme hours totaling million words transcribed
182	ambiguity high location names cities named buffalo based previous work paper presents refined hybrid approach geographic references using information extraction engine infoxtract normalization module consists local pattern matching discourse occurrence analysis default senses multiple knowledge sources number ways driven context maximum spanning tree search applying sense heuristics extracting web results benchmarked accuracy test collections consist news articles tourist guides performance contribution component discussed introduction task decode extracted entities problem nes including city new york state country canada brazil china usa needs properly handled converting normal form support entity profile construction merging visualization events map partly supported grant air force research laboratory rome ny contract authors wish thank supporting constraints geographically related mentioned document rochester probable refer
183	present probabilistic parsing model german trained negra treebank observe existing lexicalized models using head dependencies successful english fail outperform unlexicalized baseline learning curves effect lack training data propose alternative sister instead outperforms achieving labeled precision recall indicates appropriate treebanks flat structures frank keller school informatics university edinburgh buccleuch place eh lw uk inf ed ac charniak collins proposed successfully applied czech chinese resulting performance significantly lower bikel chiang compare leaving possibility lexicalization useful languages paper structured follows section reviews syntactic properties focusing semi flexible wordorder describes standard presents series experiments results odds reported poor error analysis shows cope
184	paper new language model multi class composite gram proposed avoid data sparseness problem spoken collect training maintains accurate word prediction capability reliability sparse compact size based multiple clusters called statistical connectivity position grams regarded attributes cluster created represent positional furthermore introducing higher order grouping frequent extended experiments result lower perplexity error rate speech recognition smaller parameter conventional effective flexible rule grammatical constraints cases performance strongly depends models accuracy increase according number transition combinations exponentially reliable probability values dramatically critical sufficient solution ngrams words mapped probabilities approximated depend definition classes fact
185	notion target categorization concept learnability svms derives formal properties inductive nature based availability large set training certain assumptions material results linearly separable svm controlled error accordingly chapter analyzes methods estimating predictive accuracy task knowledge embedded provides complete information statistical theory directly employed upper bound testing discusses core technique inducing tc functions means first tradition approaches induce maximum margin hyperplane separates positive negative binary setting empirical evidence performance known benchmarking data sets confirms viability induction transductive introduced exploits consistent bias building approach analogies forms active learning derived pieces weak test algorithms concrete application previous reported chapters efficient finally presented reference software platform effect author ph thesis empirically grounding powerful book great merit space given
186	paper presents lightweight knowledgebased reasoning framework javelin domain question answering propose constrained representation text meaning flexible unification strategy matches questions retrieved passages based semantic similarities weighted relations words obtain mechanism match answer candidates organization follows section briefly components discusses syntactic processing strategies sections preliminary assigns confidence values final contains summary future plans introduction modern systems aim providing answers natural language opendomain context task achieved combining information retrieval extraction techniques modified applicable unrestricted texts semantics poor surface pattern matching statistical methods successful factoid complex tasks require consideration requirement motivated work qa incorporate knowledge ontologies inference engines world databases unavailable alternative approaches adopted present approach detection contrast trying realize formal model explicit consists basic analysis module engine passage
187	present approach named entity recognition support vector machines capture transition probabilities lattice trained hundreds thousands features drawn conll shared task training data margin outputs converted estimated using simple static function performance evaluated test set results english german model introduction language independence achieve different languages appear require ner systems severely limited number consider computational expense handling large numbers high risk increases feature finely tuned effective constrained sets naturally dependent increasing tagger handle ameliorate problem designer select relatively lieu highly parameters efficiently simultaneously limiting candidates application paper proposes novel way svms called svm describes space presents interested based sentence processed individually built column word contains vertex possible tag connected edge
188	paper stage model content determination systems summarise time series data first involves building qualitative overview set second using actual produce summaries based observations human experts introduction propose general architecture summarisation assumes happens stages formed decided extensive knowledge acquisition carried sumtime project matches ka activities stop implemented issues need think degree strategy appropriate nlg addresses problem indicates process responsible determining texts generated probably important end user perspective agreement community different adapting widely varying approaches algorithms architectures intuitions developers instead empirical detailed rules corpus analysis interaction
189	approaches described automatic unsupervised acquisition patterns information extraction approach based particular model acquired predicate argument structure dependency chain effect alternative models previously studied paper compare prior introduce new subtree arbitrary subtrees trees discovery procedure demonstrate experimentally improvement recall using introduction process identifying events actions participating entities text field developed focus study moved knowledge including domain specific lexicons methods emerged event corpus annotation view cost manual labor representation work pattern fixed set templates relations subject verb object previous paths nodes discuss limitations relation ability capture scenarios present extract direct evaluation scenario template tasks shows proposed outperforms section describes
190	oral communication ubiquitous carries important information time consuming document given development storage media networks record store conversation documentation question interesting piece large database traditional retrieval techniques keywords representation offer additional indices place rejoinder alternative index activity discussing planning informing story telling paper addresses problem automatic detection activities meeting situation everyday extensions basic idea discussed evaluated similar define subsets larger detect automatically shown tv shows emotions dominance distribution speakers available surface directly despite small size databases results effectiveness obtained introduction access research area recording storing amounts audio data feasible written electronically documented constructing new form transcript minutes communications resource especially corresponding documents cost using considered high tutorial introductions senior staff member worthwhile attend office meetings contain informations relevant informal
191	statistical measures word similarity application areas natural language processing modeling information retrieval report comparative study methods estimating cooccurrence frequencies required frequency estimates generated sized corpus web data impact size effectiveness base evaluation toefl question set practice questions sets consisting number multiple choice seeking best synonym given target context provided examine exploit combination measure estimation method answers results previously reported introduction different tests proposed strength association texts attempt dependence words using statistics large key assumption consequence occurrence closeness text indicative kind relationship synonymy antonymy sequences unlikely independent provide quantitative compare pairs occurring despite fact simple idea variety ways estimate appear document passage paragraph sentence fixed window boundaries
192	paper proposes new approach segmentation utterances sentences using linguistic model based maximum entropy weighted bidirectional grams usual gram algorithm searches sentence boundaries text left right candidate boundary evaluated mainly respect context fully considering divided incomplete fragments order make contexts propose modeling experimental results indicate significantly outperforms segmenting chinese english input speech recognition language analysis generation output figure systems module representing current utterance exactly pronounced punctuation symbols marking shows parse segmented recognizer contains wrongly recognized words noise crucial segment processing believe accurate greatly improve performance modules stevenson demonstrated difficulties experiment people educated bachelor degree level required broadcast transcripts removed humans agree insertion
193	mapping syntactic structure prosodic widely discussed topic linguistics work insights gained research syntax prosody order develop computational model assigns unrestricted text resulting intended help speech predict phrase breaks addition linguistic constraints incorporates performance oriented parameter approximates effect speaking rate rulebased probabilistic require training present implementations english german evaluation results examine approach account different break patterns associated slow normal fast rates ip vp np ap det tease girl didn dogs figure sentence utterance introduction intonational phrases phonologically defined units characteristic contour particular marked presence major pitch accent boundary manifested pause accompanied local fall rise constituent final syllable lengthening stronger articulation initial consonants nonrecursive cover modifiers spoken language delivered uninterrupted monotone cues pauses tones greatly listener understand systems statistical models
194	truecasing process restoring case information badly text paper explores issues proposes statistical language modeling based achieves accuracy news articles task evaluation shows measure improvement named entity recognition using context automatic content extraction mention detection speech improved factor enhances machine translation output yields bleu score argues valuable component processing applications introduction large high quality corpora reality digital world enormous collections low natural transcripts various audio sources optical character online messaging email web raw produced containing misspellings insertions deletions grammatical errors jargon terms work ibm tj watson research center want enhance order produce better rule systems models focuses readability carrying data brings picture new originally considered noisy nlp tasks performs normalization styles genres consider following mildly ambiguous sentence rep james showed going meeting alternative
195	paper describes novel multi stage recognition procedure deducing spelling pronunciation set names overall goal automatic acquisition unknown words human conversational spoken spelled single utterance achieving concise natural dialogue flow first pass extracts letter hypotheses waveform maps phonemic hierarchical sublexical model capable generating mappings second determines combining information augmented language constraints integrated users asked time process implemented multiple parallel threads real operation subsequent inducing new series operations automatically updates systems immediately accommodate word experiments promising results phoneme accuracies preliminary dataset introduction emerging effective means humans access spaces interaction computers way knowledge space static intervention developers significant enhancement usability ability acquire end include understanding usage task carry effectively challenging regard
196	recent advances automatic speech recognition technology goal naturally sounding dialog systems reach improved brought light new problem understand user tells need sophisticated responding issue response users extensively studied natural language generation community context research adapted high cost hand crafting knowledge based overcome employing machine learning techniques work reported paper partially funded darpa contract mda asr limited quality typically employ initiative strategy prompts specific information presents paradigm range input time output interactions interaction supply different support mixed places greater requirements increases responses terms informativeness
197	causation relations pervasive feature human language despite automatic acquisition causal information text proved task nlp paper provides method detection extraction present inductive learning approach discovery lexical semantic constraints necessary disambiguation question answering devised classification questions tested procedure qa verbal brief review previous work computational linguistics section lexico syntactic patterns express english texts difficulties involved validation ambiguous referring proposed results discussed application demonstrated linguists tried tackle notion causality natural focusing constructions relation studies attempted extract implicit inter sentential cause effect using knowledge based inferences hand coded domain specific bases scale realistic applications researchers linguistic identify explicit inference french capture relationships indicators organized model classifies causative
198	ongoing work information extraction seen text normalization task normalized representation detect paraphrases texts paraphrase detection tasks built robust analyzer english exclusively achieved using symbolic methods grammar development rules expressed formalism developed integrated way experiment paper evaluated presents encouraging results collection particularly interesting build documents processed output selected knowledge analysis phase unifies different ways expressing similar products first corpus semantic focus following section dedicated continuity parsing finally evaluation performed future improvements discussed introduction expected study main perspectives point view recognize expressions convey generation produce natural language semantically equivalent original phrase address processing consisting agency
199	present method identifying cognates vocabularies related languages measure phonetic similarity based features performs better orthographic measures longest common subsequence ratio dice coefficient introduce procedure estimating semantic glosses employs keyword selection wordnet tests performed indicate capable discovering average nearly percent precision introduction narrow sense historical linguistics words developed ancestor word cognate pair french spanish latin contexts including paper term loosely denoting different similar form meaning making distinction borrowed genetically english japanese borrowing considered unrelated identification component principal tasks field establishing relatedness reconstructing histories language families corpus bitext alignment extracting interesting multilingual corpora task addressed lated ways level given goal compute value reflects likelihood assume lexeme notation accompanied specify metalanguage
200	present implemented model story understanding apply children argue consists building models efficiently constructed using satisfiability solver program contains multiple representations commonsense knowledge narrative input transforms problem runs produces output expressed language event calculus based multi representation propose states events described concerned space time needs feelings single realm represented different levels spatial semantic hierarchy topological metric granularity room scale object powerful engine particular operates conjunction rich world scope methodology introduction fundamental unsolved artificial intelligence computational linguistics order understand text able make inferences explicitly ability reason perform reasoning largely ignored late seek
201	expanding repertoire commercial user interfaces incorporating multimodal techniques combining traditional point click speech recognition synthesis gesture applications software help children read child reads aloud keeps track offers feedback difficulty subtle changing text color articulated phrase friendly character talks infinitely patient detailed records progress reading company sup introduction vision technology provide high quality low cost coach delivers voice activated instruction practice assessment electronic media fundamental fun mainstream th basic level country critical needs improve performance future individually depends literacy predicts economic individuals basics reviewed recent report national panel engaging supported oral valuable means building proficiency present giving finding human adult sit automated break bottleneck school support reduce digital divide unprecedented tracking data leverage teachers efforts
202	paper proposes application finite state approximation techniques unification based grammar word formation language german refinement algorithm proposed extends space automaton selectively adding distinctions parsing history point entering context free rule selection items exploits specific linguistic nature experiments avoids explosion size construction formalisms computational syntax english grammars possibly unificationbased makes possible deal bracketing structure compounding impossible cover generality setting languages spelling conventions compounds support convenient split sub token processing finitestate technology multi complex written spaces words appear corpora fully adequate general account analysis checking features derivational affixes case tree required instance prefix combines nouns linearly adjacent verb including suffix turns noun mis ver locus rules nlp orthography following productive patterns spelled separating components
203	paper presents corpus study evaluative speculative language knowledge useful applications text categorization summarization analyses annotator agreement characteristics subjective performed yields needed design ective machine learning systems identifying subjectivity natural refers aspects express opinions evaluations tagging distinguishing sentences present forms objectively factual information task especially relevant news reporting internet forums various agents expressed numerous retrieval extraction current technology focuses exclusively subject matter documents additional document relevance including status material presented attitudes topic recognition email classi cation intellectual attribution recognizing speaker role radio broadcasts review mining generation style clustering point view application introduction opinionated writer linguistic clues pragmatic discourse distinctions existing lexical resources comprehensively coded goal work corpora contributes empirically examining explore annotating
204	optimality theoretic syntax optimization unrestricted expressive power ot constraints undecidable paper provides proof decidability based expressed reference local subtrees builds kaplan construction showing lfg generation produces contextfree languages language base grammar assumed given highly setup using linguistically motivated set learning proceeds bias unmarked linguistic structures computational interleaving candidate constraint checking proposed task identification optimal potentially infinite proven assume characterized context free plus additional violated structure generated cfg defined iff problem intersection known spirit extremely powerful individual explanatory arise interaction simple introduction systems interesting alternative classical formal grammars data meaning way form grammatical alternatives underlying logical
205	classification problems require decisions large number competing classes tasks handled general purpose learning methods addressed ad hoc fashion suggest approach sequential model utilizes classifiers sequentially restrict maintaining high probability presence outcome candidates set theoretical computational properties discussed argue important nlp domains advantages illustrated experiment partof speech tagging introduction natural language inferences viewed resolving ambiguity semantic syntactic based surrounding context turn goal select class label collection include word sense disambiguation accent restoration choice selection machine translation sensitive spelling correction recognition identifying discourse markers popular technique variety sort shown significant success partial list consists bayesian decision lists hybrids hmms inductive logic research supported nsf grants iis sbr linear transformationbased source difficulty fact words possible tags algorithms handle multi
206	present paper seek approach bilingual lexicon extraction non aligned comparable corpora phrasal translation evaluations cross language information retrieval stages model proposed acquisition terminology disambiguation selection best alternatives according linguistics based knowledge different rescoring techniques evaluated order select results demonstrate yields better translations effectiveness achieved japaneseenglish pair scarce resources scoring clir consists retrieving documents written using queries application completed large scale test collection ntcir figure shows overall design consisting main parts follows bi directional term linguistic pruning applied extracted filter detect terms morphologically similar speech tags source query related world wide web possible interaction user finally linear combination dictionaries thesauri transliteration special phonetic alphabet foreign words loanwords depending cost introduction
207	paper investigates bootstrapping statistical parsers reduce reliance manually annotated training data consider unsupervised approach iteratively trained output semi supervised corrected human corrects parser adding selection labeled integral frameworks propose methods based criteria minimizing errors maximizing utility incorporating criterion method results better introduction current state art large corpora penn treebank production expensive labor intensive given bottleneck considerable automating annotation process overcome approaches machine learning applied sample variant active tries identify small set unlabeled sen benefit selecting high offset additional contain reduces number sentences annotator check maximize result minimize error blum introduced bootstrap classifiers different views initially seed label unannotated iterative
208	present novel data driven method integrated shallow deep parsing mediated xml based multi layer annotation architecture robust accurate stochastic topological field parser german constraintbased hpsg phrasal constraints highly flexible allowing targeted fine grained guidance constraint conduct systematic experiments demonstrate substantial performance gains introduction strong points processing technology lfg parsers certainly lies high degree precision detailed linguistic analysis systems able deliver considerable progress area speed rival medium depth technologies terms throughput robustness net effect impact application oriented nlp fairly limited advent hybrid architectures presented possible integrate added value integration largely focused lexical level improve urgent needs increasing coverage work supported grant dfki project whiteboard restricted morphological pos information extended lexico semantic named entity expressions including multiword assume vertical pipeline scenario tools provide annotations preprocessing interface perspective opened layered centric broader encourages horizontal cross effects
209	ibm research people working unstructured information management technologies strong focus hlt spread globe engaged activities ranging natural language dialog machine translation bioinformatics domain question answering analysis strongly suggested improving organization ability quickly discover results rapidly combine different approaches accelerate scientific advance furthermore reuse common architecture robust software framework transfer product platforms market analyses indicating growing need process specifically multi lingual text coupled investment led development middleware processing dubbed uima heart powerful search capabilities data driven composition distributed deployment engines paper general introduction focusing design points engine discuss helping technology goals major labs significant human researchers group developing technical engineering pursuit specific objectives applications high level fold advances enabling rapid combination
210	paper refines analysis cotraining defines evaluates new training algorithm theoretical justification gives yarowsky shows based different independence assumptions agreement unlabeled data matter directly seek classifiers agree suggestion special case particular application considers properties core recent work prove classifier low generalization error second view addresses shortcomings original proof justifies searching extend ways first assume conditional assumption proposed blum remarkably powerful violated weaker suffices finds report implementation empirical results finally consider question relation suggest actually holds effective finding high precision overview term bootstrapping refers problem setting given small set labeled large task induce
211	morphotactic component states inflections resulted compilation transitions morphophonemic rules added conclusion note current proposal morphemic lexicon grammar compatible separate morphological syntax integrated inflectional morphology architecture figure fact suitable inflecting languages surface forms bound morphemes isolate delivered sequence morpheme labels analyzer matched lexical type assignments sing loc grammatical interpretation argued computational models lattice necessary embodies tactical problems discussion transparent scoping semantics main concern cases remainder article role kind analysis performed end case study english plural section present morphosyntactic treatment shown follow carpenter categorizing numerical modifiers intersective adjectives noun boys interpreted green boxes bracketing reflects set sets denotes nonempty members correctly interpret interaction
212	developed willex tool helps grammar developers work efficiently using annotated corpora recording parsing errors major new functions first decreases ambiguity results comparing corpus removing wrong partial automatically manually second data clarify defects statistically applied large scale hpsg style improve general purpose grammars reduces human workload language intuition encoded syntactically tagged xml format records allow picture target save debugging time effort ideal developing tools writer xtag alep controll nara institute science technology following problems largely depend help users handle effectively let correct locally cope shortcomings proposes alternative method efficient process workflow conventional different ways check sentence modify hand sentences
213	unification grammars known given grammar word undecidable order ensure decidability constraints commonly line parsability suggested recognition problem decidable satisfy olp question satisfies paper investigate various definitions discuss inter relations introduction db context free considered lack expressive power needed modelling natural languages originated extension basic idea augment rules feature structures express additional information variants exist necessarily assume explicit backbone string parsing deliver parse trees induces determining structural descriptions assigned rest concerned formal turing machines constraint called offline literature recognizing existence make comparative analysis different first time researchers conjecture
214	present simple method language independent task text categorization learning based character level gram models approach information theoretic principles achieves effective performance variety languages tasks requiring feature selection extensive pre processing demonstrate independence proposed technique experimental results greek english chinese japanese problems identification authorship attribution genre classification topic detection state art case neighbor classifiers common aspect approaches treat standard problem reduce process steps engineering space critical achieving features identified reasonable classifier perform unfortunately methodology drawbacks first construction dependent various techniques stop word removal stemming require specific knowledge design adequately purely issue asian identifying words sequences hard suffer added complexity coping segmentation errors second attention linguistic style markers systems rely heavily bag third enormous number possible consider
215	paper describes domain independent machine learning based approach temporally anchoring ordering events news achieves accuracy partially introduction motivated pilot experiment subjects providing event judgments revealed narrative convention applied time successive past tense clauses involves mixed initiative corpus annotation automatic tagging identify clause structure aspect temporal adverbials reference times respect report results practical nlp applications text summarization question answering place increasing demands processing information multidocument important know relative order correctly merge present able ask occurs occurred prior particular capabilities presuppose ability infer discourse number different knowledge sources appear involved inferring including world max entered room drunk wine man died central secretary general opened meeting arrived south africa pointed dictated perceived value latest
216	paper proposes new method ranking synonyms ordered suitability nuances particular context semantic features extracted definition statements ordinary dictionary ranks types initial step achieve paraphrase authoring support introduction researches automatic paraphrasing aim document modification wide range nlp applications reading comprehension transformation based external constraints hand revision known type targets texts preparation systems revising documents classified syntactic points spelling grammatical mistakes corrects grammar checker readability similar aims simplify complicated sentences phrases reflect authors intentions precisely replace words semantically ambiguous inadequate ones suitable contexts third handle semantics rare let consider kind first presents target word input sentence user paraphrases selected keeping consistency especially important express differences paraphrased pairs clearly
217	propose question answering encyclopedia knowledge base existing encyclopedias lack technical new terms automatically generated world wide web purpose first search pages containing term linguistic patterns html structures extract text fragments describing finally extracted descriptions organized based word senses domains evaluate way experiments japanese information technology engineers examination test collection ishikawa university library science tsukuba japan ac jp introduction motivated partially trec qa late major topics natural language processing retrieval communities number systems targeting proposed harabagiu rely conventional ir shallow nlp methods complicated procedure requires explicit bases paper generate includes recent modified version method intuitively answers interrogative questions searches database related performance evaluated coverage accuracy ratio
218	qc cg oe cv hc rb fa fb ub rc vc ec rd aa db su ax dc yx va ad rr cu ce vb ev
219	apply decision tree based approach pronoun resolution spoken dialogue deals pronouns non np antecedents present set features designed determine promising evaluate switchboard dialogues compares byron manually tuned introduction corpus methods machine learning techniques applied anaphora written text considerable success demonstrated systems approaches achieve performance comparable hand crafted easily new domains feasible port given paper describes extensions adaptations needed applying important differences accounted obvious difference abundance studies shown significant allen report trains eckert strube note remainder consists suggest algorithm improved considerably enabling resolve difficulties encounters previous tiny deep semantic analysis discourse processing
220	business retrieval fresh information important conventional search engines based centralized architecture retrieve time collect documents web robots contrast engine distributed need site makes index independently result fast indexing support temporal required paper particular propose implementation ranking organized follows section survey databases cse define evaluate finally end conclusions value determined ratio number consumers want providers increases decreases known called common knowledge according shannon theory entropy words creates soon highest first created valuable process finding sense
221	named entity recognition key techniques fields natural language processing information retrieval question answering unfortunately chinese lack capitalization uncertainty word segmentation paper present hybrid algorithm combine class based statistical model various types human knowledge order avoid data sparseness problem employ tong yi ci lin thesaurus smooth parameters measure person names location organization newswire test evaluation mandarin respectively introduction ner task first introduced message understanding conference subtask entities defined temporal expressions number compared simpler research focuses multilingual ne started including japanese spanish continued english think main differences lie unlike lacks plays important role signaling second space words segment text errors affect result third different structures especially single unified capture
222	propose lexicalized tree adjoining grammar source features useful reranking output statistical parser paper extend notion kernel arbitrary sub trees parse derivation derived provided ltag formalism addition original definition making compact based task obtain labeled recall precision wsj section penn treebank sentences length words results gives rise relative difference score improvement linear discriminative methods permit feature functions condition aspects input flexibility makes possible incorporate various kinds defined characters speech tags context free rules depending application model applied grams commonly nlp applications explicitly using linguistic insight problem search entire space ngram representation polynomial sequences gram typically introduces noisy result lower accuracy way solve function tailored particular parsing
223	paper report experiments automatic word sense disambiguation using maximum entropy approach english chinese verbs compare difficulty tasks languages investigate types contextual features useful language experimental results suggest richer linguistic wsd beneficial central problem lexical level natural processing highly ambiguous words pose continuing problems nlp applications lead irrelevant document retrieval information systems inaccurate translations machine translation different senses translated correctly tagging context prove choice efforts develop provide accurate current emphasis creating manually tagged data supervised training statistical evidenced senseval polysemous distinct related greatest challenge predicate argument selectional restrictions hypothesized particularly disambiguating verb introduction models solve classification task applied wide range including sentence boundary detection speech parsing assigning tags viewed similar separate set required vocabulary item
224	progress human language technology requires increasing amounts data annotation growing variety languages research named entity extraction exception linguistic consortium creating annotated corpora support information english chinese arabic programs paper covers scope tasks describes challenges multilingual corpus development concludes description developed introduction ongoing vast training plus stable benchmark measure researchers require greater volumes representing inventory sophisticated presents substantial challenge hlt community creation costly new approaches tens hundreds thousands hours speech millions words text availability high quality resources remains central issue communities involved basic education related role international centers continues evolve accommodate emerging needs founded university pennsylvania seed money darpa specifically address need shared ldc created published databases accumulated considerable experience skill managing large scale collection projects established center standards best practices resource
225	growing infrastructures sharing nlp tools resources paper presents sissa project aims developing infrastructure prototyping editing validation application architectures provide user graphical environment selecting activities relevant particular task associated linguistic processors execute connecting new checking chosen architectural hypothesis corresponds functional specifications given twofold aim definition common unification different formalisms grammar description implementation repository storing grammars written using rapid testing systems starting available introduction recent years commercial deployment technologies makes urgent availability allow quick integration modules applications efforts direction gate provides software heterogeneous processing evaluated refined individually combined larger concentrate aspect designing end hand
226	researchers intuitions differences humancomputer human interactions previously subject empirical scrutiny work presents initial experiments direction ultimate goal learn improve dialogue systems working data air travel domain identified number striking mixed initiative term dialogues clear sense really means define context communicator task darpa funded program involving major industry academic sites established provide generation intelligent conversational interfaces distributed information current initiated voice menu style interaction flexible strategy shared control fall concentrated groups moving domains introduction comparing humanhuman annotated sets tags act unsolicited aim begin exploration aspects shed light hc issues examine voiced strong communication want compare
227	objective research develop language learning based minimum specific functionality compatible observations perceptual capabilities human development proposed meaning extracted video images detection physical contact parameters mapping sentence form performed grammatical constructions retrieved construction inventory closed class items uniquely identifying target structure resulting displays robust acquisition behavior certain developmental studies modest innate specificity thomas institute theoretical biology universit berlin germany cnrs fr collision suggesting infants represent event predicate agent patient arguments demonstrated force dynamic primitives support attachment sequences recognize events including pick stack characterization logic intermediate representations renders variability motion view importantly lexical semantics number verbs established automatic image processing introduction posed problem pairs cognitive science task artificial confronted reduced version faced child involves extraction paired scene significant sentences meanings remains nativist perspective
228	detection unknown words unfortunately recall satisfactory mainly chinese language new patterns created hardly efficiently maintain rules hand introduction statistical techniques nlp research word using results showed based model better solution resource needed large corpus fortunately tagged corpora purpose propose method extract person names organization low frequency treat general experiments first segment assign pos tags text morphological analyzer second break segmented characters character features svm chunker proposed steps successively analysis chasen widely japanese texts achieves precision newspaper articles assume similar characteristics certain extent languages share semantically heavily loaded kanji hanzi assumption hidden markov models target sequence maximize probability details allow detect especially case
229	selectional preference learning methods focused class relations verb selects subject given nominal papers extends previous statistical models preferences presents model learns classes verbs motivation twofold different senses share tested word sense disambiguation task object relationships extracted small disambiguated corpus david nlp group university basque country pk spain si es factors help alleviate scarcity data fact using words provides ability approach easily extended larger corpora defined exercise order evaluate sample documents semcor following introduction section reviews restriction acquisition explains formalized sections shows results wsd experiment acquired analysed finally conclusions drawn future work outlined literature learned form eat entity paper yielding relation hierarchy opposed trained associations tagged wordnet
230	statistical methods pp attachment fall classes according training material first unsupervised trained raw text corpora second supervised manually disambiguated win regard accuracy small sets available case advantageous disambiguation algorithm outperforms extracted treebank varied backoff approach collins transformation based brill resnik scored correct attachments outperformed better results reported nagao wordnet thesaurus learner achieved figures english evaluated german work constrained availability constraint intertwined combination using information learning leads best believe relevant languages treebanks introduction numerous prepositional phrase proposed broadly divided decision derived large automatically processed prominent lexical association score hindle rooth cooccurrence values ratnaparkhi resulted
231	paper reports experiments classifying semantic role annotations assigned prepositional phrases penn treebank framenet cases prepositions classified given dataset inventory using standard word sense disambiguation features addition traditional collocations incorporate class based form wordnet hypernyms achieve slightly better performance versus separate classifiers preposition single classifier combined approach yields significant gain accuracy collocation types achieves individual classification effective confusion fine grained roles introduction english convey important relations text verbal adjuncts principle means conveying supporting entities described predicate highly ambiguous typical collegiate dictionary dozens senses common tend closely related contrast parts speech variety distinct recent advances senseval natural apply basic handling course disambiguate granularity present dictionaries illustrated later nonetheless certain feasible provide results disambiguating different levels coarse earlier work computational linguistics
232	paper describes method learning countability preferences english nouns raw text corpora maps corpus attested lexico syntactic properties noun feature vector suite memory based classifiers predict membership classes able assign precision ence knowledge important analysis generation helps constrain interpretations parses preference determines plural range possible determiners particularly machine translation closest equivalent different source languages chinese japanese mark means choice largely responsibility component addition obtained resource dictionary construction learn unannotated first annotate automatically train using set gold standard data comlex transfer dictionaries alt training described baldwin bond run extract members countable dog uncountable furniture bipartite pair clothes discuss present lexical resources experiment process results evaluation finally theoretical practical implications
233	present automatic extraction salient information email messages providing gist meaning dealing raises challenges address paper heterogeneous data terms length topic method combines shallow linguistic processing machine learning extract phrasal units representative content application fully implemented embedded active platform evaluation performed paradigms introduction volume huge growing qualitative quantitative study overload sidner shows people receive large number day summarization techniques adequate realworld applications great need berger mittal mckeown radev kupiec hovy message summarizer convey user document phrase combining web documents raise text task addresses free style syntactically grammatically formed domain genre independent variable multiple topics furthermore lack syntactic grammatical structures granularity extracts presents level complexity work problem identifying spread sentences paragraphs novel approach first simple noun phrases candidate representing
234	known occurrence counts words documents modeled poorly standard distributions binomial poisson observed vary simple models predict prompting beta mixtures robust alternatives deficiency fact occur given document resulting large amounts propose using dealing evaluate competing naive bayes text classification task account practically relevant variation easier work set parameters controls properties distribution important model aspects data realistic applications suspect loglinear applying negative linguistic count word occurrences natural ask extent extra captured answering question main goal begin reviewing classic results frequency fixed length texts introduction violate simplistic assumptions probability particular inadequacy modeling proposed case commonly alternative ability capture
235	paper presents extended glr parsing algorithm grammar pcfg based tomita extends define new assigns probability frequency associated rule syntactic implemented approach statistics furthermore experiments executed fields chinese base noun phrase identification results compared ways prove efficient method straightforward way combine statistical property rules experiment presented introduction significant components natural language processing methods developed development corpus linguistics applications general shift reduce widely lavie spoken finite state probabilistic model compute action probabilities formalization structure important pars explain following section definition symbols inherits classifications penn tree bank totally speech tags functional tag set pos belong terminal non final
236	linguistics generally labeling approaches concludes article advocating calls new foundations general forth textbook machine translation harvard articles earliest history project including design development automatic dictionary subsequent theoretical applied work area syntax includes interesting accounts personal experiences especially connection visit soviet union later participation junior member language processing advisory committee national academy sciences report great influence course mt weaver relating individual content source sharply divergent views events relationships young assistant provides details career personality director account organization subgroups impression conveyed structured relatively smoothly functioning operation discussions occasionally picture emerges possible memories paul colleagues christine describes evolving set weekly characterized lack harmony main focus
237	present neural network method inducing representations parse histories using history estimate probabilities needed statistical left corner parser resulting achieves performance penn treebank best current task despite smaller vocabulary size prior linguistic knowledge crucial success structurally determined soft biases representation hard independence assumptions introduction unlike problems addressed machine learning parsing natural language sentences requires choosing unbounded number possible phrase structure trees standard approach problem decompose choice sequence choices finite actions tree define probabilistic model defining action context apply techniques learn parsers based models probability conditioned previous faced unusual situation conditioning information major challenge designing accurately estimated approaches hand crafted set features represent work presented automatically induce real valued
238	approach automatic detection syllable boundaries presented demonstrate manually constructed grammars trained novel algorithm combining advantages treebank bracketed corpora training investigate effect corpus size performance evaluation shows hand written grammar performs better finding extensive compounds tts needs module words converted graphemes phonemes processed speech placement correct boundary essential application phonological rules offers machine learning predicting method builds resources first resource series context free extracted automatically predict different described section second aims combine obtained probabilistic evaluated test influence adding linguistic information increases accuracy models instance coded knowledge consonants onset coda restricted distribution position word plays important role furthermore linguistically motivated need small achieve high perform largest remainder paper organized follows refers introduce combination
239	paper describes natural language learning method extracts knowledge form semantic patterns ontology elements associated syntactic components text combines eurowordnet ontological concepts correct sense word assigned disambiguation module extract sets subject verb direct object indirect define behaviour main textual based role hand shown maximum entropy models applied wsd tasks provide results evaluation revealed accuracy rate preliminary test explain adequate set improve success nlp pronoun resolution implemented modules performed english general features allow treatment languages spanish introduction defined configure add new information source processing obtain necessary count different tools parser make analysis parsing selection functional tool order ensure appropriate concept finally pattern extraction store pairs sentence
240	named entity recognition important sophisticated information service question answering text mining answer type unit depend focus model korean word specific features capitalizing feature english high dependence large amounts hand labeled data dictionary tedious expensive create paper devise hmm based recognizer consider various context models furthermore weakly supervised learning technique cotraining combine unlabeled keywords training ne case classification classified clues inner clue words present detecting contained determining boundary ambiguity determine nes share statistical unify detection extend initial seed method boosting introduction recent
241	paper presents experiments applying latent semantic analysis dialogue act classification employ lsa proper augmented ways report results diag corpus tutoring dialogues spanish work theoretical goal assessing approach based raw text improved using additional features introduction systems need perform dialog order understand role user utterance plays generate appropriate turn recent years variety empirical techniques train classifier propose method thought representing meaning word kind average meanings passages appears passage words contains learns cooccurrence collections texts builds space represented vectors similarity measured cosine contained angle single value decomposition mathematical technique causes arranged reflect major associative patterns data ignores smaller important influences successfully applied tasks assess quality student essays interpret input intelligent research
242	provide logical definition minimalist grammars formalization chomsky program leads neat relation categorial grammar parsing resource sensitive logic learning algorithm structured data emphasize connection montague semantics viewed formal computation form presentation observed discussed study lexicalized consumption common base differ various respects hand traditional operation poor generative capacity unless properties provided precise lack computational crucial theoretical practical viewpoint regarding applications needs generation algorithms considering conceptual aspects needed validate linguistic claims economy efficiency claim treatment simpler description defined course important claimed central notion forms obscure process syntax suggested first step direction setting immediately set framework yields hints
243	generative view language processing builds bigger units smaller ones means rewriting steps axiomatic eliminates invalid linguistic structures set possible wellformedness principles present generator based argue combined tag grammar flat semantics permits avoiding drawbacks known hold generators computational linguistics universit des saarbr cken germany uni sb tor program models satisfying formula parsing model enumerate parse trees conjunction lexical categories selected basis input string plus additional constraints encoded similarly generation bag items look phase design work efficiently natural type information delivered logic grammars shows constraint programming implement tree descriptions entries expressed paper build minor modifications generate description workings algorithm compare standard existing algorithms
244	biographical multidocument summarizer summarizes information people described news corpus statistics linguistic knowledge select merge descriptions document collection removing redundant summarization components extensively evaluated coherence accuracy non redundancy produced introduction explosion world wide web brought vast relatively unstructured created demand new ways managing unwieldy body dynamically changing goal automatic text partially structured source extract content present important condensed form manner sensitive needs user task summaries generic aimed broad audience topic focused tailored requirements particular group users multi definition extension single collections related documents mds potentially help glance examine similarities differences specialized systems constructed various applications discuss biographies course book length author description nature biography vary physical characteristics scientific achievements crucial point facts person life selected organized presented meet compression quality reach computers kinds
245	lingo redwoods initiative seed activity design development new type treebank medium large scale treebanks exist english pre existing publicly available resources exhibit following limitations annotation mono stratal encoding topological tectogrammatical information depth linguistic recorded comparatively shallow format representation hard small predefined range ways extracted representations static evolution tend fall field aims novel treebanking methodology rich nature dynamic data retrieved varying granularity constant regular updating project working build foundations develop basic set tools construction maintenance construct initial annotated trees distributed source license mar systems industry need general parse ranking disambiguation robust recovery techniques observe consensus necessity bridging activities combining symbolic stochastic approaches nlp promising research parsing number frameworks lack appropriately language corpora hpsg likewise focussed extraction applications lacks semantic interpretation designed gap section present motivation
246	paper describes spoken dialog qa substitution centers capable making dialogs fixing speech recognition errors clarifying vague questions based large text knowledge base introduce measures make experimental evaluation shows advantages user input automatic recognizer best candidates confirmation significant parts selection choices cards using confidence retrieval significance result asking final description extraction introduction personal computers encounter troubles consult manuals experts solve solutions problems beginners retrieve proper item available furthermore operation cost problem proposed substitute center operator help substitutable needs first backs needed note inefficient secondly users know clearly realize developed shown figure features follows
247	language text analysis toolset paper gives brief description components comprising including minimalist parser concept learning programs thesaurus constructor automatically computes word similarities based distributional characteristics words parsed corpus resulting similarity database smooth probability distribution statistical models clustering algorithm constructs roget semantic categories unsupervised fashion learner identify similar expressions introduction natural processing syntactic knowledge deeply intertwined acquisition usage goal research build base iterative process involves start parsing large manually constructed extract lexical phrases collocations idiomatic selectional preferences second cycle assistance newly acquired allows better resolve systematic ambiguities removing unlikely parts speech hypothesis result higher quality parse trees turn extraction later cycles demonstrates main consist following broad coverage english called minipar grammar program instead using
248	present architecture integration shallow deep nlp components aimed flexible combination different language technologies range practical current future applications particular high level hpsg parsing performance ranging named entity recognition chunk clause enrich representation natural text layers new xml meta information using single shared data structure called chart details methods extraction checking realworld german benefit grammatical analysis introduction years trend processing argue purposes texts provide sufficient highly accurate useful tasks carried emergence techniques proof utility focus exploit maximum ignoring certain complex issues typically handled systems played significant role area industrial technology suffers insufficient robustness throughput confronted large quantities unrestricted extractions attempt exhaustive aspects try analyse understand passages contain relevant speed wrt nl exactly counts explicitly defined means detailed domain specific lexical entries rules perform required
249	based machine translation adaptations enhancements create chineseenglish hong kong legal code various bilingual resources available linguistic data consortium background chinese english ebmt software experiments described shallow function using sentence aligned dictionary given sufficient parallel text extracted statistically corpus perform program looks matching phrases source language half performs word level alignment entries containing matches determine portions input generate translations phrasal glossary gaps selection best guided trigram model target supporting required number changes training procedures discussed section segmented individual words initial baseline segmenter ldc frequency list make segmentation decisions provided large completely cover vocabulary result sentences incorrect segmentations included
250	present machine learning framework resolving anaphora morpho syntactic recency semantic features based existing lexical knowledge resources algorithm obtains additional web search lexico patterns specific anaphors incorporating innovative feature leads percentage point improvement classifier measure soviet cities refers set excluding moscow rephrased schools mentioned university risk factors mr company designer age contrast list contexts antecedent available anaphorically structurally left conjunct anaphor research shows relieve symptoms children focus cases section describes corpus approach using naive bayes different sets first includes standard string comparison evidence play smaller role heads pronominal instead large diverse world necessary understand city universities informally called american english viewed factor add extracted wordnet named entity recognition antecedents
251	word extraction important tasks text information processing mainly kinds measures internal measure contextual paper discusses chinese first widely adopted tested compared individual basis various schemes combining tried improve performance finally left right entropy integrated effect genetic algorithm explored automatically adjust weights combination thresholds experiments focusing character promising result mutual powerful best scheme achieves integration introduction new words generated rapid development society resulting lexicon meet requirement natural language extract immense collection problem task extracting multi characters texts similar phrases english regard research phrase carried extensively currently mainstream approach statistic based general estimating soundness extracted item estimates associative strength constituents listed including frequency selectional association symmetric conditional probability dice formula log likelihood chi score
252	approach aimed reducing ort skill involved building spoken language interfaces applications created specifying relatively small set utterance action pairs grouped contexts intermediate semantic representations speci cation rmation requests dialog constructed automatically properties variant transduction arise combining techniques paraphrase generation classi provide experimental results varying number build particular application developing non trivial interactive currently requires signi person months major coping variation input users handling write large natural grammar manually hope coverage su cient multiple create simulation intended introduction record interacting recordings transcribed annotated information relating domain transcriptions annotations statistical understanding model guidance manual development mixed initiative systems involves design pass data processing components response tend makes di cult port new domains machine learning extensive furthermore
253	current alternatives language modeling statistical techniques based large amounts training data hand crafted context free finite state grammars build maintain way address problems grammar approach compile recognition written expressive formalism theoretically straight forward compilation process exceed memory time bounds result accurate efficient speech evaluate approaches problem additional reduce structural ambiguity model difference availability research systems achieve impressive performance using models trained domain targeted domains sufficient available unavailable explored relevant designed new functions human analog interaction cases commercial developers impediment collecting expense required collect corpus prohibitive existence atis database doubt factor popularity travel community exactly reason major finitestate tedious quickly scope increases write
254	paper focuses transformation grammar checking technology learning environment second language writing starting point checker swedish called studies conducted aimed exploring support context first study developed methodology impact writer text interested earlier work educational setting problems alarms limited recall definitely sensitive issue learners settings teachers concerned perfectly working analyzers new strategies dealing explored interaction highly confusing introduce program able detect correct furthermore emergence make learner shifts attention situation energy eventually correcting reflecting according getting conception reviewed authentic development tools vision guiding idea studying developing help writers reflect
255	paper propose adding term grammatical information sentence entropy language model order improve performance added features obtained stochastic context free grammar finally experiments using penn treebank corpus carried significant improvements known history effort modeling techniques directed es defined expression named conditional principle determination probability expensive possible number word sequences great traditional models assume depend entire limited equivalence relation rewritten introduction important component computational applications speech recognition automatic translation optical character retrieval statistical gained considerable acceptance efficiency demonstrated fields applied calculate chain rule work partially supported spanish contract granted universidad del commonly gram reduced resides training data simple formulation implementation provided words predict makes local
256	assuming goal person query references particular argue derive better relevance scores using probabilities derived language model personal names corpus based occurrence frequencies inverse document frequency present method calculating match probability directory legal professionals compare idf predict search precision word proximity queries major baseball players results predictor indicate rare high virtual tags identify effective collocation features professional class occurred documents john smith referred majority leader mapped different people surprising experience know uncommon common evidence predicts argued intended measure relative ambiguity standard probabilistic engines degree terms phrases collection reason
257	paper investigate task automatically identifying correct argument structure set verbs verb allows predict relationship syntactic arguments role underlying lexical semantics following method described exploit distributions selected features local context extracted word wsj corpus based speech tags phrasal chunks constructed decision tree classifiers trained data best performing classifier achieved error rate work shows subcategorization frame learning algorithm previously applied czech extract sfs english evaluated classifying alternation classes differ previous studies minimally annotated construct passed ofspeech tagger chunker identify base categories noun phrase potential knowledge acquisition plays important nlp selectional preferences frames corpora various tasks fine grained distinguish kinds select consider finding relate observed list particular involves roles
258	mechanism interpretation arguments cope noisy conditions terms wording beliefs argument structure achieved application minimum message length principle evaluate candidate interpretations receives input quasi natural language propositions presented english generates form bayesian network performance evaluated feeding cases produced matched precisely representation original introduction paper focus argumentative discourse composed implications present nl based evaluation provides uniform incremental framework combining uncertainty arising different stages process enables factor elements rely particular knowledge tested networks logic representations future figure shows simple subset research supported australian council grant bn contains preferred obtained web interface seen differs structurally addition belief value
259	billion base pair sequence human genome available attention focusing annotating extract biological meaning discuss obtained methods analyse sequences particular approaches using stochastic grammars analogous computational linguistics gene finding protein family classification
260	argue verbal patient diagnosis promising application limited domain speech translation architecture designed type task represents compromise principled linguistics based processing hand efficient phrasal propose demonstrate prototype instantiating built source regulus platform translates spoken questions symptoms english japanese using vocabulary words introduction motivation language crucial medical initial evaluation emergency department obtaining accurate history chief complaint equal importance physical examination parts world large recent populations require care unable communicate fluently local especially likely facilities insurance issues setting acute need quick pointing area body clearly constraints sufficient way useful tool basic philosophy attempt intelligent fixed phrase linguistically motivated grammar translator run time behaves essentially allows variation input spirit approach normal books typically allow slots phrases order minimize
261	propose hidden markov models unsupervised training extractive summarization selects salient sentences documents included summary clustering combined heuristics popular approach annotated data required conventional methods means text cohesion consideration probabilistic rigorous robust require supervised method incorporates framework modified yields optimal clusters modeled transition probabilities hmm term distribution emission final decoding process tags theme class labels parameter carried segmental algorithm output extract summaries topic detection content based evaluation shows outperforms existing summarizer terms relative similarity baseline introduction multi document collection related application includes news story different sources tracking stories single source time frame case extension domain independent approaches extraction shallow automatically extracted form directly
262	multimodal dialogue systems allow users input information multiple modalities handle simultaneous sequential composite different coordination schemes require capture collect integrate user respond joint interpretation performed study understand variability evaluate methods perform collection enhancement form incorporation dynamic time window fusion module proposed enhanced provides superior temporal characteristics robustness compared previous restrictions available imposed application flexibility ways coordinate inputs pose problem determining period completed turn method windows address issue allows modality order delay end motivation introduction providing needs interpreted combined proper understanding timing considering sequentially simultaneously consist leading large number deal complex determine suitable unlikely receive indicate determination
263	conventional information systems cater temporal reason useful capture maintain knowledge associated action paper propose model organize relations embedded chinese sentences kinds event expressions accounted single multiple events declared experiments conducted evaluate mining algorithm using set news reports results signi error analysis performed opening new future research introduction extraction upcoming challenging area cope increasing volume unwieldy distributed resources www regarded equally important piece domains task extracting tracking time occurs frequently planning scheduling question answering simple explicit direct expression written language company closed left implicit recovered readers surrounding texts know fact earthquake knowing exact bankruptcy relative precise unavailable typically determined human account properly restrictive hard separate discovery natural processing english tenses aspects di erent verb forms elements sentence expressing reference transforming situations logic operators
264	present rate principle governing language generation implies local measures entropy increase sentence number demonstrate case measuring different ways effect lexical non causes speech random variable deal unit text person produced previous words stream likely produce variables distributions obviously depend claim average related work introduction known information theory efficient way send noisy channels constant humans try communicate obey communication medium examine paper evidence holds measure first proposed shannon informally proportional difficulty correctly guessing value highest values equally probable lowest choices probability deterministically advance concerned english exhibited written results easily extended community inspired distortion audio signal
265	approach named entity recognition recurrent neural network known term memory applied trained perform passes sentence outputting decisions second pass first acquire information disambiguation self organising map sequences generate representations lexical items presented whilst orthogonal represent speech chunk tags words derived occurrence statistics different form resulting reflect morphology james provide detailed description operates briefly similar manner standard som consists set inputs units unit contains weights equal size number input closest vector chosen processing sequence winning competition subsequent activation decay factor beginning new available activated indicate levels order presentation advantage
266	paper investigates methods automatically infer structural information large xml documents using reference format approach schema generation problem application inductive inference theory doing review extend results relating search spaces grammatical inferences data set evaluate result process concept minimum message length comprehensive experimentation reveals new hybrid method effective finally tractability issues including scalability analysis discussed discusses considerations followed conclusions section previous work introduction given recent emergence problems solved facilitate important involves addressing differences loosely formatted traditional structured clearly ability structure powerful tool bridging gap handled ways advantage flexibility possible approaches correspondingly suitable outcomes reason best firstly derive measure quality inferred dtd seen determining relative utility content models task extends proposed presented following fashion provides details related fields overview solution
267	topic detection tracking approaches monitor broadcast news order spot new previously events track development ones dynamical nature makes state art methods present definition potential model evolving discuss incorporating ontologies similarity measures topics illustrate dynamic hierarchy decreases exhaustive computation performed tdt process mainly work progress import text categorization purpose paper outline main aspects ongoing future empirical motivation organized follows problems section examine definitions event presents novel representation approach measure elements deal hierarchies conclusions place world reported perceive effort deducing continuous stream sense wall analogy given setting trying typically conducted using machine learning taught recognize difference predefined classes categories providing number pre labeled samples learn word frequencies training material
268	paper investigate phenomenon verb particle constructions discussing characteristics availability nlp systems concentrate particular coverage provided electronic resources given constantly growing number combinations possible ways extending available investigated account regular patterns productive verbs particles discuss levin classes means obtain issues involved adopting approach cases compositionally adding specific meaning construction following pattern vpcs subject considerable investigation instance occurs wide range combines productively discusses aspectual kim carried television ate sandwich argument affected contrast suggests action conclusion fraser points semantic properties affect possibilities combining influence follow case glue paste semantically similar objects specified join material combine clearly common thread running list new
269	report project derive word translation relationships automatically parallel corpora effort distinguished simpler faster models previous high accuracy approaches methods achieve translations comparable work previously reported nearly coverage types perform particularly class multi compounds special text parsed logical forms employing source language grammar lexicon constructing form training corpus transfer patterns construct target transformed strings using generation written linguist principal roles played derived discussed paper provide correspondences content lemmas assist alignment process augment lexicons parsing case described section introduction progress aimed learning bilingual simple statistical easier implement run problem overall approach machine deep learned specifically component trained sides produce analysis grammars constructed linguists aligned level stems
270	utility domain ontologies widely acknowledged community barriers overcome practical useful tools important achievement reduce cost identifying manually entering thousand concept descriptions paper describes text mining technique aid ontology engineer identify concepts introduction cooperating work people organizations communicate different contexts backgrounds viewpoints assumptions needs regarding problem jargon terminology confused overlapping evaluation methods mismatched poorly defined consequence lack shared understanding leads poor communication particular solutions involved impacts effectiveness cooperation flaws enterprise organization identification requirements specification inter systems possibility using sharing components goals conceptual terminological confusion achieved properly defining set relevant characterize given application respect thesaurus aims describing terms seen enriched definitions relationships knowledge means richer semantic represented base kb goal description
271	paper reports tool assists user annotating video corpus enables search semantic pragmatic structure gda tagged format allowed patterns plain phrase capable generating timestamped file manually publicly available academic purposes xml tag set adds information syntax semantics pragmatics texts corresponding voice contribute basic research technologies promote application development chapter explains method relates data image introduction achieve natural communication environment computers users interactive prototype systems talk developed using multimodal built achieving free effective ation enhancing automatic learning huge hoped various tv news language teaching materials extracted intellectual content valuable fields machine translation retrieval handling question responses knowledge discovery initiative aims internet authors annotate electronic documents common standard allows machines automatically recognize structures annotated expected emerge serve linguistic corpora worldwide self extending
272	developing dialogue systems complex process particular designing efficient management strategies precise guidelines develop sure test validate suggestions reinforcement learning search optimal strategy specific situations approaches produced interesting results including applications involving real world suffers fact state based words expressed decision table specifying action generality states limits analysis potential paper tackle problem rules generalize readable underlying easier explain investigate capability directing looking generalization whilst proceeds introduction ubiquitous receiving attention define behavior mainly determine badly perceived users generic methodologies exist testing approach wizard oz studies iterative design techniques mixed initiative recent seen walk series
273	present rule based shallow parser compiler allows generate robust language absence training data resorting limited number rules aim identifying constituent boundaries contrast approach approaches parsing evaluation tool english french tasks available domain independent style finally developed using techniques mirror information contained instance trains non recursive np chunks marked able obtain richer categories syntactic functions hand finite state rely development large set capture ways detecting nps write following det adj noun time consuming needs possible rewriting cases pos errors left robustness accuracy suffer regular expressions manipulated transformed automata minimized determinization minimization given costly port tools new change existing paper argue order accomplish task unnecessary develop sets
274	javelin integrates flexible planning based architecture variety language processing modules provide domain question answering capability free text demonstration focus processes questions retrieves likely answer candidates given corpus operation explained depth browsing repository data objects created session web browser justification operator models model process history results analyzer retrieval strategist information extractor generator gui planner dialog response execution manager figure controls individual components introduction simple factoid answered reasonably using pattern matching systems surface patterns enhanced semantic categories types order likelihood answers furthermore hovy obtained pre extracted approaches don represent meaning clear generalized non complex task type availability user needs combination techniques combined dynamically determine optimal powerful control mechanism required lcc implemented feedback loops ensure constraints met retrieving documents expanding terms includes passage loop lexico logic proving ibm combines knowledge agents
275	present design development hidden markov model division news broadcasts story segments topology textual features discussed non parametric estimation techniques employed obtaining estimates transition observation probabilities visualization methods developed analysis performance presented introduction current technology makes automated capture storage indexing categorization broadcast feasible allowing computational systems provide intelligent browsing retrieval stories maybury effective able partition input signal appropriate sequence paper discuss approach segmentation based fine grained generation words produced program critical application obtain robust typically approaches extracting stream likely different boundaries observed span individual berger lafferty boundary decisions predictions range exponential language compare trigram croft utilize local context xu generative figure hmm
276	mechanism generation lexical paraphrases queries posed internet resource generated using wordnet speech information propose synonyms content words statistical obtained corpus rank evaluated answers reside la times subset trec improvement performance document retrieval related research vocabulary mis match user indexed documents addressed query expansion common techniques blind relevance feedback word sense disambiguation consists retrieving small number given constructing expanded includes appear frequently retrieve new set wsd precedes avoid irrelevant mihalcea moldovan machine readable thesaurus specifically obtain sch tze pedersen lin automatically constructed thesauri improvements reported comparable results encouraging experimental indicate ir restricted sensitive errors approach differs approaches form alternative harabagiu
277	large scale parsing complex timeconsuming process infeasible real world applications described addresses problem combining finite state approaches statistical techniques engineering knowledge keeping complexity low possible cost slight decrease performance parser robust fast time based strong linguistic foundations introduction simple extensions interaction dependents mother node second probability model pcfg production vp traditional cfgs dg rules verb subcategorization frames important component trained developed tested collection syntactically analyzed sentences penn treebank broad coverage returns optimal set partial structures fails complete structure sentence designed order useful amounts unrestricted text achieved observing following constraints discussed section using syntactic theory known relatively flat lack nodes relying preprocessing discarding unlikely readings beam search cocke younger kasami algorithm restrictive hand written grammar divide conquer approach level tasks reliably solved handed recognition speech means tagging base nps verbal groups
278	paper investigates application ranked region algebra information retrieval large scale unannotated documents automatically annotated document structure semantic tags using taggers retrieve specifying represented words report kind data retrieved experiments approach introduction structural search structured text reports annotate structures apply ohsumed test collection public field biomedical science tag various corpus implemented ranking model engine preliminary evaluate genia small manually succeeded retrieving relevant answers exact matching fails lack robustness non specification works doesn work section explains query texts
279	present description language sdl offers declarative way specifying new complex nlp systems existing modules help operators sequence parallelism unrestricted iteration given implement minimal interface compiler returns running java program realizes exactly desired behavior original speci cation execution semantics complemented precise formal ned terms concepts function theory sprout shallow platform development processing multilingual resources introduction paper focus general called allows set base assuming initial module implements methods composed realizing parallel potentially self application single communication independent decoupled mediator sensitive connecting simply putting sharing common assumes functionality provide input clear internal state start computation approach permits exible experimentation different software architectures furthermore guarantees independently developed stay integrated worst case needs ed upgraded resp
280	investigate global index grammars grammar formalism stack indices associated productions restricted context sensitive power discuss structural descriptions generate compared generated ligs represent corresponding hpsgs schemas introduction notion mildly sensitivity introduced possible model express required properties formalisms natural language phenomena requires constant growth property polynomial parsability limited cross serial dependencies canonical nl problems exceed free multiple agreements reduplication crossing languages characterized geometric hierarchy levels level considered certain able capture counting proven recognition algorithms time complexity general problem descriptive regarding linear indexed combinatory categorial insufficient proposals extend modify view possibility modeling coordination probably crucial respect alternative showed mentioned generalized forms
281	human tutors detect respond student emotional states current machine preliminary learning experiments involving transcription emotion annotation automatic feature extraction spoken tutoring corpus indicate developing enhanced automatically predict adapt models work addressed detection based educational settings paper positive negative neutral emotions discuss results pilot goal develop computational specific dialogue itspoke called end text atlas types essay answering qualitative physics problem tutor engages provide feedback correct misconceptions elicit complete explanations revises ending causing revision interfaced sphinx speech recognizer stochastic language trained user utterances synthesizer adapting knowledge sources needed components developed set dependent using typed enhance contains dialogues collected web interface supplemented high quality audio link performs task subjects
282	present algorithm improves efficiency search optimally aggregated paragraph summarises flat structured input specification model space possible paraphrases paragraphs sequences compositions set tree adjoining grammar elementary trees transforms equivalent paraphrasing power better computational properties identifies explicit mapping propositions surface realisations associated particular entity essentially list attribute value pairs refer fields attributes field names relationship specified represent relationships values facts slightly complex structure coerced form focus simple case application additionally assume required able summarise subset given record summary include member challenge sort summarisation devise satisfies potentially incompatible constraints first flexible combination expresses second despite large flexibility probably implies capable finding reasonable time contribution work makes algorithms prune terms tag lexicalised version
283	paper presents methods qualitative comparison lexical association measures results obtained adjective noun pairs preposition verb triples extracted german corpora approach compare entire list candidates sorted according particular reference set manually identified positives estimates large number double occurrences inferred random samples introduction computational linguistics variety proposed identifying associations words tuples text range pure frequency counts information theoretic statistical significance tests mathematical properties extensively discussed strategies employed evaluating identification adequate crucial unsolved issue collocation treatment data first specify requirements evaluation mea instance based introduce experimentation procedure discuss widely ams finally handling low suggested mutual log likelihood ratio test occurrence applied sets section description base best supplemented precision recall graphs complete comprising strata examined
284	reducing language model size critical issue applying lm realistic applications memory constraints paper measures studied purpose pruning probability rank entropy evaluated performance criteria real application chinese text input terms character error rate first present empirical comparison showing performs best cases high lies strong correlation novel method combining experimental results combined criterion consistently leads smaller models pruned using separately cer introduction backoff gram large vocabulary speech recognition typically trained corpora practical techniques produce smallest keeping loss small possible research focused development estimate traditional count cutoff based absolute frequency recent shown better developed sophisticated perplexity study
285	paper presents results acl sighan sponsored first international chinese word segmentation bakeoff held reported conjunction second workshop language processing japan motivation contest report analyze make recommendations future introduction problem received attention literature reviews various approaches hard compare systems lack common standard test set approach promising based published nonetheless fairly tested selected corpora single accepted including standards evaluation number contests recent years china context general evaluations chineseenglish machine translation third segmented according national gb granted case plausible alternative segmentations specifies allowed accuracies mid participated higher scores motivations holding current twofold
286	present new speech tagger demonstrates following ideas explicit preceding tag contexts dependency network representation broad lexical features including jointly conditioning multiple consecutive words effective priors conditional loglinear models fine grained modeling unknown word using resulting gives accuracy penn treebank wsj error reduction best previous single automatically learned tagging result introduction approaches sequence problems partof unidirectional approach inference regardless hmms maximum entropy techniques decision trees systems work direction exceptions brill transformation based learning known successful recent years seen chaining scores decisions successive local form global model entire clearly identity correlated past future tags identities case influence explicitly considered point left right first order hmm current predicted backward interaction shows implicitly later generated turn able capture directions reasons advantageous make information available
287	using specific newspaper commentary paper explores relationship surface oriented deep analysis purposes text summarization discussion followed description ongoing work automatic understanding current state implementation goal methods shallow exactly needed addition following sample analyse steps knowledge necessary arrive desired result concise summary sketch follows fusing based introduction generally speaking language cognitive agent means reconstructing presumed speaker goals communicating application hard wire aspects reconstruction process interesting complexity acknowledged paid attention moving individual utterances connected discourse additional problem arises partitioning material segments inferring connections recent years approaches rhetorical parsing proposed try recover structure general layout theory starting idea imagine push bit understand effect produce topic figure shows german
288	introduction past years great number spoken dialogue systems developed typical task domains include airline information train model speech understanding process converting recognition results semantic representations equivalent database query commands disambiguating slots ned priori manually approach workable data structure application organized typically relational di erent exible needed interfaces access described rigid format particular normal text purpose retrieval technique useful nd list matching documents input keywords extracted statistical performed routing regarded special case ir candidates obtained result signi problem user intended item especially telephone electrical appliances large screen displaying presented desirable narrow interactively interactive friendly novice users requiring detailed beginning paper address strategy retrieved initiated spontaneous utterance section method generate guiding question using restaurant
289	paper presents named entity classification orthographic contextual information random method employed generate refine attribute models supervised unsupervised learning techniques recombination produce final results introduction commonly considered main tasks recognition features best classify words according somewhat disparate separated sets divided subsets sub grouping attributes instances multiple classifying processes increase overall accuracy shown propagate errors importantly decision regarding separation various manual task reasonable assume different relative levels significance languages using division optimal limited users knowledge subsequent subgroups treated meta sons names chosen assigned randomly evolved gradually generalisations inferred naming certain types relating abstract connotations word infer structure emergent stretches time set constraints stem language possibly representing
290	computational learning natural language attempted using knowledge available research areas psychology linguistics lead systems solve problems theoretically practically useful paper present aims learn syntax way computationally effective psychologically plausible perform task unsupervised applied corpus declarative sentences penn treebank shown comparatively respect significantly supervised somewhat simpler principle significant overlap perspectives common wish frequently humans especially setting annotation training perspective annotated resources general large amounts unannotated text desire able extract grammars meaning given wise investigate know human approach solving work seeks maintain psychological build represent syntactic categorial grammar formalism section introduce cg aim define problem
291	report evaluation results summarization analyze resulting data different types corpora develop robust created based sentence extraction applied summarize japanese english newspaper articles obtained workshops lectures evaluated addition relationships key sentences features discrete combinations match distributions better sequential speech corpus comparable written means worth analyzing main methods required reduce size document proposed method integrating positions frequencies words article order extract manually assigned parameter values integrate estimating significance scores hand machine learning training kupiec aone bayes rule lin nomoto matsumoto generated decision tree svm paper using analysis gives indication combine introduction ultimate goal create handle
292	link detection regarded core technology topic tracking tasks new event paper formulate story information retrieval task hypothesize impact precision recall systems motivated arguments introduce number performance enhancing techniques including speech tagging similarity measures expanded stop lists experimental results validate hypothesis introduction research sponsored darpa translingual extraction summarization program related organizing streams data newswire broadcast news segmentation detects stories linked discuss plane crash victims considered contrast hurricane andrew different events discusses previously unseen groups performing tdt based findings incorporated ideas baseline cmu better compare seen cluster clusters ned improved developing separate
293	fuf rf qq qd td distance type dd wd eq ey yy
294	discovery semantic relations text increasingly important applications question answering information extraction summarization understanding detected checking selectional constraints paper presents method results learning detect validity tested sentence corpus targeted accuracy dan moldovan human language technology research institute university texas hlt edu allows systems address questions components need identify entities synthesize gathered multiple documents knowledge intensive techniques augment statistical methods building advanced nlp provides deriving necessary discover semantics relation different ways refer led researchers claim meronymy complex treated collection single based linguistic cognitive considerations way parts contribute structure determined types component integral object portion mass stuff feature activity place area wordnet classified basic member grouped general
295	present paper technique allowing choose parsing granularity approach relying constraint based formalism main advantage lies fact linguistic resources method useful particular systems text speech need simple bracketing cases requires precise syntactic structure illustrate comparing results different levels figures respective performance tagged corpus introduction nlp applications make shallow techniques rely deep analysis relies stochastic methods later symbolic ones constitute problem needing occasions typically case parsers order calculate groups basis units superficial information solution consist using constructions exists implementing require treatments second entire job precisely imagine generative framework implement capable calculating chunks phrases possible embedded organization constraints constitutes answer allows resource fully partially
296	propose multilingual approach characterizing word order clause level means realize information structure illustrate problem languages differ degree freedom exhibit czech free language variation pragmatically determined english fixed primarily grammatically german scale work theoretically rooted previous structuring prague school framework systemic functional notion theme present implemented kpml different wo properties algorithm specific combines idea constraints posed grammar complementary mechanism default ordering based applied systems allow multiple sources speaker employs indicate parts sentence meaning context dependent affecting inherent aspect contributes important way overall coherence text commonly accepted major source organization given content particular linear natural generation explicitly models relation practical perspective employed fuf realpro product grammatical choices fine
297	paper presents statistical approach automatic building translation lexicons parallel corpora briefly pre processing steps baseline iterative method actual algorithm evaluation algorithms presented terms precision recall time conclude presenting applications multilingual extracted described introduction scientific technological advancement domains constant source new term keeping lexicography areas unless computational means based equivalence relation lexical knowledge sources texts limited human resources appear different corresponding printed meant users known reasons differences discuss issue exactly make useful experiments automatically modern approaches extraction equivalents rely techniques roughly fall categories hypotheses testing methods gale church smadja melamed generative device produces list candidates segments subject independence test association measure higher expected assumption assumed pairs independently process characterized local maximization estimating
298	paper presents method implicitly resolve ambiguities using dynamic incremental clustering korean english cross language information retrieval framework propose query first translated looking dictionary documents retrieved based vector space terms ranked oriented document clusters incrementally created weight calculated experiment trec clir test collection achieved performance improvement queries ambiguity resolution corresponds monolingual original combine outperforms introduction describes applying implicit context weighting ranking enables users retrieve written different methods fall categories statistical approaches translation establish lingual associations require large scale bilingual corpora approach possible high quality machine systems available practical dictionaries multilingual ontology thesaurus researches adopt simpler given wide availability order achieve necessary solve problem increased
299	recent years saw increased construction large corpora awareness expansion application knowledge acquisition bilingual terminology extraction present paper seek approach lexicon non aligned comparable combination pruning evaluations crosslanguage information retrieval propose explore stages translation model disambiguation selection best alternatives basis morphological using scale test collection japaneseenglish different weighting schemes smart confirmed effectiveness proposed linguistics based introduction researches corpus approaches machine rise particularly promise provide enrich lexical resources dictionaries thesauri generally rely text play important role natural language processing given special enrichment unlike parallel collections texts pairs languages contrasted common features topic domain authors time period property abundant expensive accessible world wide web concerned exploiting scarce cross clir consists retrieving documents written queries conducted ntcir data
300	supertagging tagging process assigning correct elementary tree ltag supertag word input sentence paper propose supertags expose syntactic dependencies unavailable pos tags first novel method applying sparse network winnow sequential models construct supertagger distance syntactical achieves apply np chunking gives rise absolute increase score transformation based learning frame described provides effective efficient way exploit information introduction lexicalized adjoining grammar associated following facts make attractive firstly encode makes useful pre parsing tool called mean parser assign hand term suggests time complexity similar linear length focus task application proposed phase model includes attaching approached using machine techniques successfully applied tasks regularized svms crfs maximum entropy
301	present noun phrase coreference extends work soon knowledge produces best results muc resolution data sets measures respectively improvements arise sources extra linguistic changes learning framework large scale expansion feature set include sophisticated lean manner algorithm access surface level features paper presents np investigates types extensions corpus based approach first propose evaluate modifications machine provide substantial statistically significant gains precision second attempt understand incorporating additional improve performance expand arguably deeper lexical semantic notably grammatical variety constraints preferences similar explored context pronoun lin previous treats broadly applicable hard information represented contrast incorporate selectively universal using expanded mixed drops significantly algorithms investigated built selection mechanisms demonstrate em introduction refers
302	sources training data suitable language modeling conversational speech limited paper supplemented text web filtered match style topic target recognition task possible bigger performance gains using class dependent interpolation grams introduction models constitute key components modern systems ngram model commonly type requires large quantities matched terms tasks involving ideal material transcripts costly produce limits currently available methods developed purpose adaptation existing new topics domains domain contain relevant irrelevant information various identify portions prior combination past work pre selection based word frequency counts probability sequences latent semantic analysis retrieval techniques clustering defining subsets test set perplexity prune documents corpus common method additional train separate small amounts combine referred mixtures technique
303	paper describes construction language choice models microplanning discourse relations natural generation attempts generate appropriate texts users varying levels literacy consist constraint satisfaction problem graphs derived results corpus analysis based written readers adapted poor allowing certain constraints psycholinguistic evidence design microplanner evolving discuss compromises involved generating readable textual output implications nlg architectures finally plans future work using definition relate readability performance reading task measured first preliminary experiments tested outputs girl sally test spelling finished need practise spell longer words click necessary people learning hard skills improve introduction generator individual generates feedback reports adults web assessment inputs answers questions currently report skill tests generated shown figure developed aim tailoring particular
304	paper presents semi automatic construction method practical ontology using various resources order acquire reasonably limited time manpower extend thesaurus inserting additional semantic relations hierarchy classified case obtained converting valency information frames previously built computational dictionaries machine translation acquired concept occurrence extracted automatically large corpora stores rich constraints concepts enables natural language processing resolve ambiguities making inferences network based word sense disambiguation achieved improvement methods korean generators share knowledge store different contains independent taxonomic general build high quality base manual indispensable previous attempts performed manually developed considering context situation construct solve problem propose advantage existing usages first define representation modifying suitable design structure defined orl
305	introduction deep linguistic processing produces complete syntactic semantic analysis sentences processes fails producing result structure processed words input fall coverage grammatical resources natural language systems monolithic grammars addition deal huge search space sources non determinism particularly broad uni cation based dimensions information interleaved theories hpsg propose lack robustness cient make inadequate practical applications interfaces paper presents nlp integrates speech tagger chunker preprocessing module grammar spanish integrating shallow overall process improves signi release parser certain tasks reliably dealt computationally expensive techniques integration provides larger structures allows implement default lexical entry templates virtually unlimited avoiding increase ambiguity present inspired accordance following section describes discusses extensions required order transfer delivered entries ned results performance provided papers ends
306	qcs information retrieval presented tool querying clustering summarizing document sets developed modular development framework facilitates inclusion new technologies targeting ir tasks details architecture interface preliminary results detailed descriptions weighting factors strategies using current computational methods retrieving set documents best match query topic creating summary multiple follows latent semantic indexing means summarization hidden markov model respectively consists collection format input output dynamic html approach allows computation formatting place server requirement users systems enabled browser application introduction software efficient organized generic designed relevant cluster resulting subset produce single redundant user reduced categorized content survey previous work combination improve radev
307	rapid growth real application domains nlp systems genuine demand general toolkit programmers linguistic knowledge build specific provide interface accept sample sentences convert semantic representations allow map domain actions order reduce workload managing large number forms individually perform grouping organize meaningful groups paper present methods verb based category implementation discuss pros cons method utilized according different needs introduction motivation improvement natural language processing speech recognition techniques spoken input choice software user interfaces way communication mean time especially handling grown rapidly recent years develop handle problems accurately generate ends new existing applications using program methodology programmer specify set corpus task meaning
308	develop framework formalizing semantic construction grammars expressed typed feature structure logics including hpsg approach provides alternative lambda calculus maintains desirable flexibility unificationbased approaches composition constraining allowable operations order capture basic generalizations improve maintainability signs index functioning somewhat variable similar large number implemented fairly early ways easier work based great advantage allowing syntax semantics interface easily problems specified terms tfs logic interpretation relies intuitive correspondence conventional logical representation spelled furthermore tightly constrained instance principle stop process accessing arbitrary pieces conceptually guarantees grammar monotonic mean rule application content daughter subsumes portion mother makes impossible guarantee certain generation algorithms effectively finally theoretical perspective clear substantive missed minimal recursion egg specification enforces accumulation making rules daughters fully spec introduction constraint formalisms incorporate
309	theoretical concepts semantic type coercion instead utilize occurrence frequencies corpus predict metonymic interpretations roughly acquire ranked set enjoy ing book construction estimating probabilities enjoyed books estimate basis appearing complement object similarly verb subject fast plane likelihood seeing vs quickly results meaning differences adjective associated different nouns derive account vendler observation cluster meanings single noun combination given verbs adjectives evaluate comparing model predictions human judgments ranking correlates reliably intuitions limited scope suited interpretation wellformed constructions distinguish odd metonymies acceptable ones cases paraphrases generated principle particular learn conventional constraints event duration argument potentially captured indirectly constraint right referring attested according won possible paraphrase
310	generation consider first term extraction basic preceding tasks automatic potential application indexing book reviews indices document collection navigation compiling controlled vocabulary terminologies medical coding applications papers address topic generically review paper current systems including known lexter fastr termight terms giving brief description contrastive analysis lee chen addresses problem incremental update domain specific chinese lexicons line news sources identified allocated real time corresponding categories using highly efficient data structures called pat trees acceptable lexicon complete significant supplies linguistically interesting tional adjectives signals french scientific text contrasting production type construction relational frequently signal goes technique identifying based looking paraphrases adjective noun expressed prepositional phrase complement preposition nominal form extends earlier work recognition intuitions role context termhood candidate local likely
311	present paper method achieving integrated way tasks topic analysis segmentation link detection combines word repetition lexical cohesion stated collocation network compensate respective weaknesses approaches report evaluation corpora french english propose measure specifically suits kind systems introduction aims identifying topics text delimiting extend finding relations resulting segments raised important largest dedicated called linear tdt initiative addresses mentioned domain dependent viewpoint necessarily implement work categorized according knowledge achieve rely intrinsic characteristics texts distribution linguistic cues applied restriction domains low results doesn characterize topical structure surface clues exploit independent words built dictionary large set collocations collected corpus overview accordance discourse processes linearly detects shifts finds links delaying decision account analyzed window current
312	main area paper concerns neural methods mapping scientific technical information assisting user carrying complex process analysing large quantities procedure analysis domain patent complexity studied topics accuracy question answered lead analyst partition reasoning viewpoints classical tools manage global way tool considered study core model represents significant extension som based introduces concepts dynamics multi maps displays communication dynamic exchange exploited order perform cooperative deduction different analyzes performed data demonstrates efficiency viewpoint oriented compared patents objective subjective quality criteria account evaluation experimental context constituted database related oil engineering structure field semantics firstly generate corresponding areas analysts experiment selected correspond advantages titles indexing vocabulary automatically extracted textual contents text resulting
313	investigate performance structured language model terms perplexity components modeled connectionist models distributed representation items history make better contexts currently interpolated inherent capability fighting data sparseness problem growth size context length increased trained em procedure similar previously training slm experiments significantly improve ppl upenn treebank corpora interpolating baseline trigram using hidden events obtained parser statistical machine translation crucial component searching prohibitively large hypothesis space state art systems gram simple effective time smoothing techniques probability estimation proposed studied literature recent efforts various ways information longer span captured normal syntactical available word based stochastic parsing build parse trees input sequence condition generation words lexical capture useful hierarchical characteristics
314	paper presents recent developments indexing technique aimed improving parsing times methods exist serve purpose rely statistical data collected lengthy training phases goal obtain reliable method exhibits optimal efficiency cost ratio processes focus static analysis grammar received attention years computational linguistics organized follows first problem introduced followed description general strategy chart second detailed overview performance structure grammars presented finally conclusions future work outlined techniques timeconsuming operations retrieval categories look process retrieved category match daughter large scale cfgs position contain smaller unification costly mentioned reduces number unifications needed research require development time spent entire edit test debug cycle important needing considerable gathering burden better efficient current reduce means filtering unnecessary using index advantage
315	communication behaviour affected emotion discuss dialogue participants expressions manifested content keywords emotions annotation effects introduction fundamental stage research conducted human machine fortunate access valuable corpus dialogues nurses patients comprising utterances contain genuine emotional speech form ideal basis studies realistic conversational state affects way propose annotating alongside currently annotated phenomena reveal interesting useful correlations improve understanding benefit natural language applications overall aim develop scheme create containing study participant communicative motivated observations consultation described naturally occurring unusual circumstances consultant goal elicit concerns patient high level read analyst eye apparent certain analysis community changing grounding discussing subject feel increase number clarification requests repetitions look doesn
316	previous work minimizing weighted finite state automata limited particular types weights present efficient new minimization algorithms apply generally simpler fast point theoretical limits characterize kind behaved weight semirings methods defined finding minimum number states general np complete introduction known efficiently minimize deterministic automaton sense constructing recognizes language original possible arcs useful saving memory building large deploying nlp systems small hand held devices built complex regular expressions savings considerable especially applied intermediate stages construction smaller intersected faster computational linguistics community turned attention compute interesting functions input strings traditional returns boolean set indicates accepted probabilistic probability equivalently negated transducer output string mohri log probabilities cases central speech processing kinds formulation permits
317	natural language processing applications require semantic knowledge topics order possible efficient developed acquires automatically text segments using unsupervised incremental clustering method approach important problem consists validation learned classes applied needs know number build subset reformulate evaluation comparing classifications established different criteria compare based words class descriptors thematic units first results lead great correlation tagged corpus learning set generally adopted systems participating trec tdt wanted design allowing work domain restriction subjects represented recognized texts grounded conceptual segmentation divides lemmatized aggregates similar aggregation associating weight according occurrence represents importance word relative described topic aspect allows augment treating successive corpora existing possess
318	paper present novel customizable paradigm advantage predicate argument structures introduce new way automatically identifying central based extended set features inductive decision tree learning experimental results prove claim accurate enable high quality defined market changes source slot fillers change pri instrument london gold fell current value location daily time report figure filled information event successful techniques built domain relevant linguistic patterns select verbs matched documents extracting handcrafted acquired rich literature covers methods acquiring recent reported process texts efficiently fast ideally implemented finite state automata methodology pioneered fastus simple elegant disadvantage easily portable contrast truly independent designed know predicates introduction goal extraction tasks provide level indexing news stories including wire radio television sources context purpose hub evaluations capture classes events
319	paper describes new features cross language information access first feature partial disambiguation function bi directional retriever search request translation ir advantage black box machine approach consistent test collections permutations english japanese second performs interactive summarisation retrieved documents based semantic role analysis illustrate usefulness evaluation results precision high outputs ranked list target evaluated using metrics average clir solves barrier problem user express need probably make written deserves attention subsumes provides useful source integrates retrieval support bidirectional enhancing performance traditional sense mt systems accesses internal data structures commercial multiple candidates terms present positive introduction received
320	paper applies maximum entropy models task named entity recognition starting annotated corpus set features easily obtainable language first build baseline ne recognizer extract entities context information additional data turn lists incorporated final improve accuracy described avoids relying dependent knowledge instead remainder organized follows section outline framework specify experiments training search procedure approach presents experimental details shows results obtained english german test sets finally closes summary outlook future work introduction present extracting natural inputs objective given input sequence choose tag highest probability possible sequences directly posterior determine corresponding word assume decisions depend limited window current predecessor tags obtain following second order model additionally requires processing different languages specified submission deadline clinton
321	natural language parsing accurate quick explanation based learning technique speed accuracy declines ebl paper shows loss framework deductive abductive allows extending closure parser present chinese abduction experiments improvements efficiency introduction difficulties general particular local ambiguities words phrases extensive linguistic non knowledge required resolution different approaches provide types offer rich syntagmatic contexts disambiguation richer rule statistical acquire mainly paradigmatic require larger corpora handle unseen events smoothing abstract category labels research carried project integrates nlp technologies platform generalizes compilation time performs similarity fuzzy match runtime techniques computationally demanding effect method systems small acceptable order magnitude computing apart generally recognizes acquires kind texts help couldn improve output learn parse
322	paper describes rapidly interactive translingual retrieval basic functionality achieved new document language single day improvements require relatively modest additional investment applied techniques first search chinese collections using english queries successfully added french german italian achieve capability separation independent components application asymmetric leverage extensive infrastructure translation indexing keywords cross information introduction goal produce systems allow users present retrieve documents languages read focus rapid extending current dependent resource bilingual term list architecture consists main demonstrate effectiveness tasks conclude describing experience adding originally developed asian specific segmentation adopted reasons support query multiple terms simplifies processing second display translated processes machine orders magnitude faster commercial accomplish
323	tractor telri research archive computational tools resources features monolingual bilingual multilingual corpora lexicons wide variety languages language processing key element focal national technology institutions emphasis central eastern european countries hopes complement archives providing service users currently represented existing unique strength lies provided europe role hub network resource creation standardisation distribution links eu non communities user community brings providers academic industrial ongoing relationship designed foster emergence joint projects engineering philosophy accept format distribute form received addition certain standards recommended help offered wish make lack simply pragmatic measure face problems heterogeneity based profound current practice future aims build particularly parallel extracting meaning including bulgarian croatian czech dutch english estonian french german hungarian italian lithuanian romanian russian serbian
324	explore problem single sentence summarisation news domain summary resemble headline generation present singular value decomposition guide theme best represents document summarised doing intuition generated accurately reflect content source paper presents svd alternative method determine word suitable candidate inclusion results recall based evaluation comparing different strategies selection indicate thematic information help improve introduction important generate new scratch resulting occur verbatim instead paraphrase combining key words phrases text precursor first particular case specifically english headlines constructed regard approximation given corpus summaries exist article resembles selecting approach explored number researchers work section existing approaches selected basis criteria acts grammatical preceding chosen purpose
325	meaning representations nlp focus attention thematic aspects conceptual vectors learning strategy relies analysis human usage dictionary definitions linked vector propagation currently doesn account negation phenomena work aims studying antonymy larger goal integration present model based idea symmetry compatible define functions allows construction enumeration potentially lexical items finally introduce measure evaluates given word acceptable antonym term kernel manually indexed terms necessary bootstrapping relationships synonymy hyperonymy explicitly mentioned way globally increase coherence paper function help improve dealing tags definition texts opposite generative text applications ideas research paraphrase summary introduction representation important problem addressed approaches team works disambiguation built automated capabilities supposed encode associated words expressions automatically defines revises according
326	issues description places discussed context logical geospatial theory lies core geologica answers geographical questions based knowledge provided multiple agents outline introduction answered information single source answer deduced sources obvious consult agree conventions nomenclature notation problem determine place corresponds particular apply names coordination carried automated deduction theorem prover operates formal differs search engine instead merely finding list documents vocabulary matches question attempts understand provide developing forced develop systematic ways naming identifying corresponding given descriptions paper first ll present representation discuss mechanisms solution sample mention related work proposed extensions posed subset english translated logic natural language parser gemini form rephrased presented application consists
327	paper proposes hybrid handcrafted rules machine learning method chunking korean partially free word order languages japanese small number dominate performance developed postpositions endings proposed primarily based residual errors corrected adopting memory efficient handle exceptions natural language processing checking estimates exceptional cases revising evaluation yields improvement score various methods lexical information speech grammatical relation neighboring words position plays important role syntactic constraint english successful local appropriate characteristic wordorder weak positional instead constraints overt restrict composition phrases unless concentrate enlarge window hypothesis enlarging size cause dimensionality results deficiency generalization especially provide noun phrase verb respectively simple using rivaling inference models algorithms statistics approximately
328	paper describes evaluation existing technique locates sentences containing descriptions query word phrase experiments expand previous tests exploring effectiveness searching larger document collection results showed working significantly better smaller collections improvement stringent definition constituted correct description devised measure pointed potentially new forms evidence improving location process shown large free text searched experiment performance improved consequently scale conducted phrases world wide web using output commercial search engine locate candidate documents processed locally addition increasing number queries tested different definitions relevance tried rest explains shows expanded followed pointers future work keywords information retrieval descriptive www based composed parts end located holding simply routed returned split term passed ranked
329	experience developing discourse annotated corpus community wide working framework rhetorical structure theory able create large resource high consistency using defined methodology protocol publicly available linguistic data consortium enable researchers develop empirically grounded specific applications introduction advent scale collections marked paradigm shift research natural language processing corpora common languages accelerated development efforts annotation ranges broad characterization document level information topic relevance judgments discrete analysis range phenomena rich theoretical approaches text applied documents primarily identifying topical segments inter sentential relations hierarchical analyses small paper nlp main goal undertaking effort reference essential considerations outset needed consistently nominal fee cover distribution costs describes challenges faced building complexity scope including selection approach training quality assurance resulting contains american english selected penn treebank believe holds great promise
330	treatment questions question answering relies solely information word level recognize desired type locate compose parts answers distributed areas wider window introduction research projects investigated problem automatically simple brief phrasal identifying extracting answer large collection text systems built exhibit fairly standard structure create query user perform ir documents likely contain pinpoint passage candidate common difference lies pinpointing employ based scoring method desirable words texts segments return position giving highest total score content contained variant matches expected variations possible scores multiword phrases gaps range allowed computation works degree limitations satisfactory run factoid qa paper work webclopedia project semantics initially recognizing simplicity power
331	paper explore effects data fusion first story detection broadcast news domain element experiment involves combination evidence derived distinct representations document content single cluster run composite representation consists concept free text using tdt evaluation methodology evaluate number strategies propose reasons shows performance improvements keywords lexical chaining introduction goal monitor reorganize stream stories way help user recognize different events occurred set aspect problem constitutes technical tasks defined initiative given arriving chronological order group articles discuss clarified notion topic differentiating classification retrospective online environment identify novel decision considering documents arrived prior current evaluated forcing adhere temporal constraints real time words make soon arrives input event clustering hand partition clusters related
332	present syntax based statistical translation model transforms source language parse tree target string applying stochastic operations node capture linguistic differences word order case marking parameters estimated polynomial time using em algorithm produces alignments better produced ibm introduction mathematical process statistically modeled automatically corpus pairs tms machine alignment multilingual document retrieval automatic dictionary construction data preparation sense disambiguation programs developing tm fundamental issue applications researchers first described models noisy channel converts sequence words movements translations applied independently movement conditioned classes positions duplication identity details fully criticism style structural syntactic aspects demonstrated structurally similar pair suspected different english japanese incorporate accepts input sentence preprocessed
333	annotation graphs servers offer infrastructure support analysis human language resources form time series data text audio video paper outlines areas common need empirical linguists computational reviewing tools development proposes framework future tool resource sharing based overlap opportunity reuse existing coordinate new initiatives communities share burden results linguistics interacts research teaching additional opportunities natural technology greater access robustness linguistic turn necessary develop technologies discusses application traditionally diverse fields inquiry assumptions needs goals studies introduction despite different methodologies traditions researchers variety core processing speech recognition information retrieval observations performance annotations encoding judgment standards maintaining consistency distributed processes extracting relevant expensive create maintain increasing demand growing number solution expanding created purposes classic switchboard corpus
334	syntax based algorithm automatically builds finite state automata semantically equivalent translation sets fsas representations paraphrases extract lexical syntactic paraphrase pairs generate new unseen sentences express meaning input predict correctness alternative semantic evaluate quality translations market gained memorized impossible infer fact consistent intuition following phrases stock rose prices context paper propose solutions problems problem representation induction enables encode compactly large numbers algorithms derive inputs routinely released conjunction scale machine evaluations multiple english foreign language texts instance given figure induces fsa represents distinct capture fighting battle died killed structural week contexts correct
335	review existing types dialogue managers propose information state approach allow complexity ease portability discuss implementational drawbacks dm work underway develop new resolving introduction spoken systems shown steady improvements recent years continue advancing field direct research reducing tradeoff handle complex interactions easily modified domains simplest finite suitable simple initiated tasks make novice developers create type scale mixed initiative dialogues complicated wide variety possible input known voicexml similar include graduate institute rapid application developer unisys dialog design assistant nuance speech objects swedish commercial sophisticated frame based dms semantic frames containing multiple slots keys hold value conversational partner volunteer request time order filled satisfaction parties task conversation complete supports flexible arbitrary flow control controlled scripts rules certain conditions language tool danish generic
336	word segmentation msr nlp integral sentence analyzer includes basic derivational morphology named entity recognition new identification lattice pruning parsing final produced leaves parse trees output customized meet different standards value combinations set parameters participated tracks bakeoff pk ctb ranked respectively analysis results shows component contributed scores description chinese current standalone segmenter displayed components described input first segmented individual characters looked dictionary containing lexicalized words formed node feature augmented phrase structure rules applied form larger units include derived morphological processes reduplication affixation compounding merging splitting entities person names place company product numbers dates monetary tree reflects history rule application added existing single nodes treated parser internal structures useful various purposes
337	simple unsupervised technique learning morphology identifying hubs automaton purposes hub node graph degree greater create word trie transform minimal identify mark boundary root suffix achieving similar performance complex mixtures techniques introduction recognize morpheme learner seen roots suffixes instance helpful harmful evidence guess words divided help ful harm seeing varying reason prefer division represent language links labeled characters nodes organizing occur specific prefixes boundaries furthermore simplified path compression remove remaining modified produce source described matches intuitive idea allows assemble chaining morphemes representation highlights representing morphotactic information phonological represented economically separate transducer composed searching
338	report experience building statistical mt scratch including creation small parallel corpus results pilot evaluation systems trained sets ca sentences tamil english data apparently output humans knowledge achieve performance rates high accuracy topic identification recall document retrieval question answering collection preparation obtaining web newspapers online editions large international community internet dissemination information initial investigation sites decided download experimental www com news site provides local sri texts translations availability fairly domain allowed train language model encoding tokenization written non latin script schemes exist unicode standard includes set widely practice offer material assume rely special type fonts offered free text identify face attribute html
339	applications natural language processing technologies involve analyzing texts concern psychological states processes people including beliefs goals predictions explanations plans paper efforts create robust large scale lexical semantic resource recognition classification expressions commonsense psychology english text achieve high levels precision recall hand authoring sets local grammars concepts approach performance greater obtained using machine learning techniques demonstrate utility corpus analysis identifying references competitive political speeches history genres common words phrases refer mental broad range reason day understanding human studied fields terms theory mind set everyday reasoning abilities field computational linguistics study received special attention generally viewed conceptual areas addressed building resources number projects included larger berkeley framenet project attempted degree breadth depth sorts
340	objective paper present new dimension game theoretic semantics using idea coordination problem explain metaphor metaphorical expression man wolf contradictory statement objects set falls study intentions language intended effect conditions lead effects tradition rhetoric aristotle natural characterize approach pragmatic late th century paradigm linguistics syntax pragmatics called tension thoughts oped possible substitute truth conditional explores possibility introduced lewis admits plurality meanings introduction search human presupposes means falling category fall priori way easily imagine situations meaningful sue went party friend knew
341	paper address problem combining language models simple interpolation methods log linear improve performance fall oracle knows reference word string selects best list strings obtained using different lm actually acts dynamic combiner hard decisions provide experimental results clearly need model combination suggest method mimics behavior neural network decision tree amounts tagging lms confidence measures picking hypothesis corresponding report significant perplexity improvement moderate increase semantic accuracy level dialog context dependent semantically motivated grammar based statistical modeling learning data generic steps followed preparation training selection type specification structure estimation parameters introduction essential speech recognition understanding systems high mention robustness portability proposed studied past decades turned task beat standard class grams great deal promising approach limited domain applications phrase stochastic
342	paper investigate practical applicability training task building classifier reference resolution concerned question significantly reduce manual labeling work produce acceptable performance apply problem german texts tourism domain order provide answers following questions labeled data required achieving reasonable introduction major obstacle natural language processing systems analyze utterances need identify entities referred means referring expressions pronouns definite noun phrases prominent supervised machine learning algorithms pronoun results nps fairly deficiency approaches unknown annotated optimal researchers nlp began experiment weakly applied document classification namedentity recognition phrase bracketing statistical parsing first discuss features relevant feature set using briefly introduce paradigm followed description corpus annotation way prepared binary algorithm section specify experimental setup report
343	van der sandt geurts forward extensively applied notion fundamental identity presupposition anaphora universal consensus developed view basically correct supposing entails empirical hypothesis number facts remained paper presents argues differentiated notions fruitful research semantics pragmatics interface introduction said follows reasonably relation rough general sense called stay level turn relations theory yields certain technical advantages treatment implemented discourse representation argue despite progress relationship actually understanding phenomena time empirically wrong respect linguistic data start problems fairly assuming intended consequences refer following
344	information extraction wants make results accurate resort increasingly coherent implementation natural language semantics paper focus semantic case roles texts setting essential theoretical framework argue possible detect basis morphosyntactic lexical surface phenomena concise overview methodology preliminary test confirm hypotheses introduction currently receives large research traditionally associated verbatim domain specific free text input documents scanned relevant elements particular topic slots predefined frame types systems try acquire knowledge automatically detecting syntactic manually annotated techniques inherently limited exclude understandable reasons efficiency restricts algorithms possibilities fact identifying earliest notable accounts doubt charles fillmore article fundamental argument notion connected realisation syntactico categories deep structure determine distinctive functional patterns considerable likely universally valid realized
345	introduction
346	study problem learning recognise objects context autonomous agents cast object recognition process attaching meaningful concepts specific regions image words given set images captions goal segment intelligent naive fashion proper mapping paper demonstrate model learns spatial relationships individual provides accurate annotations allows perform respects real time constraints mobile robot introduction writing hope promote discussion design agent semantic associations environment precisely associate discrete region labeled concept appropriate consistent say recognised laboratory prototype ideas presented extend wide variety settings proceed elucidate requirements achieving primarily need paired user input formally task function separates space descriptions nw total number figure left collect data right captured lab labels
347	known annotation language resources significantly raises potential enables development common technologies despite fact increasingly complex linguistic information added biomedical texts standard solutions proposed encoding paper describes standardised xml tagset annotated corpora based text initiative guidelines general ground discussion genia corpus currently contains abstracts medline database hand terms marked semantic class accompanying ontology introduces tei implements conversion number aspects discussed tokenisation prevalence linkage ontologies base case encoded project markup dtd encode scheme specify constructive mapping original developed xslt transformation motivations designed widely accepted architecture annotating porting projects gain new insights possible practices maybe make better suited interchange fully automatic need abandon format
348	set supervised machine learning experiments centering construction statistical models wh questions built shallow linguistic features employed predict target variables represent user informational goals report different aspects predictive performance including influence various training testing factors examine relationships introduction growth popularity internet highlights importance developing machinery generating responses queries targeted large unstructured corpora time access world wide web resources numbers users provides opportunities collecting leveraging vast amounts data activity paper research exploiting collected logs order build infer techniques posed based encyclopedia service focus analyses complete phrased english obtained natural language parser decompose type information requested topic focal point additional restrictions question level answer term aim project predictions enhance answering systems
349	paper proposes novel method extract paraphrases japanese noun phrases set documents proposed consists steps retrieving passages using character based index terms given phrase input query filtering retrieved syntactic semantic constraints ranking grammatical forms experiments conducted evaluate years worth newspaper articles accuracy needs improved fully automatic paraphrasing past approaches deal variations linguistic expressions studied various applications natural language processing machine translation dialog systems qa information extraction defined process transforming expression keeping meaning intact define means core definition basis consider different denoting crucial question finding automatically research types clues tried assuming sentences sharing named entities similar structure likely barzilay mckeown assume translations original text contain subcategorization verbs paraphrase construction np relative clause previous work corpus approach notable exceptions katz particular
350	statistical nlp systems frequently evaluated compared basis performances single split training test data results obtained using subject sampling noise paper argue favour reporting distribution performance figures resampling number additional information distributions make statistically quantified statements differences parameter settings corpora classifier better given adequacy trained dataset adequate analysing features indicative comparing sets different set improves result case answers questions provide useful insight particular sensitivity properties similar reported treatment question presented tests significance fixed related works martin hirschberg provides overview error small samples discusses raised explicitly addressed prevailing evaluation methods means addressing propose experimental methodology recall introduction common practice evaluating
351	stochastic unification based grammars define exponential distributions parses generated unificationbased grammar existing algorithms parsing estimation require enumeration string order determine likely calculate statistics needed estimate training corpus paper describes graph dynamic programming algorithm calculating packed ubg parse representations maxwell kaplan enumerating graphical complexity worst case polynomial key observation using required rewritten max sum product functions exactly kind problem solved models introduction log linear probability incorporate virtually kinds linguistically important constraints equipped statistically sound framework learning abney pointed non contextfree dependencies general probabilistic context free markov branching processes proposed loglinear defining unfortunately maximum likelihood estimator computationally intractable requires depend set strings infinite presumably complex structure johnson observed related tasks conditional given
352	human evaluations machine translation extensive expensive months finish involve labor reused propose method automatic evaluation quick inexpensive language independent correlates highly marginal cost run present automated understudy skilled judges substitutes need frequent bottleneck developers benefit paper viewpoint measure performance closer professional better central idea proposal judge quality measures closeness reference translations according numerical metric mt requires ingredients corpus fashion successful word error rate speech recognition community appropriately modified multiple allowing legitimate differences choice order main weighted average variable length phrase matches view gives rise family metrics using various weighting schemes selected promising baseline section evaluate bleu experiment compare
353	paper presents going research automatic extraction bilingual lexicon english japanese parallel corpora main objective examine various ngram models generating translation units gram baseline model new compared experiment sentences shows chunk bound produces best result terms accuracy coverage improves approximately previously proposed trained using statistical methods machine learning techniques linguistic clues obtained tools prone error partially reliable information usable generation unannotated length dependency linked aim determine characteristics achieve high wide identify limitation section generate explains algorithm pairs sections present experimental results analyze finally concludes introduction developments based mt largely rely available expensive resource monolingual hand seek maximal exploitation knowledge approach greatly recent
354	purely confidence based geographic term disambiguation crucially relies notion positive negative context methods combining measures relevance user query introduction questions standardly handled statistical framework ask absence contextual information probability word refer person organization place alternative exists expect numbers sum strictly appropriate particular disambiguate spatial references natural language text strongly non local character increase background eventually reach point training data parameter low repeatable experiment base probabilities cases effectively stand really judgment paper contained unstructured structured databases automatically processing ambiguous large figure search interface showing results ranked map tion adding dimensions document systems requires new algorithms determining documents clear
355	story link detection regarded core technology topic tracking tasks new event paper analyze retrieval framework examine effect number techniques including speech tagging similarity measures expanded stop list performance present experimental results utility differs consistent analysis separately investigate improving systems common processing models developed tdt share steps includes preprocessing tokenize data recognize abbreviations normalize remove words replace numbers digits add tags tokens stems generating vectors document frequency counts incrementally updated sources stories presented additionally separate term frequencies york times computed cnn incremental compute tf idf vector compared using cosine distance introduction research sponsored darpa tides program related organizing streams
356	present demonstration prototype aimed providing support procedural tasks astronauts board international space station current functionality includes navigation procedure steps requesting list images particular image recording voice notes spoken alarms setting parameters audio volume dialogue capabilities include handling corrections entire context response user request responding help demand partially better efficiency feedback astronaut training personnel added features visual step correction moves intention introduce flight introduction engage wide variety medical procedures extra activity scientific repair maintenance human activities require extensive thorough written form number various warnings sub branch points instructions communicate mission control group developing assistance aist hockey described first version operated simplified unpacking operating digital camera included speech input output second xml based display
357	paper presents method incorporating word pronunciation information noisy channel model spelling correction proposed builds explicit error pronunciations modeling similarities words achieve substantial performance improvement previous best performing models introduction errors generally grouped classes typographic cognitive occur writer know spell cases misspelling correct related keyboard substitution letters keys misspelled non result single insertion deletion early algorithms based assumption differs exactly operations estimating probabilities weights different edit conditioning left right context insertions deletions allowing multiple high accuracy achieved acl brill moore introduced new generic string edits reduced rate nearly proved advantageous substitutions letter sequences deals phonetic significantly better allows larger size makes residual following triples guess
358	conditional random fields sequence labeling offer advantages generative models hmms classifiers applied position tasks language processing shallow parsing received attention development standard evaluation datasets extensive comparison methods train field achieve performance reported base noun phrase chunking method conll task better single model improved training based modern optimization algorithms critical achieving results present comparisons confirm strengthen previous maximum entropy introduction analysis biology described mappings input sequences labels encoding include speech tagging named entity recognition focus identifies non recursive cores various types text possibly precursor information extraction paradigmatic problem np finds nonrecursive phrases called nps pioneering work ramshaw marcus introduced machine learning metrics extended additional shared main approaches first approach relies order probabilistic paired label instance hidden markov multilevel second views classification problems
359	basic geo coding service encompassing parsing tool integrated digital gazetteer development parser need explicitly large resource collections statistical accounts scotland currently contain implicit form making inherently geographically searchable figure process introduction project undertaken edinburgh university data library larger aims develop protocol based uk server authority identified candidates current implementation consists main components generic demonstrator interface term refers identification document tagging candidate consequently geographic shows submitted identifies series potential displayed number occurrences text matching link records highlight option available original table various sorting functions county feature type default attributes disambiguation specification multiple entries attached single enabling output different instances application specific xml schema html contains
360	standard architecture nlg defined work describes modularization tasks module indicate kind tools believe certain widely ai nlu community appropriate paper presents complete integrated description logic content determination segmented discourse representation theory document structuring lexicalized formalism tactical component account user model illustrated generator produces texts explaining steps proof assistant planner communicative goals logical form message la sdrt sdrs plan micro semantic dependency tree surface realizer text figure data structures introduction proposed represented tool structure output precisely according reiter dale vary author reformulate specific terms modules section justifies task specifies
361	incremental algorithm introduced producing distinguishing descriptions generate minimal description paper generalised sets individuals disjunctive properties approach unnecessarily ambiguous redundant present alternative constraint based builds existing related algorithms produces using positive negative straightforwardly generalises ary relations integrated surface realisation introduction english languages possible function definite identify set referents uttering expression form speaker gives sufficient information hearer objects referring generation perspective means starting described known hold constructed allows user inform specific attributes referent np unambiguously talked task constructing singular basis received attention literature time general statement hand remained outstanding papers step direction showed extend basic dale reiter plural conjunctions integrates
362	paper describes application active learning methods classification phone strings recognized using unsupervised phonotactic models training data required recognition assigning class labels audio files work described demonstrates substantial savings effort obtained actively selecting labeled confidence scores classifier saving labeling evaluated different spoken language domains terms number utterances length phones selection giving utterance accuracy surprisingly conventionally trained word trigram requiring transcription aim advantage reducing train classifiers based systems assign applied problems sequences carried according method alshawi inputs model simply set recorded phase iterative procedure gram refined successively resulting current pass speech construct iteration currently estimate
363	stop generates personalised smoking letters evaluated controlled clinical trial believe largest rigorous task effectiveness evaluation performed nlg detailed results presented medical literature paper discuss structure cost learn compares techniques purpose perspective order help future researchers decide appropriate way evaluate systems increasingly important areas nlp mellish dale summary point underlying theories general properties texts generated actual application context theory evaluations typically comparing predictions observed corpus text asking human judges rate quality authored included rated set provide baseline showing subjects different measuring differences outcome variable success performing despite work aware previous compared meeting communicative goal non control young
364	consider problem parsing non recursive context free grammars generate finite languages natural language processing arises areas application including generation speech recognition machine translation present tabular algorithms perform practical settings despite fact introduction applications require large set candidate strings means computation selects wellformed according grammar likely model typically encoded compact way motivated cfgs allow representations derivable single nonterminals substrings different unfolding generated secondary affiliation german research center artificial intelligence able abstract let first fix terminology term refers process deciding proceedings th annual meeting association computational linguistics philadelphia pp giorgio satta di universit padova italy dei leads unnecessary duplication occurrence repeated substring independently parsed approach prohibitively expensive preferable algorithm shares working directly
365	paper ties loose ends finite state optimality theory first discusses perform comprehension grammars consisting constraints studied ot unlike production yield regular set making methods giving suitably flexible presentation carefully treat recent variants compiled transducers unify showing compilation possible components grammar relations including harmony ordering scored candidates benefit construction simpler implementation directional optimal produce comprehend general range infinitely pronunciations formulas identical sense complex varies underlying surface forms considers pairs consider course nested definition preclude computational shortcuts modest goals fact present problem required performed techniques constructions cut altering approximating formalism hook manage compile
366	shown basic language processes production free word associations generation synonyms simulated using statistical models analyze distribution words large text corpora according law association contiguity acquisition explained learning produced subjects presentation single stimulus predicted applying first order statistics frequencies occurrences observed texts conducted occurrence data requires second reason occur appear similar lexical neighborhoods approaches systematically compared validated empirical turns tasks performance comparable human paradigmatic introduction fundamental types relations believes correspond operations brain syntagmatic relation spoken written frequently expected chance different grammatical roles sentences typical pairs coffee drink sun hot teacher school substitute sentence affect high semantic similarity computed determining agreement red blue derived
367	following recent adoption machine translation community automatic evaluation using bleu nist scoring process conduct depth study similar idea evaluating summaries results unigram cooccurrences summary pairs correlates surprising human evaluations based various statistical metrics direct application procedure data contained multiple judgments duc single document progress summarization paper methods gram occurrence context setup discussed intrinsic section gives overview discusses ibm procedures compares cooccurrence terms correlation recall precision significance prediction concludes future directions introduction automated text drawn natural language processing information retrieval communities years series workshops special topic sessions acl coling government sponsored efforts united states japan advanced technology produced couple experimental online systems despite common convenient repeatable easily applied support development time comparison different understanding conference run national institute standards
368	paper present method based behavior nonnative speaker reduction sentence foreign language demonstrate algorithm using semantic information order produce reduced sentences difference languages ensure grammatical meaning original addition orders able different proposed removing clauses indexing document retrieval methods remove phrases syntactic categories rely context words accuracy problem mani maybury process writing reversing set revised rules improve performance summarization mckeown studied new extraneous phrase multiple source knowledge decide removed sources include statistic computed corpus consists written human professional prevented relative produced knight marcu demonstrated compression similar devised decision tree approach noisy channel framework applications including speech recognition machine translation parsing define rhetorical text documents introduction researches automatic focused extraction identifying important paragraphs texts
369	address appropriate user modeling order generate cooperative responses spoken dialogue systems unlike previous studies focus knowledge typical kinds users model propose comprehensive specifically set dimensions models skill level target domain degree automatically derived decision tree learning using real data collected obtained reasonable classification accuracy strategies based implemented kyoto city bus information developed laboratory experimental evaluation shows adaptive individual serve guidance novice increasing duration skilled practical simplest form according spread cellular phones telephone enable obtain various places special speech interface involves inevitable problems recognition errors conveyed communications determine make tell essential factors cope confirmation proposed management methods confidence measures results implicit includes prompts terms determining say output answers corresponding questions furthermore change initiative
370	paper examine improve precision recall document clustering utilizing meta data newsml tags assist approach effective experiments sample news experimental result shows using average algorithm facilitates business media publishing industry introduction nowadays people great demand knowledge information overload problem try suit customers need electronic management introduced group similar documents easier searching reading widely ensured effectiveness manual labor cost reduced time saved provides convenient clustered users accuracy suggest provide flexible hypothesis better additional contained standard enhance performance algorithms evaluated proposed chinese sources evaluation experiment showed provided achieved remaining organized follows section overview current approaches analyses existing problems suggests solution
371	paper experiments automatic extraction keywords abstracts using supervised machine learning algorithm discussed main point adding linguistic knowledge representation relying statistics better result obtained measured previously assigned professional indexers extracting np chunks gives precision grams pos tag term feature dramatic improvement results independent selection approach applied aim keyword assignment small set terms describes specific document independently domain belongs benefit appropriate terminological character work treated task first proposed turney important issues define potential features considered discriminative represent data consequently given input approaches presented noun phrase matching speech sequences different frequency collection relative position occurrence introduction research topic received attention deserves considering usefulness serve dense summary lead improved information retrieval entrance relatively documents
372	automatic speech recognition enabled applications medical corpora literal transcriptions critical training speaker independent adapted acoustic models obtaining costly time consuming non hand obtain generated normal course transcription operation paper presents method automatically generating texts place language reconstruction produce human labor trained data perform better lower perplexity humans educated task high cost makes asr require thousands talkers accurate idiosyncratic natural previously shown harder successfully adaptation incomplete exclude utterances commonly occur dictation filled pauses repetitions repairs ungrammatical phrases depending talker material constitute significant portion present
373	sentence planning set inter related distinct tasks scoping choice syntactic structure elementary speech acts decision combine sentences paper present spot planner new methodology automatically training basis feedback provided human judges task phases first simple randomized generates potentially large list possible plans given text plan input second ranker ranks output selects ranked ranking rules learned data trained learns select rating average worse recognition component request information caller departure airport user provides month day travel dialog strategy communicative goals turn implicitly confirm destination cities time representation utterance figure job decide number potential realizations alternative implicit introduction
374	previous research shown plausibility adjective noun combination correlated corpus occurrence frequency paper estimate frequencies pairs fail occur million word using smoothing techniques compare human ratings class based distance weighted averaging yield estimates significant predictors rated provides independent evidence validity introduction certain combinations adjectives nouns perceived plausible classical strong tea highly opposed powerful hand car argued theoretical literature pair largely collocational property contrast verb object predictable hypothesis investigated study lapata potential statistical correlation analysis judgements elicited subjects derived measures conditional probability given log likelihood ratio resnik selectional association measure positively highest obtained surprisingly yielded negative judged results suggest best predictor simply collocate record language experience obvious limitation applied
375	paper considers important issues monolingual multilingual link detection experimental results nouns verbs adjectives compound useful represent news stories story expansion helpful topic segmentation effect translation model needed capture differences languages introduction digital era assist users deal data explosion problem emergent internet contain large real time new information attempts extract multi lingual document summarization tracking tdt term project proposed diverse applications focus application aims determine discuss sizes compared comparable sentences addition represented different table performance feature selection strategies similarity threshold experiments conducted investigate effects environment ldc provides corpora support
376	present domain independent topic segmentation algorithm multi party speech feature based combines knowledge content using text form linguistic acoustic cues shifts extracted automatically induced decision rules combine different features embedded builds lexical cohesion performance comparable state art algorithms information significant error reduction obtained combining sources introduction aims divide documents audio recordings video segments topically related units extensive research targeted problem written texts spoken monologues studied segmenting conversations participants paper meeting transcripts study recorded meetings typically informal style includes ungrammatical sentences overlapping speakers generally pre set topics discussed segmenter comprises components word distribution identify homogeneous cohesive second component analyzes conversational indicative overlaps speaker changes integrating probabilistic classifier effective improving section review previous approaches applied corpus intended segmented annotation discourse structure mainly relies particularly
377	spoken dialogue systems promise efficient natural access information services phone widely applications email travel customer care moved research labs commercial receive millions calls month huge data led need fully automatic methods selecting subset caller dialogues likely useful improvement stored transcribed analyzed paper reports results automatically training problematic identifier classify human using corpus darpa communicator planning domain features identify classes accuracies introduction large variety deployed prototypes exist personal restaurant banking years strong requirement extract provide development developed first tested prototype fielded limited setting possibly running supervision finally stage application constantly undergoing house field subjects paid
378	paper describes right left decoding method translates input string generating direction addition presented bidirectional advantages output ways merging hypothesized partial outputs directions experimental results japanese english translation showed better suitable observed introduction statistical approach machine regards problem maximum likelihood solution target text given source according bayes rule transformed noisy channel model paradigm posteriori distribution prior exists efficient algorithms estimate parameters problems smt search sequence words stack algorithm dynamic programming translate word render pruning technologies assuming linearly aligned texts proposed deal drastically different correspondence sov svo suggested greedy integer first suffer similar described second impractical real world application presents
379	paper proposes new framework spoken dialogue based human subjects wizard oz using model information retrieval retrieving shop driving car designed refers suitable generating query reply authors constructed large scale database woz enables efficient collection action technique run effectively volume data traditionally collecting manually providing supplementary instance input speech required considerable labor address problem propose constructing examplebased performed subject pseudo scheme specific processing introduction first provide overview previously proposed given scenario operator searches returns user dialog modeled shown fig elements described request tells contents inquiry demands reference receiving generates referencing domain knowledge current context background increasing computing power techniques
380	paper describes method bootstrapping reinforcement learningbased dialog manager using wizard trial state space action set discovered annotation initial policy generated supervised learning algorithm tested shown create performs significantly better effort handcrafted small number dialogs mdp framework applied management constructed vector components including information history recognition confidence database status work hand selected ensure limited training proceed tractable selection impractical size increases automatic generation elements currently problem closely related exponential rl based systems introduction motivation recent successfully strategy experience typically formulating markov decision process despite successes questions remain especially issue prior data available line operation proceeds follows section outlines core issues applying sections addressing procedure test respectively present results discussion conclusions propose specifically address choice representation
381	cross database retrieval domain queries di ers target distribution term occurrences causes incorrect weighting assigns weight based resolve problem propose distillation framework query selection experiments using ntcir patent test collection demonstrate ective president news article gives large document frequency genre low think problematic terms eliminated stop word dictionary order mentioned describing approach description introduction revised mandatory runs task participants required struct search basic features follows retrieve patents relevant ranking kind relevance feedback okapi improvements
382	position paper argues interactive approach text understanding proposed model extends existing semantics based authoring using input source information assist user content permits reliable deep semantic analysis combining automatic extraction minimal human intervention various choices menu ranked according likelihood allowing selection author choice exceeds certain threshold performed automatically acts flexible aid operator tuning low level purely somewhat unreliable higher powerful guide building interpretation advantage plain textual interface representation easily accessible general users organized follows section present document mda constructs internal interacts realization explain extended raw serves rank accounting current work legacy normalization provide first implementation indicate links ideas
383	present supervised machine learning algorithm metonymy resolution exploits similarity conventional syntactic head modifier relations high precision feature recognition suffer data sparseness partially overcome problem integrating thesaurus introducing simpler grammatical features preserving increasing recall generalises levels contextual resulting inferences exceed complexity undertaken word sense disambiguation compare automatic manual methods extraction order recognise interpret large knowledge inference necessary metonymic readings potentially ended developing based previous feasible recognised actually regular pakistan location refers national sports teams won world cup similar regularly names england scotland lost semi final introduction figure speech expression refer standard referent related seat person ask wants importance resolving metonymies shown variety nlp tasks translation question answering anaphora contrast regularity exploited method pursued approaches polysemy needs
384	investigate verbal nonverbal means grounding propose design embodied conversational agents relies kinds signals establish common ground human interaction analyzed eye gaze head attentional focus context direction giving task distribution behaviors differed depending type dialogue grounded overall pattern reflected monitoring lack negative feedback based results present eca acts update state speaker behavior listener look map hang left floor figure face conversation introduction essential ensure participants share understanding said meant process ensuring adding called participate indicate utterance work needed shows provided continues add directions gives explicit clearly fact looks twice analyses maintaining attention public signal sufficiently
385	traditional vector based models word occurrence counts large corpora represent lexical meaning paper present novel approach constructing semantic spaces syntactic relations account introduce formalisation class evaluate adequacy modelling tasks priming automatic discrimination frequency matrix row corresponds unique target column represents linguistic context contexts defined small number words surrounding entire paragraphs documents typically treated set unordered cases information viewed point dimensional space similarity mathematically computed measuring distance points using metric cosine euclidean variants knowledge differences parts speech construction lexemes surface forms minimal assumptions respect dependencies fact assumed certain semantically relevant lack makes building relatively straightforward language independent entails contextual contributes studies tried incorporate view constructed introduction proved
386	recent statistical parsers rely preprocessing step hand written corpus specific rules augment training data extra information head finding node labels lexical heads paper provide machinery reduce human effort needed adapt existing models new corpora first propose flexible notation specifying allow shared different second report experiment expectationmaximization automatically fine tune set particular annotated model decoding parsed figure methodology development parser indicates augmentation introduction work parsing operate realm parse trees appear treebanks transformed transformation illustrated included augmentations include items label suffix indicate argument adjunct viewed latent directly present treebank recovered means process recovering largely limited construction heuristics case constructed optimal robust required construct considerable respects runs counter driven approach steps address problem
387	level center type described characterized interaction structured data consists following components structure defines set basic entities attributes methods identifying references user statements consortium members include university sheffield cnrs limsi duke suny list transactions supported service detect dialogue models handling various conversational situations human fashion consistent character optional meta strategy required address privacy security concerns built using limited static large degree domain independent adaptable sufficient design mixedinitiative capabilities explained section feel natural efficient giving broad initiative conduct wish create naturalness derived corpora actual conversations real needed develop speech prosody prototype caller management incorporated first demonstrator based galaxy communicator architecture standard configuration shown figure dm handle dialogues european languages additionally switch language recognition nat understanding french german text conversion telephony server hub database response generation ken
388	recent trec results demonstrated need deeper text understanding methods paper introduces idea automated reasoning applied question answering shows feasibility integrating logic prover approach transform questions answer passages representations world knowledge axioms linguistic supplied renders deep relationship trace proofs provide justifications boosts performance qa first syllables verb uniformly resources order inference engine verify extract lexical relationships candidate answers introduction motivation spite significant advances technology remain problems solved bridging gap words pinpointing exact consideration syntactic semantic roles better ranking justification performing systems reached plateau ranked th answered correctly total number clear new ideas based language necessary push introduce novel feasible effective scalable implemented called representation integrated
389	answer validation emerging topic question answering domain systems required rank huge amounts candidate answers present novel approach based intuition implicit knowledge connects quantitatively estimated exploiting redundancy web information experiments carried trec judged collection achieves high level performance simplicity efficiency make suitable module describes abductive inference process valid respect explanation background theoretically motivated semantic techniques tasks expensive terms involved linguistic resources computational complexity motivating research alternative solutions problem paper presents hypothesis number documents retrieved occur considered significant clue validity searched means patterns derived processing order test idea automatic implemented questions provided
390	ngram modeling simple language widely applications capture distance context dependency word window largest practical natural meantime occurs order incorporate kind paper proposes new mi approach model consists components captures pairs using concept mutual information better performance evaluation xinhua corpus million words shows inclusion best decreases perplexity trigram percent compared chinese segmentation errors corrected recognition machine translation nature obvious deficiencies instance currently exist preferred relationships highly associated psychological experiments meyer indicated human reaction pair stronger faster poorly
391	york university th new ny usa sekine cs nyu edu paper morphological analysis method based maximum entropy model consult dictionary large lexical information identify unknown words learning certain characteristics potential overcome word problem introduction basic techniques japanese sentence morpheme minimal grammatical unit process segmenting given row morphemes assigning attributes partof speech type important problems posed training corpus statistical approaches acquire corpora estimate correctly able make acquired added developed best mori nagao proposed probability string letters characters augmented improvement accuracy slight
392	paper describes robust linear classification named entity recognition similar applied conll text chunking shared task state art performance using different linguistic features easily adapt token based tagging problems main focus current investigate impact various local data enhanced significantly relative simple available languages sophisticated helpful provide improvement expected introduction important research area field information extraction topic central theme message understanding conferences nowadays large electronic makes necessary build systems automatically process extract spite significant work problem solved earlier reports suggested accuracy machine learning lower relatively small labeled studies performed restricted domains experience indicates statistically vary depending underlying domain challenges make statistical consistent types sources present advantage proposed incorporate
393	paper presents new formalization unification join preserving encoding partially ordered sets essentially captures means preserve generalizing standard definition ai research shows statically ontology logic typed feature structures encoded data structure fixed size need additional union operations important grammar implementation development based significantly reduces overhead memory management reference pointer adj noun case nom acc plus head mod figure sample type appropriateness conditions types values tfss features relative arrays logical terms regarded expressive refinement different ways first allows chains unbounded depth chain length pointers monotonically refine unbound bound second given tfs acquire promotes subtype acquires extra carpenter convention using general subtypes motivation
394	named entity recognition task proper nouns numerical information extracted documents classified categories person organization key technology extraction domain question answering first ne recognizer based support vector machines gives better scores conventional systems shelf svm classifiers inefficient present method makes substantially faster approach applied similar tasks chunking speech tagging feature selection efficient training sentences sec pc tagger tokens alpha processor slow practical applications paper natural language processing pos problem svms clear features important work useful finding useless mention reduce time suppose set data th sample label goal decision function accurately predicts unseen non linear classifier sign input
395	propose computational model visually grounded spatial language understanding based study people verbally objects visual scenes implementation word level semantics embedding compositional parsing framework implemented selects correct referents response broad range referring expressions large percentage test cases analysis successes failures reveal context influences utterances future extensions account figure sample scene elicit set mechanisms correspond commonly descriptive strategies resulting feature extraction algorithms lexicon terms features robust parser capture syntax spoken engine driven combines lexical units term semantic composition highlight individual words process processes combine models governed rules designing simplifying assumptions assumed meanings independent purely incremental holds data understands correctly evaluate collected speakers able understand
396	types technical texts meaning embedded noun compounds language understanding program needs able interpret order ascertain sentence explore possibility using existing lexical hierarchy purpose placing words compound categories category membership determine relation holds nouns paper present results analysis method biomedical domain obtaining classification accuracy approximately hierarchies necessarily ideally suited task pose question algorithm terms behave uniformly respect semantic topmost levels yield accurate providing economic way assigning relations introduction major difficulty interpretation sentences complex structure phrases consider title journal abstract labeled term study efficacy acute treatment highly dependent information large corpus hold surprisingly simply pairs ncs leg skin pain first word nc falls mesh second
397	cluster verbs lexical semantic classes using general set noisy features capture syntactic properties feature previously shown work supervised learning setting known english verb moving scenario class discovery clustering face problem large number irrelevant particular task investigate various approaches selection unsupervised semi methods comparing results subsets manually chosen according linguistic method tried consistently applied data semisupervised approach overall outperforms hand selected focus extending applicability classification group share common semantics frames expressing arguments serve means organizing complex knowledge computational lexicon creating highly resource intensive terms required time expertise development minimally importance automatically classify languages substantial amounts labelled available training classifiers necessary consider probable lack sophisticated grammars text processing tools extracting accurate broad performs contrast merlo stevenson confirmed
398	word fragments pose problems speech recognizers accurate identification improve recognition accuracy helpful disfluency detection algorithm occurrence indicator disfluencies different previous effort including acoustic model paper investigate problem fragment approach building classifiers using prosodic features experiments combining voice quality measures extracted forced alignments human transcriptions obtain precision rate recall data spontaneous overall significantly better chance performance introduction occur frequently indicators expressed percentage contain pattern description task dutch reported casual conversations british english bear atis corpus examined switchboard called partial happens speaker cuts unsolved community cases simply treated vocabulary words incorrectly recognized affects neighboring causing increase error fails provide important information detected increasing probability
399	overview patent retrieval task ntcir main technical survey participants tried retrieve relevant patents news articles paper introduce design collections characteristics submitted systems results arranged try want brief summaries proposals free styled introduction field information held successive evaluation workshops trec build utilize various kinds test third workshop effort first explore targeting documents goal provide enhancing research processing mining exist commercial services paid attention reasons lack collection document treatment specially applied fruitful discussions current status future directions convinced need specifically asked consequently release
400	work progress natural language analysis medical questionanswering context broader text retrieval project analyze limitations domain technologies developed general question answering systems alternative approach organizing principle identification semantic roles answer texts correspond fields format motivation aspect patient treatment questions arise search published evidence appropriate likely clinicians child increased lead decrease growth significantly slower group receiving higher high quality available way point care patients decision making frequently results additional changed decisions speed important investigation potential end users shown physicians need access information seconds longer abandoned practice using current best help called based medicine finding relevant typical problem area qa achieved success domains factoid corpus news stories track recent conferences
401	document structure separate descriptive level analysis generation written texts purpose representation mediate message text physical presentation abstract seen extension nunberg grammar closely related logical markup languages html tex using intermediate subtasks language understanding defined cleanly introduction appears collection words set pages fact tend strong graphical component accompanied conventional graphics pictures diagrams form elements titles headings chapters sections captions paragraphs lists overlay ways equivalent prosody speech layout undoubtedly contributes meaning utterances contribute tradition rich linguistic framework describing representing surprisingly natural systems presentational features aid interpretation attempt render output principled way course dimension nlg definition produce laid recent cases achieved mapping directly
402	accuracy ir result continues grow importance exponential growth www increasingly important appropriate retrieval technologies developed web explore new type answer set based operational experience proposed approach attempts provide high quality documents user maintaining knowledge base expected queries corresponding document elaborate architecture experimental results keywords driven classification automatic construction introduction goal information finding suited question massive collections satisfied response time expecting fast effort current systems especially focus improving precision recall notable trend accurate immediately usable answering using pre constructed pairs known traditional search engine term indexing tf idf approaches syntactic semantic pragmatic provided expert wordnet difference fact returns distilled need appeared query terms trec track motivated recent work field focuses barbara runs actual collection ranked list hand implicit
403	development framenet large database semantically annotated sentences research statistical methods semantic tagging advance previous work adopting maximum entropy approach using viterbi search highest probability tag sequence given sentence examine syntactic pattern based ranking increase performance analyze strategy extracted human generated features experiments indicate accuracy annotations held test set knowledge gildea jurafsky build classifier split problem distinct sub tasks frame element identification classification phase information parse tree learn boundaries elements presented focuses second completely classify extract model conditional role report body movement agent cause introduction hands inspiration np pp ability develop automatic hampered lack corpora recent laid foundation approaches project seeks annotate subset british national corpus semantics frames defined
404	paper presents method unsupervised discovery semantic patterns useful variety text understanding tasks particular locating events information extraction builds previously described approaches iterative pattern acquisition common characteristic prior output algorithm continuous stream gradually degrading precision differs previous algorithms introduces competition scenarios simultaneously provides natural stopping criteria learners maintaining levels termination discuss results experiments examine different aspects new procedure introduction work motivated research automatic considered important reference objective search entities kind corresponding user current systems achieve matching problem recall coverage large extent acquiring comprehensive set relevant scenario occurring proposed methods gained popularity substantial reduction manual labor require build learning focus convergence related
405	accurate evaluation machine translation problem brief survey current approach tackle presented new proposal introduced attempts measure percentage words modified output automatic translator order obtain correct feasibility method assessed important translators comparing results obtained various methods upv es francisco institut inform spanish catalan texts using hybrid following section discuss quality metrics introduce semiautomatic methodology mt tool facilitate kind finally present criteria introduction research lacks appropriate consistent criterion evaluating turns indispensable allow compare systems elicit variation affect translations field user choose shows number inherent difficulties first dealing subjective process define paper project aim construction scope inductive objective
406	multi processor systems commonplace based analyses actual argue exploit capabilities machines unification grammar parsers distribute work level individual operations present generic approach parallel chart parsing meets requirement implementation technique lingo achieves considerable design parser tied particular hard incorporate improvements available reason solution general possible obvious way ensure optimizations sequential let mimic basically paper hpsg developed stanford currently research institutions allows results compared groups section explore possibilities parallelism natural language analyzing computational structure discuss respectively performance finally compare introduction increasing demand accuracy robustness brings computing power addition increasingly applications require direct user interaction webbased responsiveness major concern mean time small scale desktop
407	paper describes application standard clustering technique task inducing semantic classes german verbs using probability distributions verb subcategorisation frames obtained intuitively plausible automatic evaluated independently motivated series post hoc cluster analyses explored influence specific frame groups coherence supported tight connection syntactic behaviour lexical meaning components provides principled basis filling gaps available knowledge english classification applications machine translation word sense disambiguation document various attempts infer conveniently observable morpho properties first work obtain automatically robust statistical parser acquire purely information provided form conditions relatively coarse second delicate condition prepositional phrase clustered means iterative unsupervised hard method known cf goal values parameters process explore role descriptions demonstrate implicit induction suggest ways refined
408	paper proposes unsupervised learning model classifying named entities training set built automatically means small scale entity dictionary unlabeled corpus enables classify cost building large hand tagged rules ensemble different methods repeats new generated various brings better result individual method experimental shows precision recall korean news articles introduction organization kaist announced list successful candidates dan da extraction important step applications natural language processing involves identifying text types person location time expressions numeric think classified easily using dictionaries proper nouns wrong opinion passes created continuously impossible add pn noun pp postposition verb categories followed classification english main approaches first approach employs crafted costs maintain changed according application second belongs
409	machine translation model proposed input translated source language target paraphrasing processes implemented prototype japanese chinese pair paper describes core idea paraphraser transfer exchanging information introduction humans generally capability mother tongue lesser extent foreign languages leads making conducting translate unfamiliar try paraphrase easier expressions contrast module biased bilingual mt models processor initiative analyzer integration based statistical shirai performed necessary prepare subsequent process words operates sub successful new similar human pro systems called designed generate sufficient knowledge sense design considered translator engineering point view advantage
410	work studies named entity classification catalan making large annotated resources language views explored compared exploiting solely direct training bilingual models given collection available spanish empirical results obtained real data point multilingual clearly outperform monolingual ones resulting easier improve bootstrapping unlabelled introduction wide consensus recognition natural processing tasks performance applications information extraction machine translation question answering topic detection tracking detecting classifying units text kept growing years previous mainly framed message understanding conferences devoted included nerc competition task recent approaches proceedings shared editions conference talp upc es learning systems languages remarkable aspect widely ml algorithms supervised require set labelled trained cause severe bottleneck expensive obtain case minority pre existing linguistic limited funding possibilities main causes developing independent small sets advantage
411	paper proposes multi dimensional framework classifying text documents concept multidimensional category model introduced representing classes contrast traditional flat hierarchical models classifies document collection using multiple predefined sets categories set corresponds dimension converted classification strategies possible directly based equivalent efficiency classifications investigated data nn na ve bayes classifiers experimental results performs better introduction past previous works focus task classify structural relationships existing databases organized type structure reuters newswire ohsumed trec improve accuracy variety learning techniques developed including enable criteria classified assigned class criterion merits approach support viewpoints solution sparseness problem centroid methods topic sports politics entertainment zone intra economics social inter mood news powerful tool manage large number grouping
412	paper describes rental enables sharing resources ltag hpsg formalisms method grammar conversion fb strongly equivalent style applied latest version xtag english experimental results obtained successfully worked parser achieved drastic speed share grammars lexicons parsing techniques introduction approach various feature based lexicalized tree ing head driven phrase structure automatically converts strong equivalence means generate exactly parse applications reduce considerable workload develop huge resource scratch concern limited enable ideas developed formalism studies ones disambiguation models programming development term refer confusing figure elementary trees overview ment works restricted closed community relation discussed investigating apparently valuable communities dependent computational framework
413	paper describes methods detecting word segments morphological information japanese spontaneous speech corpus tag large accurately using first method detect type second definitions pos categories includes semiautomatic analysis achieve precision better tagging words types comprise accuracy achieved yamada isahara new york university th floor ny usa sekine cs nyu edu introduction processing technology project construction csj collection monologues dialogues majority academic presentations simulated public speeches presented specifically paid non professional speakers transcriptions audio recordings goals corresponding defined members national institute language called term approximates dictionary item ordinary represents various compounds length
414	semantic roles agent patient domain specific speaker message topic based statistical classifiers trained roughly sentences hand annotated framenet labeling project parsed training sentence syntactic tree extracted various lexical features including phrase type constituent grammatical function position combined knowledge predicate verb noun adjective information prior probabilities combinations clustering algorithms generalize possible fillers test passed achieves accuracy identifying role constituents task simultaneously segmenting achieved precision recall study allowed compare usefulness different feature combination methods explore integration parsing attempt predicates unseen data introduction recent years ones natural language understanding rapid advances characterized processing tasks speech recognition tagging finally begun appear semantics play greater widespread commercial deployment simple systems answer questions flight arrival times directions report bank perform financial transactions sophisticated research generate concise summaries
415	systems interact user natural language infancy mature complex desirable developer automatic method creating generation components produce quality output efficiently conduct experiments goal appears particular discuss composed spot trainable sentence planner fergus stochastic surface realizer nlg work ported new domains apparent ease integrated real time dialog dm manager implicit confirm request period soft merge imp generator tts text speech flying newark leave figure recall basic tasks planning content structure target determined achieve overall communicative linguistic means lexical syntactic convey smaller pieces meaning realization specification chosen transformed string inflecting words shows cooperate generate corresponding set goals addresses stage embodied extend various ways apparently introduction
416	objects involved lf interpretation utterance want make intuitions individuals eventualities lexical meaning anaphora clear possible certainly forms representation scheme clause relation clauses indexed label associated abstract object sentence john left mary computational linguistics volume number written first argument asymmetric binary predicate consequent second eventuality leading occurs arguments order corresponding occur text appear set available discourse referents includes represent resolved anaphors reusing follow upset sue anaphoric variable contributed demonstrative pronoun subject leaving fact depending contribution adverbials
417	paper suggests efficient indexing method based concept vector space capable representing semantic content document information measure quantity ratio defined represent degree importance proposed expected compensate limitations term frequency methods exploiting related lexical items furthermore approach independent length regarded overall text value represented index weight works introduction improve unstable performance traditional keyword search web include previous weighting function depend statistical extracting exact indexes objective propose extracts efficiently weights according using model comprises concepts way recognized dimensional chains extraction vectors computed advantage terms equally important regarding indicator functions tested
418	present new framework classifying common nouns extends namedentity classification fixed set semantic labels called lexicographers developing wordnet number practical advantages information contained dictionary additional training data improves accuracy learning define realistic evaluation procedure cross validation introduction lexical useful natural language processing retrieval applications particularly tasks require complex inferences involving world knowledge question answering identification coreferential entities large databases include words encountered broad coverage nlp ideally automatically existing resources thank thomas roark colleagues brown laboratory linguistic editing advice material based work supported national science foundation grant identifying syntactic properties unknown terms database assign position synset hierarchy introducing synsets extending appropriate doing accurately problem paper address simpler determining class supersense belong systems thesaurus extension extraction named entity recognition partially different ways goal tagging vehicle organization person
419	paper introduces chinese word tokenization hmm based chunking experiments deal unknown problem log second term mutual information order simplify computation assume independence introduction mi regarded major bottlenecks language processing normally implemented segmentation literature affected title competition exists problems ambiguity detection modeling successfully applied bottleneck proposes scheme cope words form new individual tag dependent token sequence independent tags assumption reasonable dependence captured first equation applying computed chain rules ngram assumed
420	named entity extraction important subtask document processing information question answering typical method ne japanese texts cascade morphological analysis pos tagging chunking cases segmentation granularity contradicts results building units nes inherently impossible setting cope unit problem propose character based firstly input sentence analyzed statistical analyzer produce multiple answers annotated types possible tags best finally support vector machine chunker picks portions introduces richer previous methods base single result apply irex task cross validation measure shows superiority effectiveness introduction aims identifying proper nouns numerical expressions text persons locations organizations dates common standard data set provided workshop generally following steps segmented words brings recognize shown table definitions artifact contains book titles laws brand
421	model ccg parser hockenmaier steedman fail capture correct bilexical dependencies language freer word order dutch paper argues probabilistic parsers predicate argument structure clark defines generative derivations captures including bounded unbounded range introduction state art statistical penn treebank style phrase grammars categorial grammar include models defined terms local trees demonstrates inadequate languages equally applies czech argue problem avoided instead captured propose focus combinatory transparent syntax semantics interface direct immediate access includes arising coordination extraction control sound manner experimental results english demonstrate inclusion improves parsing performance depends degree formalism likely based formalisms benefit conditional inconsistent first review dependency proposed
422	paper discusses innovative approach assisted scoring student responses weblas language assessment delivered entirely web expected limited production free response questions portions concerned task creation modules module instructors experts provide input prompt importantly interactively inform score interaction consists natural processing searching alternatives provided gold standard answer asking confirmation assignment processes stores information database delivery phases addresses problems format provides integrated assessing ability purpose making decisions placement diagnosis progress achievement east asian programs content specifications languages based directly course specified scope sequence charts utilize tasks similar classroom instruction designed following advantages objectives greater administrative efficiency authentic interactive valid assessments integration incorporation cutting edge multimedia technology nested automatically assess existing systems rater focus holistic essay peg disregard simply perform surface feature analysis tabulation syntactical usage lsa require large corpora basis
423	present general model pp attachment resolution np analysis french make explicit different assumptions relies generalizes previously proposed models series experiments conducted corpus newspaper articles assess various components information sources introduction prepositional phrase noun known tasks traditional context free rules help selecting parse valid parses priori correct subcategorization solve problem necessary encoded lexicons huge addition frames encode senses words combined units language makes recognized works knowledge automatically acquired corpora decision process built building blocks making diverse fit probabilistic framework allows estimate quantities perform inference incomplete steps hand paper generalizing integrating focus analysing strings corresponding combination verb prep sequences phrases precisely nps consider arbitrarily complex embedded subordinate clause problems tackle
424	alias threattrackers advanced information access application designed needs analysts working large daily data feed help decompose gathering topic unfolding political situation iraq specifications including people places organizations relationships collect browse basis nearest related technologies retrieval document interface categorization extraction named entity detection currently total provides complete analyst control awareness program multiple views keywords collected included sentence excerpt summaries tables entities original source search coreference anaphora documents redundant filter sentences allow create description demo new categories chemical weapons created serve form triage representation contains pointers mention fig spelling variation pronouns refer future versions cognitive indexing include audio mentions database entries addition supports standard key word lookup relationship authored classes
425	japanese language predicate placed end sentence content inferred reaching complicated people want know earlier stage negative interrogative grammatical form called ko ou relation exists kind concord element appears pointed gives advance notice paper present method extracting automatically expression data large scale electronic corpus verify usefulness meaning reading entire helpful understanding early kakari morphemic gave elements appear dropped research attempted collect extract main points argument follows previous works position study introduction
426	paper proposes automatic method detecting grammar elements decrease readability japanese sentence consists components check list detected detector search program defining level element read words phrases checker realized provides items levels searches identify currently working aspects concerned kanji characters vocabulary reports aspect introduction prefer readable texts transmit crucial information instructions strong completely rewrite improve english measuring reading age studied chronological reader understand text value calculated length number syllables readers specific goal study present tools help rewriting work improving
427	discuss properties collection news photos captions collected associated press reuters vocabulary dominated proper names implemented various text clustering algorithms organize items topic matcher identifies articles share picture special structure allows extract people actually image reliably using simple syntactic analysis able build directory face images individuals need isolate objects solve correspondence problem caption extracts regions exploring issues context trying automated classifier collecting feb photographs ap collect day unique vast majority subset focus illustrated bbc cnn make heavy fact field agencies afp journalistic writing guidelines emphasize clarity certainly necessary author average words convey salient details writer first responsibility identify contain
428	paper introduces set guidelines annotating time expressions representation times refer describes methods extracting multiple languages introduction processing temporal information poses numerous challenges nlp progress accelerated corpus based applications benefit include extraction question answering summarization machine translation visualization annotation scheme described novel features including following goes message understanding conference terms range flagged importantly representing normalizing values communicated addition handling fully specified handles context dependent significant contextdependent recent study revealed print broadcast news ones local months hot global subclass indexical require knowing speaker speaking determine intended value weeks work funded darpa translingual detection research program contract number arpa order
429	paper presents unsupervised method discriminating senses given target word based context occurs instances occur similar contexts grouped mcquitty similarity analysis agglomerative clustering algorithm represented surface lexical features unigrams bigrams second order occurrences summarizes approach describes results preliminary evaluation carried using data senseval english sample line corpus creation sense tagged time consuming knowledge acquisition bottleneck severely limits portability scalability techniques employ discrimination suffer problem expensive preprocessing external sources manually annotated required objective research extend previous work developed relied localized contextual adopts distinct larger number locally globally instance discriminated incorporates ideas later including reliance training raw text identify feature term objectives include determining extent different types impact accuracy interested assessing measures matching coefficient cosine affect overall performance
430	paper examines different possibilities advantage taxonomic organization thesaurus improve accuracy classifying new words classes results study demonstrate similarity nearest neighbors addition distributional word useful evidence classification decision based introduction machine readable thesauri indispensable wide range nlp applications information extraction retrieval manual construction expensive recent research aiming develop ways automatically acquire lexical knowledge corpus data address problem largescale augmenting items specifics task number need classified poorly predictable semantic distinctions account reason poor approaches approach particularly suited previous demonstrated cooccurrence statistics target sufficient numerous synsets wordnet organized follows sections algorithms section describes settings experiments details evaluation method presents concludes methods techniques previously applied summarized according following neighbor category centroid operate vector representations meaning terms counts
431	word segmentation first step chinese information processing performance segmenter direct great influence steps follow different segmenters results handling issues boundary present paper need absolute definition acceptable help reach correct syntactic analysis end keyword automatic evaluation corpus natural language following test job provider participant according rule provided encouraging supply list elected participants section describes work bakeoff respectively includes training set people daily data features standard error wide coverage linguistic phenomenon topics required statistic latest version manually validated high level correctness consistency specification detailed carefully designed guidance using nlp ensure fair contest systems common framework introduction
432	paper addresses question metaphors represented wordnets purpose domain centered data collected hamburg metaphor database online source created study possible representations based results analyses french german corpus eurowordnet implementation problem discussed shown complete representation synsets relations clearer indication level individual needed global conceptual dealt new pre existent knowledge constrains possibility produce understand novel metaphoric expressions encoded higher concerns single domains work framework introduced lakoff johnson think appropriate representing underlies systematic similar inter lingual index unstructured fund concepts providing mapping languages special case ili entry called composite record regular polysemy covered fact lexeme university refer building organization extends lexemes members respective construction ewn language independent polysemic deleted order reduce overgeneration propose add indexes wordnet instead
433	ongoing construction large semantically annotated corpus resource reliable basis largescale acquisition word semantic information domainindependent lexica backbone annotation roles frame semantics paradigm report experiences evaluate data first project stage discuss problems vagueness ambiguity introduction based methods syntactic learning processing established computational linguistics comprehensive carefully worked resources available number languages penn treebank english negra german situation different initial stages currently small corpora predominantly concentrated senses senseval initiative notable exception prague consequence ca recent work unsupervised approach relying statistical extract regularities raw using ontologies wordnet lack providing bottlenecks language technology train tools extensively necessary paper present current salsa aim provide investigate efficient phase focus research role relations specifically berkeley framenet addition selectively annotate anaphoric links tiger
434	paper describes implementation compute positional ngram statistics based suffix array data structures multidimensional arrays ngrams ordered sequences words represent continuous discontinuous substrings corpus particular model shown successful results extraction collocations large corpora computation heavy instance generated word size window context comparison computed classical clear huge efforts need process reasonable time space solution shows log complexity function designed models common fact string frequencies task gigabytes processed yamamoto church exist reason low order commonly natural language processing applications specific field multiword unit introduced evidenced unlikely previous tokens consequence number rapidly reaches figures
435	paper describes lingua architecture text processing bulgarian first pre modules tokenisation sentence splitting paragraph segmentation partof speech tagging clause chunking noun phrase extraction outlined proceeds anaphora resolution module evaluation results reported task cally based algorithms language analysis way getting lack resources introduction state art parsing knowledge automatic falls providing reliable framework robust real world applications abstracting information problem especially acute languages benefit wide range programs various projects address different aspects morphological disambiguation previous work pursued development poor environment high level component integrity reports implementation referred includes pos builds basis considerably shallower linguistic input trading depth interpretation breadth coverage workable solution automatically performs identification third person personal pronouns original
436	paper presents novel information integrating advanced extraction technology automatic hyper linking extracted entities mapped domain ontology relates concepts selection hyperlinks sprout generic platform development multilingual text processing components combining finite state unification based formalisms grammar formalism offers efficiency high degree demo relevant german texts tourism offering direct connection associated web documents demand internet document base accessing search engine quality link targets higher standard engines first specific interpretations sought second provides additional structure including related shallow analysis currently linguistic resources english italian french spanish czech polish japanese chinese tokenization morphological named entity recognition free section innovative features gives details demonstrator introduction typed feature structures machines utilization language creation history applied identifying sources new systems commercially viable supporting diverse discovery management tasks similarly designed pieces using ontologies define relationships present integrates
437	initial experiments combining output question answering systems using data trec task explore distance based methods number metrics involving word character ngrams introduction progress technology measured individual improve accuracy way witness technological ask perform automatic community asked enter earth english answer best qa second better expected work different independent errors follow build lower bounds highest possible performance current achieve given dataset practical value allow estimate doing respect underlying difficulty continually provide targets known achievable optimal determine domain simply nist rover speech recognizer gives asr researchers updated goal shoot evaluation implicit measure extent making similar set annual opportunity information retrieval evaluate techniques variety tasks
438	propose ontology based framework linguistic annotation written texts argue actually considered special case semantic regard pursued context web furthermore present cream concrete implementation purpose demonstrate value applying anaphoric relations introduction crucial development evaluation natural language processing tools particular machine learning approaches speech tagging word sense disambiguation information extraction anaphora resolution rely corpora annotated corresponding phenomenon trained tested paper extent seen task choosing appropriate tag categories senses corresponds selecting correct class concept underlying wordnet template filling train systems finding marking attributes given ontological text event management succession person affiliation position bridging
439	paper address problem extracting key pieces information voicemail messages identity phone number caller task differs named entity interested subset entities message consequently need pick correct makes include typically associated work present extraction methods based hand crafted rules maximum entropy tagging probabilistic transducer induction evaluate performance manually transcribed output speech recognition earlier context text sources great deal focused spoken document retrieval broadcast news ne telephone conversations focus source conversational data relatively large volumes real world benefit greatly techniques goal query personal items listen entire instance called importance precisely attempts summarizing past
440	information space based occurrences text corpora allowing user visualize local regions words dimensional picture related classes similar occur recognizable clusters clearly signify particular meaning giving clear view concepts document collection technique helps interpret unknown main demonstrate projection word vectors vector built using latent semantic analysis method applied translated available training following sch tze assign coordinates number times occurs window content bearing chosen frequency reduced dimensions lsa visualized produce meaningful diagram results query perform extra steps firstly restrict attention given closely selecting group deeper second performed restricted set significant directions axes determine plane best represents data resulting diagrams summary areas actually particularly effective visualizing
441	consider problem base noun phrase translation propose new method perform task given np first search candidates web determine possible using methods developed employ ensemble na ve bayesian classifiers constructed em algorithm tf idf vectors experimental results indicate coverage accuracy significantly better baseline relying existing technologies introduction address source language target define simple non recursive cases nps represent holistic concepts accurate extremely important applications machine cross information retrieval foreign writing assistance paper contains steps candidate collection selection look word dictionary corpus related work corpora parallel straightforward approach bilingual obtain practice deal difficulty number proposed
442	paper describes parsing schemes shallow approach based machine learning cascaded finite state parser hand crafted grammar discusses ways combine presents evaluation results individual approaches combination underspecification scheme output introduced shown improve performance introduction areas natural language processing different best especially deep systems guarantees interpretability high precision provides robustness recall investigates consisting gram morphological checking respective strengths weaknesses brought light depth treebank german newspaper texts containing ca tokens sentences format chosen common denominator agree parsers constitute knowledge require efforts writing complex linguistic lexicon manage training data building hybrid improved allows partially ambiguous cases successfully disambiguate information section adopted advantages controversial points formulates classification problem basis applies learner architecture novel explores strategies
443	chunk parsing focused recognition partial constituent structures level individual chunks attention paid question analyses combined larger complete utterances parser extends current techniques tree construction component parses including recursive phrase structure function argument rithm relies memory based learning allow similarity classification given input relative pre stored set instances fully annotated treebank quantitative evaluation conducted using semi automatically constructed german consists sentences basic parseval measures developed parsers main goal analysis spans entire runs counter philosophy underlying robustness partially analyzed eh sfs uni longest match right pattern matching strategy despite popularity approach apparent gaps research comparison relatively reported evaluations measure correctness output obtained present paper help architecture order
444	objects basic types information program requires researchers using audio video recordings corpus transcriptions merely coding important views pertaining point time synchronized sequence different points view user internal state contains possible dialog changes change consequence quantitative analysis provided following standard defined set automatically derivable properties include volume comprises measures number words word length pauses overlaps utterances turns relative speaker activity ratios various calculated based stress stressed overlap speed duration alternatively pause given utterance special descriptors type descriptor vocabulary richness measured token ber theoretical cf van constructed looks phrases repeated verbal dominance equality positions lemma implemented simple stemming algorithm enables collect regularly inflected
445	spoken queries natural medium searching web settings typing keyboard practical paper describes speech interface google search engine present experiments various statistical language models concluding unigram model collocations provides best combination broad coverage predictive power real time performance report accuracy results prototype introduction number properties make particularly recognition problem first typical range words median length second large vocabulary covers query traffic third contrast systems achieved nist conversational telephone task required times modeling techniques address problems creating voice extreme simply list frequent entirety lowest provide covered computationally expensive sub word gram high low experimented configurations experience commercially available size items feasible choice yielding
446	hybrid described combines strength manual statistical learning obtaining results superior methods applied separately combination rule based parallel serial performing partial disambiguation recall first trigram hmm tagger runs experiment czech tagging performed encouraging reached absolute terms performance comparable english stands report slightly realize adequate tasks implied sentence error rate simply deal inflective languages techniques ranging plain old taggers memory maximum entropy feature best result achieved approximately thousand word training data set using manually annotated tokens prague dependency treebank project decided work usual source channel setting proper smoothing morphological processor pdt disambiguate tags mainly ease trained large publicly available able cope ambiguity reasonable time morphologically plausible given input form
447	paper proposes new approach text categorization based feature projection technique training data represented projections documents voting classification processed basis individual final test determined majority classifications empirical results proposed using outperforms nn rocchio na ve bayes times faster algorithm simple implementation process easily reasons useful classifier areas need fast high performance task introduction issue classify certain number pre defined categories active research area information retrieval machine learning wide range supervised algorithms applied set categorized nearest neighbor known focus knowledge sets dimension instance neighbors resulting allowed comparable present particular problems caused special properties
448	introduction smt english japanese mt systems tdmt order evaluate outputs manually assigned ranks native speakers target language ideal selection highest ranked figure shows individual performances derived combination left hand group indicates ra ned follows perfect problem information grammar fair understand unimportant missing acceptable broken understandable important translated incorrectly performance best output number sentences total ratio right
449	introduction overall description df dr fe gg fg gt ch ce da
450	speedup training conditional maximum entropy models algorithm simple variation generalized iterative scaling converges roughly order magnitude faster depending number constraints way speed measured attempting train model parameters simultaneously trains sequentially implement typically slightly memory lead improvements problems typical disadvantage possible output values needed prohibitive combining technique eliminated maxent form exp fi introduction variety natural language tasks including modeling partof speech tagging prepositional phrase attachment parsing word selection machine translation finding sentence boundaries unfortunately applied generally extremely slow month time single attempts later suffered applicability limited applications gis joint probabilities mention fast appears missed community useful larger range traditional techniques achieves
451	paper describes novel aided procedure generating multiple choice tests electronic instructional documents addition employing various nlp techniques including term extraction shallow parsing program makes language resources corpus wordnet generates test questions distractors offering user option post edit items based methodology generation proposed premise focus key concepts addressing central irrelevant ideas first stage identify domainspecific terms serve anchors question way syntax prime candidate domain specific sentence branch linguistics studies words sentences transformed asking discipline act stems important semantically correct answer possible additional clues provided students plausible better distinguishing confident poor uncertain ones preferably semantics pragmatics chemistry football instance order item comprehensible avoid complexity generated declarative using simple transformational rules turn results
452	paper proposes principled approach analysis semantic relations constituents compound nouns based lexical structure difficulties noun mechanisms governing decision representation method associated contextual meaning obvious aim research clarify semantics contribute productive supposed governed systematic results applying deverbal compounds japanese english conceptual contributes rules introduction difficulty effective way describing identified description remain kind categorization account construction model previous work proposed approaches categories detailed framework gen lexicon especially designed complete factors needed probabilistic disambiguate experimental high performance shallow using semantically tagged corpora fully need incorporate disambiguating necessary kinds related govern background carried aims clarifying
453	present technique virtual annotation specialization predictive answering definitional questions generally property type answer given question poses problems select strings suggested passages combination knowledge based techniques using ontology statistical large corpus achieve high precision characteristic definitions approach strengths pa successful cases deeper understanding text needed order identify defining term first brief description look certain class basic algorithm develop evaluate performance respect standard trec benchmark demonstrate sets improves addition va keywords information retrieval ontologies background introduction gaining increased attention commercial academic algorithms general proposed fail capture subtleties particular types propose different processed introduce named previously presented proven effective problem essence index
454	paper deals user corrections aware sites errors toot spoken dialogue rst corpus details procedure label exhibit prosodic properties set apart normal utterances appears correction types simple repeats likely correctly recognized paraphrases present evidence strategy ects users choice type suggesting speci methods detecting coaching useful tend shorter recognize asr compared systems di interpreting input car normally left driver turns wheel direction cleaner start working pushes button interactions hampered mismatches action intended introduction executed mainly automatic speech recognition natural language understanding component solve considerable ort trying make clear problem correct entering misrecognized information previous research brought light determine actions carried particular
455	new framework dependency grammar modular decomposition immediate linear precedence approach distinguishes orthogonal mutually constraining structures syntactic tree topological syntax nonprojective non ordered projective partially computational linguistics universit des saarbr cken germany uni sb trees formulated terms lexicalized constraints principles governing climbing conditions section discuss difficulties presented discontinuous constructions free word order languages briefly touch limitations reape popular theory domains introduce concept outline formal id lp finally illustrate account phenomena verbal complex german verb final sentences introduction called remains challenging modern formalisms address issue propose supports constraint based axiomatization parsing characterized formed ignored issues article develop complementary dedicated treatment edges labeled roles fields shape obtained allowing nodes
456	measuring differences constitutes major challenge development electronic dictionaries natural language processing systems paper presents pilot study population test method effective empirical tool define synonyms quantifiable manner knowledge lexical meaning resides collectively mind native speakers understanding extracted targeted surveys encourage creative thinking responses tests performed group high school students resulting data surprisingly web based visualization program developing analyze present collected corpus approaches constrained kind scope pre existing corpora tools currently available analysis necessarily depends heavily subjective judgment investigators conditions prove achieve complete evenly distributed coverage truly reflects diversity community propose approach hope complement methods directly repeatedly iterative process speech acquire verify semantic information briefly aid analyzing refining model extracting general background introduction problem synonym discrimination formidable humans attempting
457	paper describes wide coverage statistical parser combinatory categorial grammar derive dependency structures differs existing treebank parsers capturing range dependencies inherent constructions coordination extraction raising control standard local predicate argument set training testing obtained ccg normal form derivations derived automatically penn correctly recovers labelled unlabelled introduction recent models based lexical charniak typically context free phrase structure tree using simple head heuristics approach work involved common text wall street journal chiang adjoining alternative mildly sensitive formalism arguably provides linguistically satisfactory account coordinate phenomena potential advantage expressive facilitate recovery unbounded impact accuracy recovering make output useful unlike formalisms relations relevant interpretation extremely non surface impacts best define probability model spurious ambiguity lead exponential number given constituent addition
458	propose new methods advantage text resource rich languages statistical language models deficient achieve extension method lexical triggers cross problem developing adaptation scheme combining trigger model gram application automatic speech recognition exploiting corpus english news articles adapting static chinese transcribe mandarin stories demonstrate significant reductions perplexity errors compare lingual monolingual alternate cues crosslingual information retrieval machine translation proposed availability accurate large amounts suitably annotated training data build usable absence success witnessed called increasing arabic asr nlp resources created considerable cost bottleneck likely remain majority world future bootstrap acoustic reusing morphological analyzers noun phrase chunkers pos taggers developed translated parallel kim using improve available transcribing story
459	document clustering aggregation related documents cluster based similarity evaluation task representatives clusters terms discriminating features clue term frequencies feature selection method basis frequency statistics limitation enhancement algorithm consider contents objects paper adopt content analytic approach refine computation propose keyword experimental results weighting outperforms keywords scheme introduction relevant irrelevant relevance determination criteria measure measures dice coefficient cosine require represented vectors calculated operation general consist weight pairs similarities determined values extracted previous studies focused work supported korea science engineering foundation advanced information technology research center construction vector depends
460	propose method split translate input sentences speech translation order overcome sentence problem approach based criteria judge goodness results utilize output mt assumes particular language experiment ebmt prior methods work badly proposed achieves better quality introduction achieve technology adequate possibilities corpusbased approaches investigated dp match driven transducer machine adapted japanese english travel conversation domain high hand sensitive longer make perform technique splitting translating appears promising previous studies related roughly classified types splits parsing phase ll pre process parse speaking isn necessarily utterance including paper term strictly defining simplify discussion research word sequence characteristics efforts achieved performance recall precision correct positions despite
461	paper describes vision future time end users mixed initiative spoken dialogue systems able dynamically configure suit personalized goals argue common utility society essentially support new working vocabulary domain subdomain user interested restaurants line gather information resources web infer knowledge appropriate language models control mechanism subsequent conversation topic addition painting discusses recent research efforts directed technology development necessary realize larger goal man technologies conversational distinguished emerging deployed commercial interaction natural flexible modelled style humanhuman galaxy communicator architecture greatly accelerated pace experts complex wide range different domains underlying components matured focus evolved include issues related portability modularity dynamic believe ability naive developers existing manage personal needs crucial successful ways feasible critical initial preparation available databases defining
462	present novel approach finding discontinuities outperforms previously published results task using deeper grammar formalism combines simple unlexicalized pcfg parser shallow pre processor trace tagger surprisingly detecting occur phase structure information introduction paper explore distance dependencies particular detect step process conceptually looks sites preprocessing parsing finds dependent constituent clearly relationships vital semantic interpretation constructions prove stochastic parsers avoid tackling problem deal subset problematic cases johnson proposes algorithm able postprocessing fares faces designed capture non local confused sentence presented susceptible shortcoming overall primary contributions first extend mechanism adding gap variables nodes dominating site discontinuity allows context free reliably recover antecedents given prior second introduce finite state gives exactly finally combination new method antecedent recovery analyze organization follows section
463	paper introduces context sensitive electronic dictionary provides translations piece text displayed screen requiring user interaction achieved process phases acquisition morpho syntactic analysis selected word lookup similar tools available program works dictionaries adapted printed implement features traditional entries need splitting smaller pieces indexing special way able display restricted set information relevant based recognize discontinuous multiword expressions major believe make unique time development focused linguistic flexibility architecture flexible interface assess functional requirements start explain operation focusing implementation lexicons conclude comparing tool publicly products summarize plans future introduction instant comprehension justify usefulness type device developing main idea help users understand large number foreign language texts encounter situations usage provide cases application background providing
464	demonstrate output distributional clustering algorithm called committee automatically discovers word senses text cluster belongs corresponds sense following sample introduction using versus forms useful applications information retrieval machine translation question answering hypothesis states words occur contexts tend similar approaches compute similarity based distribution corpus programs ranked list lin approach outputs wine suit beer white red fruit food coffee juice milk shirt dress case claim business entry shows clusters headword lists members centroid feature representation represent meaning mixture distinguish multiple polysemous vector context occurs
465	paper presents application dynamic bayesian network task assigning speech tags novel text particularly challenging non standard corpora internet lingo large proportion words unknown previous work reveals pos depend variety morphological contextual features representing dependencies results elegant effective tagger introduction uncovering syntactic structure texts necessary step extracting meaning order obtain accurate parse unseen need assign string covers aspect tagging networks demonstrates success refer companion substantial discussion method details currently existing algorithms exhibit high word level accuracy solved problem first small percentage errors subsequent processing steps second robust testing corpus differs style training time diverse lacking taggers trained annotated extracted wall street journal factors significantly hamper extract information email messages websites extraction left searching perform integrate easily probabilistic reasoning producing distribution deterministic answer sources set idiosyncratic characteristics
466	address text generation problem sentence level paraphrasing phenomenon distinct word phrase approach applies multiple sequence alignment sentences gathered unannotated comparable corpora learns set patterns represented lattice pairs automatically determines apply rewrite new results evaluation experiments derives accurate paraphrases outperforming baseline systems time initially suppose simply result substitution applied domain fashion studies domains generally case instance consider following latest fed rate cut stocks rose board strongly greenspan rates introduction late parrot life rests peace pushing processes joined invisible python pet shop mechanism generating given significant practical import applications include summarization rewriting employ produce candidate components filter length sophistication forth surprisingly focus research interesting application somewhat expand existing providing observe
467	learning new words assisted contextual information context forms including observations nonlinguistic semantic domains linguistic word presented outline general architecture structural alignment coordinates order restrict possible interpretations unknown identify spatial relations applicable domain progress implementing using video sequences non input complete bird rock sequence flying tree meanings preposition register corresponding aspect trajectory fragments particular interested introduction limit assuming inputs syntactic multiword utterances includes relationship multimodal environment observed designed coordinate clues set leveraging previously learned enable create bootstrapping section based symbolic solving stated problem necessary subsystems requirements satisfy visual potential
468	paper describes original hybrid extracts multiword unit candidates speech tagged corpora classical systems manually define local ofspeech patterns lead identification known units solution automatically identifies relevant syntactical corpus word statistics combined acquired linguistic information order extract sequences words result human intervention avoided providing total flexibility different phrasal verbs adverbial locutions prepositional identified tested brown leading encouraging results problems pose need robust handling purpose statistical methodologies proposed propose called mwu unlike pre technically mutual expectation association measure acquisition process step first divided sub containing tags segmented set positional ngrams ordered vectors textual third independently evaluates degree cohesiveness ngram combination mes evaluate global sequence
469	present conditions verb phrases elided based corpus positive negative factor affect phrase ellipsis include distance antecedent site syntactic relation presence absence adjuncts building results examine generation architecture trainable algorithm vp located best performance achieved module realizer access features basic condition vpe clear literature identical meaning furthermore sufficiently provides beginning account said shown following young eastern plan projections million mark italicized nearby antecedents closer occur particular mr says businesses paying smaller percentage profits cash flow form dividends historically paper identify factors govern decision vps correlated
470	introduction number researchers devised corpus based approaches automatically learning lexical semantic class verbs mccarthy korhonen lapata merlo stevenson automatic verb classi cation yields important potential ts creation resources classes incorporate syntactic information general sense change state manner motion allowable mapping verbal arguments positions experiencer argument appear subject object levin assignment inherits great deal possible usage nlp ing explicitly hand coded paper explore multilingual corpora extend work statistics simple features extracted syntactically annotated train er set sample english limitations rst small ve correlate proposed second large needed words extract su discriminating address issues current study exploiting parallel chinese motivating hypothesis di cult detect super manifest surface language case able augment initial
471	discovery program called domain application study language universals classic trend contemporary linguistics accepting input information languages presented terms feature values discoveries human agent arising data additional discovers compares appropriate generates report english running seminal paper word order produced linguistically valuable texts published refereed linguistic journal introduction previous works machine scientific focussed historical reconstruction recent efforts directed designing programs discover new knowledge systems operate disciplines diverse mathematics chemistry medicine field currently active present particular brief description drawing illustration accepts following manually prepared database comprising sizable number described properties list abbreviations leave institute informatics features na cn pn suf findings judged interesting
472	study impact richer syntactic dependencies performance structured language model dimensions parsing accuracy perplexity rate models achieve improvement lp lr ppl wer reported baseline results using slm upenn treebank wall street journal corpora respectively analysis shows correlation quality parser remarkable fact enriched outperforms gram terms isolation second pass key achieving reduction guess final best parse given sentence traversed left right harder finding entire sought regular statistical expected techniques developed community aim recovering judged human annotator productive enhancing structure various ways enriching dependency underlying parametrization probabilistic scoring tree shown outperform wsj simple way constructor component showed better modification training procedure brought level
473	single character named entity composed chinese russia scne common written text lack depth research major source errors recognition paper formulates model framework experiments encouraging results fscore location score person alternative view problem formulate classification task construct classifiers based maximum entropy vector space respectively compare proposed approaches showing performs best cases introduction popular recent years wide applications message understanding conference provides standard testbed ner evaluation english includes related work consider types organization shown table accounts ne tokens mb corpus especially names described focus
474	commonly believed word segmentation accuracy monotonically related retrieval performance chinese information paper relationship fact nonmonotonic phenomenon begins occur leads reduction demonstrate effect presenting empirical investigation trec data using wide variety algorithms accuracies ranging appears main reason drop correct compounds collocations preserved accurate segmenters broken surprising advantage suggests words broad notion conveniently capture general semantic meaning text focus simple form processing require deep analysis perform effective accurately topic discourse relate given query context complicated source separated whitespace creates significant additional ambiguity interpreting sentences identifying underlying standard approaches character based thought superior methods simpler recent approach motivated advances automatic
475	purpose work investigate machine learning approaches confidence estimation statistical translation application specifically attempt learn probabilities correctness various model predictions based native features current context experiments conducted using original models types neural nets task large space output sentences represented sequences words given produces probabilistic score straightforward way obtaining probability input interpreted desired idea second transform base observing performance new text possibly conjunction approach known widely speech recognition virtually unknown areas natural language alternatives traditional smoothing techniques backing simpler cross validation careful scaling applicable obtain posterior evidence results obtainable external ce present incompatible practical advantages first easily incorporate specialized highly indicative perform choosing include represents kind
476	introduce multi language named entity recognition based hmm japanese chinese korean english versions implemented principle analyze training data target common analytical engine handle simply changing lexical analysis rules statistical model paper architecture accuracy report preliminary experiments automatic bilingual dictionary construction using recognizer translation information retrieval extraction developed mainly need changed previous works european languages first asian know following sections evaluation results finally introduction goal build practical accomplish aim conditions solve differences features second adaptability variety genres endless texts www third combine high
477	paper demonstrate methods improving recall precision automatic extraction hyponymy relations free text applying latent semantic analysis filter extracted reduce rate error initial pattern based achieving graph model noun similarity learned automatically coordination patterns previously correct achieve roughly increase number hyponym fish say conversely hypernym names exist variants relationship parent node child broader term narrower noted genus object traditional lexicographic terms write subset relationships regard set reasonably said central knowledge engineering numerous attempts learn beginning hearst review work section reproduce similar experiments baseline expand rest demonstrates ways mathematical models built corpora improve
478	present novel approach determination recurrent sound correspondences bilingual wordlists idea relate sounds translational equivalences words bitexts method induces models correspondence similar developed statistical machine translation experiments able determine pairs cognates employing discovered identify higher accuracy previously reported algorithms english tn tu st fom latin ed dent gen ped eat foot wolf table exhibiting corresponding phonemes shown boldface originate single proto phoneme great assistance historical linguists reconstruction engine set programs designed aid language requires provided closely related task studied computational linguistics identification employed sentence word alignment improving inducing lexicons proposed cognate implicitly employ immediately apparent strong similarity matching phonetic segments pair sentences mutual translations introduction genetically languages exhibit
479	paper defines general form probabilistic language models proposes efficient algorithm clustering based evaluation experiments revealed method decreased computation time drastically retaining accuracy introduction algorithms extensively studied research area natural processing researchers proved classes obtained improve performance various nlp tasks class gram smoothing techniques structural disambiguation word sense define propose model theoretic involves operations classify merge split decreases optimization function mdl principle efficiently point local optimum applicable existing studies computational costs significantly small allows application large corpora classified types first type heuristic measure similarity elements clustered interpretation probability resulting clusters guaranteed work effectively component statistical derived criterion learning process likelihood second clear criteria determine number methods depend specified prove troublesome proper
480	order boost translation quality ebmt based small sized bilingual corpus domain addition language model indomain monolingual conducted experiments evaluation measures bleu score nist demonstrated effect using possibility adaptation methods retrieves similar input expression adjusts obtain approach suitability target considered tried following types merging equally simply merged distinction preference multiple similarity retrieved lm make according assign probability sentence retrieval phase handled differently nearly highest probabilities sentences selected results similarities equal introduction machine adaptable new
481	present extension classic search procedure tabular pcfg parsing dramatically reduce time required best parse estimating probabilities completions discuss various estimates efficient algorithms computing average length penn treebank sentences detailed estimate reduces total number edges processed exhaustive simpler requires minute work unlike first finite beam methods achieving kind speed method guaranteed likely approximation parser implement upward propagating correct wide range control strategies maintains worst case cubic introduction bounds known dealing coverage grammars expensive practice primary types accelerating selection proposed roark ratnaparkhi strategy parses tracked moment linear arbitrarily fast reducing greedy actual viterbi pruned globally optimal locally stage grishman charniak collins intended item based framework builds figure merit items fom decide order agenda
482	translation compound nouns major issue machine frequency occurrence high productivity various shallow methods proposed translate notable memory based word compositional paper describes results feasibility study ability japanese english noun compounds introduction multiword expressions problematic idiomaticity overgeneration problems problem semantic syntactic markedness seen kick bucket large respectively occurs result failing capture idiosyncratic lexical affinities words blocking seemingly equivalent combinations target particular task outline techniques tackle carry detailed analysis viability naturally occurring data occur variability summary examination written component british national corpus nn types combined token bnc plot relative coverage frequently low account method described type figure vs stating highly linguistically differentiated
483	cross linguistic phoneme correspondences defined languages relatively closely related exactly way dialects accents single language paper present theory comparing traditional similar work using english inventory dutch german results vowels consonants unexpected information arose analysis cognate forms introduction cahill presented pilot study aim allow type generalisation permitted phonemes allophonic variation level higher idea represent identities share word equivalent cat largely identical different distinctive replaced sound accent construct universal set representing occurring particular supported grant transcriptions celex phonetic alphabet
484	martin advanced technology laboratories designing developing testing evaluating spoken language understanding systems unique operational environments past years experiences encountered numerous challenges making integral user operations paper discuss report respect number domains introduction model human interaction referred listen communicate lcs information requests communicates networked resources compute centered solutions shows tailored visualizations individual users figure deployment dialogue placing marine supply tactical vehicle creating include giving appropriate responses involves managing tension utterance brevity context response build trust similarly length utterances succinct convey correct adding signature robust handling vocabulary terms concepts able adapt noisy parameters change frequently input devices power access situation architecture galaxy
485	paper presents bootstrapping process learns linguistically rich extraction patterns subjective expressions high precision classifiers label unannotated data automatically create large training set given pattern learning algorithm learned identify sentences increases recall maintaining recognize emotional general nearly seeks information benefit able separate factual existing resources contain lists words empirical methods nlp identified adjectives verbs grams statistically associated language exhibited variety phrases addition terms occur infrequently strongly metaphorical idiomatic consequently believe subjectivity systems trained extremely text collections acquire vocabulary truly broad comprehensive scope address issue exploring allow learn collection texts research objective allows generate labeled second emphasis using represent richer flexible single apply representing
486	present comparative evaluation data driven models translation selection english korean machine latent semantic analysis probabilistic applied purpose implementation particular able represent complex structures given contexts text passages grammatical relationships stored dictionaries utilized essentially nearest neighbor learning select appropriate unseen instances dictionary distance nn computed estimating similarity measured lsa plsa experiments trec constructing spaces wall street journal corpus evaluating accuracy model selected relatively accurate translations experiment irrespective value types relationship structure fall theory method extracting representing contextual usage meaning words mainly indexing relevance estimation information retrieval area measure coherence texts applying basic concept vector representation cosine computation estimate word claimed represents similar ways based mixture decomposition linear algebra singular contrast variant sound statistical foundation defines proper generative
487	present framework statistical machine translation natural languages based direct maximum entropy models contains widely source channel approach special case knowledge sources treated feature functions depend language sentence target possible hidden variables allows baseline extended easily adding new significantly improved using model according bayes decision rule equivalently eq perform following maximization ei argmax introduction given fj translated sentences choose highest probability operation denotes search problem generation output notational convention follows symbol denote general distributions specific assumptions contrast generic referred mt fundamental equation typically favored
488	paper describes classifier assigns semantic thesaurus categories unknown chinese words focus differs ways previous research particular area prior focused proper nouns address focusing common adjectives verbs analysis sinica corpus shows contrary expectation features related word contexts context clearly important feature focuses non contextual play key role occur limited following ciaramita morphological similarity category known nearest neighbor approach lexical acquisition computes distance cilin based structure improves baseline categorization performance introduction biggest problem assigning lies incompleteness dictionaries impractical construct dictionary contain previously unseen corpora issue particularly problematic natural language processing applications work texts specifically chen articles average listed electronic novel created daily impossible collect furthermore newly coined
489	present new statistical methods evaluating information extraction systems developed evaluate political scientists extract event news leads international politics nature data presents problems evaluators frequency distribution types strongly skewed random sample typically fail contain low events manual necessary create evaluation sets costly effort coding high categories scheme overcomes considerably traditional allows interpret estimator estimate bias real generates severe discuss section circumvent using novel sampling briefly application finally advantages disadvantages relations standard procedure start brief review analysis introduction paper introduces approach study form categorization highly profile researchers quantitative performing mid extracted remained fairly simple researcher fills template historical documents list countries organizations actors articulated ontology occurred early automated
490	expressions paper describes approach machine translation places linguistic information foundation difficulty english japanese illustrated data shows influence various contextual factors method natural language transfer presented integrates rules constraints implemented results evaluation introduction examined problem translating main verb selected common colloquial forms large variety senses collocations idioms different containing extracted sentence corpus international travel domain expression manually translated general way possible target distinctions high quality automatic requires disambiguation highly ambiguous verbs correct handling non compositional idiomatic varying degrees view terms represented typed feature structures integrating pairs types extends capabilities current methods solves number key problems context construction copy shop door fax ni ga att loc nom exist translations necessary imposes finer semantic distinction state action described
491	paper describes machine learning based parsing question classification answering demonstrate type application parse trees semantically richer structurally oriented semantics treebanks offer empirically dramatically improves augmenting enriched penn treebank training corpus additional shift reduce parser previously developed translation applications particular section treebanking vastly improved accuracy questions tree extended include answer critical task presents experimental results qa typing finally potential sentences enhanced better matching introduction strong increase research identifies extracts answers large collection text unlike information retrieval systems return documents larger sections thereof designed deliver focused rock central australia russian nuclear trec form track evaluations specifically limited bytes webclopedia project usc sciences institute pursues approach pinpointing relies heavily covers numerous sentence candidates exact extracted parsed challenges faces
492	paper describes machinelearning named entity recognizer upper case text improved using mixed ner unlabeled tag additional training material approach reduces performance gap substantially muc test data method useful improving accuracy ners transcribed automatic speech recognizers information missing washington house expert securities laws leading candidate exchange commission clinton administration figure introduction propose trained labeled train message understanding conferences task consists labeling entities classes person organization location time money percent conducted experiments recognition showed improve results official applied normalized orthographic representation format
493	introduction astronauts iss spend great deal time performing complex procedures involves member reading procedure aloud performs task extremely expensive astronaut intelligent assistant designed provide cheaper alternative voice controlled control project challenging features including starting transcribed data actual target input language rapidly changing coverage functionality using regulus address challenges examplebased framework constructing portion recognizer allows make rapid changes advantage rule base corpus based information sources way able extract maximum utility small amounts initial available smoothly adjust accumulated course following sections application domain demonstrate latest version ongoing create international space station includes spoken dialogue navigation coordinated display text related pictures alarms recording notes demo exemplifies interesting component technologies speech recognition understanding developed source toolkit implements approach portable grammar modelling models derived single linguistically motivated unification specific cfg produced
494	paper presents revision learning method achieves high performance small computational cost combining model generalization capacity revise output apply english partof speech tagging japanese morphological analysis performs introduction corpus based approaches widely studied natural language processing tasks syntactic text categorization word sense disambiguation important issue decide various models hidden markov decision trees maximum entropy support vector machines getting supervised machine algorithm binary classification svms handle large number features applied presently electric industry successfully weakness general trade exists relatively hand hmms lower difficulty handling data higher practical prohibitive problem solve propose combines achieve
495	consider attributes text quality commonly mt evaluation intelligibility fidelity apply nlg appears transfer directly needs completely interpreted make crucial distinction symbolic authors end readers form textual feedback based controlled language specifying software requirements suited approach incrementally improving content model mature sister holds issues related readily recent experience evaluating producing multilingual versions user manuals raise questions best evaluate faithfulness output respect input specification introduction probably critical need addressed automatically generated texts actually say supposed fluent coherent clear grammatical answers important target point priori reason better worse result natural generation machine translation generator given assume appropriately adopt methods developed rating scales assess widespread
496	weighted finite state transducers suffer lack training algorithm harder assembled operations composition minimization union concatenation closure yields tricky parameter tying formulate parameterized fst paradigm algorithms including general trick cleanly efficiently computes expectations background motivation rational relations strings widespread language speech engineering despite bounded memory suited linguistic textual processes exactly approximately relation set pairs functions pair given input string fewer output class called admits nice declarative programming source code describing compiled efficient object optimized runtime size supports nondeterminism parallel processing infinite sets allows reverse computation unusual flexibility practiced programmer stems closed common define useful modify existing editing simply operating brief version work additional material first appeared journal length details prepared available entire generalized assign weight excluding weights represent probabilities joint
497	paper presents framework extracting english chinese transliterated word pairs parallel texts approach based statistical machine transliteration model exploit phonetic similarities words corresponding transliterations given proper noun proposed method extracts aligned text parameters automatically learned bilingual list experimental results average rates character precision respectively improved addition simple linguistic processing jason chang department science national university taiwan cs edu tw research language arabic japanese korean previous approaches focused pronunciation dictionary converting source symbols manually assigned scoring matrix measuring target heuristic rules unknown pronunciations cause problems using dependent penalty function measure similarity handcrafted mapping lead porting requires conversion trained unsupervised learning remainder organized follows section gives overview describes apply extraction
498	introduction device large buttons facilitate communications people idea decreasing number keys keyboard new realization keyboards recent popularity mobile machines researchers increasingly interested work related phones text entry current generation devices remains cumbersome innovative companies proposed predictive methods cient implementing method rst years earlier results studies ed technology looks promising context study goes cited tried various best know includes application language model carried approach examined additionally major contribution potential power examining actual section entered keypad figure shows gui visible central boxes plus button paper count characters right hand impose constraint
499	introduction important first step developing cross lingual question answering understand techniques developed english text work languages chinese described paper similar systems trec consists main components query processing module search engine answer extraction contains specific dealing language characteristics word segmentation evaluation using method based track results performance comparable version indicates heuristics applicable task number evaluated environment darpa tides program standard approach information retrieval relevant documents retrieved response parts contain useful actual typically indicated highlighting occurrences words contrast questionanswering identify passages containing possible extract history natural salton book detailed discussion relationship focus recent research extracting answers large databases technology major
500	paper presents overview robust broad coverage application independent natural language generation demonstrates different components function multilingual machine translation using languages currently working section provides description focuses core set rules describes additional layer included address issues brief evaluation method results mt process starts source sentence analyzed parser produces output syntactic tree input logical form module deep representation called lf basic relation types figure gives simple english gave john final analysis phase transfer extracts mappings target mindnet knowledge database applies produce pair repository aligned lfs portions alignment present context multi lingual developing hybrid rule based statistical performed linguistic parsers realization
501	readable dictionary thesaurus addition corpus unsupervised method word sense proposed bilingual parallel developed first extracts statistically significant corpora senses words text pairs related indicated counterparts guage aligning language order calculates correlation avoid manually tagging training data polysemous unlike previous methods using regarded clues determining pora require suitable finally instance availability large extremely selects contrast comparable available score sum correlations domains required appearing weak combination context overcome different languages domain acceptable problem ambiguity translingual alignment disparity types information useful wsd topical coverage lan major guages algorithm calculating grammatical characteristics iteratively devised disambiguated syntactically experiment wall street journal topically hon showed new
502	investigate single view algorithms alternative multi weakly supervised learning natural language processing tasks feature split particular apply training self em task selftraining fs new variation incorporates selection outperform cotraining comparatively sensitive parameter changes introduction paradigms learn classification small set labeled data large pool unlabeled using separate redundant views successfully applied number including text named entity base noun phrase bracketing statistical parsing theoretical performance guarantees fairly strong assumptions first sufficient given concept second conditionally independent class label conditions met blum prove initial weak learner boosted unfortunately finding satisfies means problem addition recent empirical results shown underlying effective factorization remains important issue successful application practice supplied users domain experts determine expected
503	claimed aspect compositional idioms literal language appear number interesting exceptions present idiomatic expressions derived compositionally sense fall class described jackendoff fake object draw tentative conclusions nature classification apparent furthermore suggest regarded aspectual composition include input thematic relations ary enjoyable time esp noisy manner phrase according intuitions web search using google engine combines readily temporal adverbials form sentences mary friends painted town red hours id board party bus paint combine making impossible interpret standard tests shows eventuality ignore reading measures contextually defined instant beginning painting consider verb
504	parse results method proposed second stage apply case analysis large corpus utilizing constructed frame dictionary upgrade incorporating newly acquired information conducted experiment upgraded evaluation showed effectiveness process paper proposes japanese handle complicated expressions double nominative sentences non gapping relation relative clauses change divided stages first construct automatically grammar introduction understand text necessary relations words required describes kinds cases verb nouns slot millions combinations hand arranging volumes coupling closest component iterative consists means gradual learning understood
505	phrasal verbs important feature english language properly identifying provides basis parser decode related structures challenge natural processing sit lexicon syntax traditional nlp frameworks separate module make handle problem paper presents finite state approach integrates verb expert shallow parsing deep morpho syntactic interaction precision recall combined performance benchmarked consistently identification basically solved presented method introduction needs address issue handling multiword expressions including sag proven based pattern matching using formalism called form third vocabulary machine readable dictionaries entries constitute illustrates solving section shows benchmarking analysis followed conclusions challenges defines problems intend solve tasks accomplish task definition first define support headed pv separated modularity considerations importantly labor
506	level relationship complex holds different syntactic salience factors providing evidence relation mutual labeled pos results antecedent discipline original version mozart corpus type precision better release result partly explained higher proportion definite nps similar findings researchers leass account structural parallelism computational linguistics volume number substitution important classes preference
507	educators interested essay evaluation systems include feedback writing features facilitate revision process instance thesis statement student automatically identified information reflect regard quality relationship discourse elements using relatively small corpus manually annotated data bayesian classification identify statements method yields results closer human performance produced baseline introduction automated scoring technology achieve agreement single judge comparable judges unfortunately providing students score insufficient instruction help improve skills need provide specific individual applicable factors contribute improvement refined sentence structure variety appropriate word usage organizational believed critical overall desirable indicate essays present guided list questions consider suggested experts provided addition instructional application utilize discuss types
508	approach improve bilingual cooccurrence dictionary word alignment evaluate improved using version competitive linking algorithm demonstrate problem faced present ameliorate particular clustering similar words language assigning higher score given single experimental results significant improvement precision recall effect morphological variants line related work research based similarities area active information retrieval community instance xu croft first clusters refines measure stemmer begin letters technique similarity scores ngrams measured number grams occurrences common clustered equivalence classes falls category algorithms proposed evaluated task melamed points cooccurrences sentence aligned data source target said cooccur occurs corresponding
509	present quantitative model word order movement constraints enables simple uniform treatment seemingly heterogeneous collection linear phenomena english dutch german complement constructions underlying scheme central assumptions psycholinguistically motivated performance grammar formalism declarative terms based typed feature unification pg allows language variations ordering discussion reduce different settings small number parameters introduction propose expressing structures tenets particular assumption realized late stage grammatical encoding process described scrutiny differences numerical paper organized follows section sketch hierarchical kernel describes linearization turn target languages finally contains conclusions root frame tree figure formed modifier segments obligatory np hd ro na know cm ate
510	paper describes application paradise evaluation framework corpus human dialogues collected darpa communicator data collection results based standard metrics additional qualitative derived using dialogue act tagging scheme performance models account variance user satisfaction addition improved absolute sites nist developed experimental design mitre set tools processing collect core making cross comparisons workshop committee included suggested implemented consistently systems contribution subjects implement specified experiment designed make possible apply integrates unifies previous approaches posits overall objective maximized task success various interaction costs predictors applying include differed considerably subsequent modeling gave insight satisfactory variables accounted completion duration recognition accuracy mean turn doing analysis
511	report sum project applies automatic summarisation techniques legal domain pursue methodology based teufel moens sentences classified according argumentative role experiments judgments house performed linguistic annotation small sample set order explore correlations features roles state art nlp perform using xml tools combination rulebased statistical methods focus predictive capacity tense aspect classifier investigating generating flexible summaries documents builds extends approach work paper deals judicial branch completed preliminary study judgment hand annotated processing link sentence primary type verb group properties end ofthe distinguish main subordinate clauses findings discuss implications process developing section provides brief background including overview description scheme
512	word prediction systems augmentative alternative communication productive processes compounding pose problem present model predicts german nominal compounds splitting modifier head components instead trying predict improved class based bigrams constructed using semantic classes automatically extracted corpus evaluation shows split compound leads improvement keystroke savings baseline preliminary results obtained integrating simple extremely low frequency causing data sparseness problems new differ types rare words typically decomposed common smaller units analyzed evening session frequent natural way handle productively formed treat primitive concatenation sort able newly occurred training constituents occur avoids specific type caused collects statistics building previous work baroni reported encouraging element predicted treating
513	paper present scoring sets concepts basis ontology apply task alternative speech recognition hypotheses terms semantic coherence conducted annotation experiment showed human annotators reliably differentiate semantically coherent incoherent evaluation annotated data shows successfully classifies german corpus followed description section contains kind knowledge representations employed algorithm corresponding given conclusion additional applications problem simple best hypothesis interface automatic natural language understanding suffices restricted dialogue systems complex operate lists asr output convert word graphs distribution acoustic model scores user expressed wish specific city map ich die looking ensuing list constituted suitable representation utterance adequate thereof eine facing multiple single
514	present approach automatically learning paraphrases aligned monolingual corpora algorithm works generalizing syntactic paths corresponding anchors sentence pairs compared previous work structural generated tend longer average capable capturing distance dependencies addition standalone evaluation question answering application currently development benefit learned introduction richness human language allows people express idea different ways words refer entity employ phrases concept acquisition alternative convey information critical natural applications effective equipped handle variations able respond differently phrased questions resources help systems deal single word synonyms wordnet multiple domain specific manually collecting time consuming impractical large scale attention focused techniques acquiring unsupervised method fragments trees roughly semantically equivalent produced similar rules advocated katz levin disagreement regarding exact definition operating interchangeable configuration structures specify synthesis developed barzilay
515	novel bootstrapping approach named entity using concept based seeds successive learners presented requires common noun pronoun correspond targeted ne man woman person procedure implemented training first decision list learn parsing rules hidden markov model trained corpus automatically tagged learner resulting approaches supervised performance types chunking classification unsupervised learning systems including need focus assuming chunks constructed parser paper presents new follows learned high precision limited recall applied large raw generate finally hmm tagger unlike involve iterative suffers error propagation commonly associated derive share grammatical structures corresponding nes utilized support pronouns nouns occur instances iteration avoid benchmarking shows taggers proper
516	paper compares different ways estimating statistical language models nlp tagging parsing estimated maximizing likelihood fully observed training data applications require conditional probability distributions principle learnt somewhat surprisingly joint superior intuitively access information given corpus maximum estimate argmax turns estimation method maximizes pseudo consistent distribution model parameters introduction involve finding value hidden variable word string typically thank eugene charniak members comments suggestions fernando pereira especially generous acl reviewers able follow research supported nsf awards nih award mh figure graphically depicts difference mle let universe possible pairs
517	readily available line text reached hundreds billions words continues grow core natural language tasks algorithms continue optimized tested compared training corpora consisting million paper evaluate performance different learning methods prototypical disambiguation task confusion set trained orders magnitude labeled data previously fortunate particular application correctly free case examine effectively exploiting large cost introduction machine techniques automatic ally learn linguistic information online applied number problems decade percentage papers published area involve comparisons approaches commonly increasing dramatic rate size typically standardization sets field problem choosing correct word given confused include principle principal weather numerous presented confusable recent includes latent semantic analysis transformation based differential grammars decision lists variety bayesian classifiers
518	present spoken dialogue designed implemented virtual focal environment architecture based agents using propositional attitudes natural language understanding component typed unification grammar commercial speaker independent speech recognition current application aims facilitate multimedia presentation military planning information semi immersive introduction paper communicating future operations centre analysis laboratory australian defence science technology organisation experimenting conversational characters access multi media conduct particular unlike telephone systems mainly created new applications command control generally seek simulate domain require established paradigm shift environments superior capability greater situation awareness facility experiment innovative technologies support goal running years contains large screen reality primary display allowing vast quantities displayed described dimensional talking heads head upper portions body represented expression movement certain autonomous behaviours gaze factors combine add life likeness create engaging interaction users presenting commercially demonstrated
519	paper describes web based english chinese concordance totalrecall developed promote translation reuse encourage authentic idiomatic second language writing exploited structured existing highquality translations bilingual magazine build text novel approaches provide high precision alignment sentence phrase word levels browser user interface ease access internet users search expression facilitates recording actions data research learners pierre isabelle pointed contain solutions problems resource particularly useful convenient available proved popular french provides familiar need type question list citations finds additional feature making solution easily recognized related counterpart highlighted extends memory technology interactive tool intended translators non native speakers trying ideas properly express allow initiative queries searching contemporary single words phrases expressions
520	paper investigate surface text patterns maximum entropy based question answering collected automatically unsupervised fashion using collection answer pairs seeds generate features statistical report results trec set km database represents corresponding ones card game filtered retain questions look similar presented task qa country troops led salt india gandhi introduction systems investigated born typical answers suggest formulated regular expressions select phrase approach learning correspondences ibm probabilistic model trainable sentence training performed bag words syntactic entity employ explore inclusion framework construction pattern extraction
521	paper elucidate korean temporal markers oe contribute specifying event time formalize terms typed lambda calculus present computational method constructing representation sentences basis grammar proposed instructions locate agree second point view observed tense fail provide solid coherent way capture relevant span verbal infix generally considered typical past marker brings interpretation possibilities simple completion resultant state je demonstrators nom clock city hall acc pa dec surrounded day introduction associated np build adverbials morning han hour widely known play important roles sentence meaning processing significant divergence opinions aspect efficient indicator leading correct kim jo credible index consult establishing complementary regarded
522	syllable word conversion important chinese phonetic input methods speech recognition major problems stw resolving ambiguity caused homonyms determining segmentation paper describes noun verb event frame identifier solve effectively approach includes nvef pair identifiers non portion experiment showed able achieve accuracy related combining overall result study indicates knowledge powerful fact numerous cases requiring disambiguation natural age processing fall chicken egg situation employed general tool systems disambiguating independently using fundamental basis treat remaining shows likely nlp expand coverage extend occurrence restrictions pairs adjective adverb believe improved additional introduction created past currently popular method based symbols requires training taught write corresponding pinyin character primary school distinct characters syllables homonym problem severe intelligent
523	representations studies intonational categories prosodic structures instance vectors values book starts introduction introduces articles puts perspective especially respect work sta bruce pierrehumbert article excellent survey model intonation suitable introductory course pages condensed version historical development major framework outlines issues changed views researchers section describing influential swedish contribution theory embodied concept sentence represented sequence tones central theoretical interpret continuous phonetic data link discrete phonological reviews arguments representation using surrounding assignment accent provides crucial argument multiple levels tonal goes follows successive tone clearly sounds distinct languages distinctions demonstrated pitch allowed performance factors utterance length represent level phonologically conventional proposed early predetermined number matter coherent treatment minimal case implement phonemic models predict gradient
524	support vector machines achieved state art performance classification tasks article apply identification semantic annotation scientific technical terminology domain molecular biology illustrates extensibility traditional named entity task special domains extensive terminologies medicine related disciplines illustrate svm capabilities using sample journal abstracts texts human blood cell transcription factor medline approximately terms annotated model performs score cross validation tests detailed analysis based empirical evidence shows contribution various feature sets introduction rapid growth number published papers fields growing application information extraction help solve problems associated overload benefit medical sciences enabling automatic facts prototypical events contained patient records research articles regarding processes affect health populate databases aid searching document summarization variety require intelligent understanding contents aim method identifying classifying extension defined darpa sponsored message conferences aimed acquiring shallow building blocks contribute high level text study looks semantics captured
525	multi document summarization documents collected extended period time subject changes paper focuses shift presents method extracting key paragraphs discuss event extraction results tracking starts sample finds subsequent tested tdt corpus result shows effectiveness introduction news stories differs single important identify differences similarities interpreted question according project occurs specific place associated actions background hand refers theme factor typical stream recognizing handling extracted based include main points resulting summary contains overlapping information technique automatically detects produces optimal window size training data sufficiently related current idea target
526	paper address issues related building large scale chinese corpus try answer questions speed annotation maintain high quality purposes applicable finally future work anticipate introduction penn treebank ongoing project objective create segmented annotated pos tags syntactic brackets first consists xinhua newswire years totaling words fully tagged syntactically bracketed released public linguistic data consortium preliminary results phase reported xia currently second word ctb developed expected completed early follow standards set segmentation tagging bracketing guidelines articles peoples daily hong kong material translated languages addition effort sources availability changed approach considerably existence able train new automatic language processing tools crucially corpora training preprocessing development control accuracy usability specifically attempt
527	ordering information critical task natural language generation applications paper propose approach particularly suited text model learns constraints sentence order corpus domainspecific texts algorithm yields likely alternatives evaluate automatically generated orderings authored human subjects asked mimic assess appropriateness multidocument summarization adjacency facts derived naturally occurring constraint satisfaction tree maximal weights space possible trees mellish advocate stochastic search alternative exhaustively examining requiring global optimum genetic select coherent people understand problem finding acceptable arise solely concept emerging field require form structuring single question answering note typically assume rich semantic knowledge organized structures communicative goals case document position provide cues respect summary sentences selected different documents ordered produce involve
528	discuss named entity recognition models characters character grams exclusively important data representation first model level hmm minimal context information second maximum entropy conditional markov substantially richer features best achieves overall english test number represents error reduction word internal yarowsky prefix suffix tries knowledge incorporating new section sequence free classifier gram substring finally add additional maxent chain tagging earlier ner work figure shows graphical emitted time state identity depends previous current addition view convenient think local emission type directly based proper classification engine described primary transition chaining allows segmentation using evaluated tasks want multiple single receive different labels avoided ways explicitly transitions words
529	increasing amounts electronic information available increase variety languages produce documents type problem manage similar different arises paper proposes approach processing structuring text multilingual authoring effectively carried work funded european union applied news agency methods natural language especially extraction technology monolingual approaches specific inflexible automatic improved create hypertextual organisation kind added value embodied contrast retrieval paradigms activity items streams detecting extracting relevant accordingly organising texts non linear fashion systems ones participating message understanding conference oriented phenomena restricted domains scope wider structure provide navigation guidelines final user suggestions architecture presented based knowledge intensive large scale general robust resources introduction modern technologies faced selecting filtering managing growing access critical traditional selection developed
530	paper presents techniques multimedia annotation application video summarization translation tool allows users easily create including voice transcripts scene descriptions visual auditory object module transcription capable multilingual spoken language identification recognition description consists semi automatically detected time codes scenes created tracking interactive naming people objects text data syntactically semantically structured using linguistic proposed works multimodal document generates versions content different languages introduction digital prevalent information source volume growing huge numbers hours required effectively browse segments missing significant annotating semantic segment structures metadata necessary advanced services natural transcript highly manageable speech processing essential role developed automatic integrating method analysis methods include color change detection characterization frames similarity frame attributes related approaches mpeg effort moving picture experts group iso dealing
531	paper considers assumptions conventionally signatures typed feature logic potential disagreement current practice grammar developers linguists working based frameworks hpsg meet unique introduction absence subtype covering discusses conditions restored realistic exist type expression description language ale components partial order types set features appropriateness declarations antecedent constraints signature relative descriptions interpreted make structure interpretation sake generality efficiency simplicity generally accepted representational accuracy advocated need implicational general necessary convenient universally observed formal addresses deal tractable manner semi lattice implies consistent pair upper bound appropriate structures non maximally specific
532	paper gives overview typology dialogue acts annotating estonian spoken dialogues problems classification determining considered aim develop interact user natural language following norms rules human communication corpora systems development distilling method implemented simplify real principles introduction describes classifying general domain problem oriented machine main goal model underlying solutions presupposition participants restrictions work simpler ones requirements developing act analysis first people actual conversations secondly make possible differentiate functions thirdly utterances linguistic realisation different known typologies decided fully correspond needs coding schemes types category design readability manipulation type important
533	address problem transliterating english names using chinese orthography support cross lingual speech text processing applications demonstrate application statistical machine translation techniques translate phonemic representation obtained automatic sequence initials commonly subword units pronunciation model map initial final characters present evaluation module retrieval mandarin spoken documents tdt corpus queries especially important carry distinctive information query relatively low document frequency finally interactive ir systems users provide importance grows unlike specialized terminology proper amenable inspired approach tries writing foreign ones language preserve way sounds orthographic read aloud speaker process referred transliteration mechanism available render say form convert string first step addressed extensively obvious reasons synthesis literature paper describes second proposed recent past providing comprehensive survey highlight representative approaches finite
534	present set algorithms enable translate natural language sentences exploiting translation memory statistical based model results automatically derived framework translations higher probability using solely produced significantly better commercial systems hybrid translated perfectly test collection introduction decade progress fields machine ebmt work modifying existing human instances stored methods proposed storing pairs finding relevant translating unseen integrating fragments produce correct outputs sato stores complete parse trees selects generates new performing similarity way store generated similar input sentence phrases optimally partitioning match partial matches choosing best possible multi engine exceptions smt couched noisy channel source let say english assumed probabilistic current
535	measure incorporates factors including perception production consideration contrast duplicated fitness function reason discrepancy mentioned preceding paragraph empirical studies tone available consider individual objective expect allow better predictions conclusions discussion article apply optimization models using study configuration vowels systems approach similar previous explanatory vowel certain criteria assumed principles governing structure sound predict optimal criterion considered objectives combined single weighted simple ga model adopts combine perceptual ranking method markedness complexity simultaneously combining scalar priori knowledge weights necessary advantage obtain set results instead generates likely actually observed consistency predicted current
536	paper discuss need corpora variety annotations provide suitable resources evaluate different natural language processing systems compare supervised machine learning technique presented translating syntactic formalisms applied task penn treebank annotation categorial grammar compared current alternative approach results indicate broader coverage using compact correctly annotated version vital evaluation large number nlp tasks unfortunately suitably given provides corpus syntactically wall street journal excellent resource dealing syntax written english formalism match suppose parser developed bracketing bear strong relationship labelling lexical items inner nodes tree entirely possible intuitively plenty information available fact required wrong form obvious useful tool present translates standard phrase structure process induces
537	work automatically building knowledge structures text apply machine learning determine clauses multiple narratives describing similar situations grouped descriptions type occurrence approach problem textual similarity context training data partial parser present results evaluating cohesiveness aggregated brief overview fits overall introduction early natural language processing included ambitious research representation information commonly experienced concept script introduced explain people understand make inferences stereotypical sequence events occur larger situation infer missing details description essence providing means extracting actually scripts includes demonstrations hand built sketchy adjustment using genetic algorithm schemata constrained circumstances pursues goals indicated explicitly common types newspaper stories incident reports appears support conclusion investigating event correlations appropriate extractable structure general sequences reliably recur instead look reliable small number goal extract correlated
538	argue detection entailment contradiction relations texts minimal metric evaluation text understanding systems intensionality widespread natural language raises number issues aside clausal representation derived approaches formal semantics permits extended range intensional entailments contradictions detected introduction appropriate metrics evaluating performance probably universal measure suffices leading collection different facets paper makes case inclusion particular portions key data traditionally viewed branch linguistics ability recognize semantic clearly sufficient criterion able tell sentence follows necessary understand sentences contradictory civilians killed suicide bombing died conversely fail understood proposing first measures real useful important facet correlates develop applications second
539	automatically acquiring synonymous words corpora challenging task methods kind resources inadequate low precision recall improve performance synonym extraction propose method extract synonyms multiple including monolingual dictionary bilingual corpus large approach ensemble combine extracted individual extractors experimental results prove complementary effective introduction paper addresses problem extracting english parallel number nlp applications information retrieval question answering employed bridge expressions gaps query space document automatic text summarization identify repetitive order avoid redundant contents summary language generation create varied texts knowledge studies investigating combination different investigate resource frequently contexts investigated discover extracts word pairs cat dog similar
540	paper proposes empirical approach development computational model assessing texts according cohesiveness argue nlg technologies generation structural paraphrases efficiently create cohesion variant parallel corpus serve resource acquisition criteria present pilot case study particular type paraphrasing separates relative clause sentence created containing cohesive instances based conducted preliminary experiment evaluation obtaining encouraging results introduction nlp tasks translation summarization text produces output important criterion performance collection syntactically semantically formed sentences required discourse level relations entities contained properly realized means linguistic devices halliday hasan types english reference ellipsis conjunction lexical needs know effectively research communities fact increasingly getting concerned notion intra sentential processing make progress marcu transforming rhetorical structures source target languages aiming improvement quality mani incorporate revision process commonly
541	paper introduce generative probabilistic optical character recognition model describes end process noisy channel framework generation text transformation output ocr designed error correction focus post processing black box systems order make useful nlp tasks present implementation based finitestate models demonstrate ability significantly reduce word rate provide evaluation results involving automatic extraction translation lexicons printed introduction great deal available electronic form vast quantities information exist primarily print critical applications technology rapid rough document field retrieval scanned documents depend heavily quality comments concept raw image database attractive comprehensive solutions require complete accurate conversion machine readable continue elusive practical unfortunately commercial perfect especially language question resource poor efforts acquire new resources using face chicken egg problem compounded fact boxes allow user tuning training lack rapidly languages largely monolithic structure current specific constraints deeply code
542	statistical machine learning algorithms successfully applied natural language processing problems compared manually constructed systems nlp easier develop maintain annotated training text required data underlying algorithm build model annotations future predicted performance depend heavily characteristics apply different degradation occur paper examine issue empirically using sentence boundary detection problem propose compare methods update moving domain investigates methodological practical aspects issues ideally study include possible linguistic reality undertaking carry hide essential observations obscure important effects variables alternative relatively simple understood try gain understanding fundamental causal easily isolated identified fewer affect outcome experiments second approach focus specific properties readily applicable similar specifically perform
543	empirical comparison cfg filtering techniques ltag hpsg presented demonstrate approximation produces effective filter investigate reason difference introduction various parsing developed lexicalized grammars tree adjoining grammar head driven phrase structure independent development individual formalisms adapted realizations exhibit different performance formalism identify algorithmic causes reveal advantages disadvantages allow integrate generic technique yields advancement community paper compare following approach key idea strongly equivalent generate parse results input obtained conversion demonstrated parsers predict possible trees approximated given interesting filters bring time complexity investigating ways context free way optimization performed existing using converting ltags extracted penn treebank
544	paper discuss approach establishing model acquisition english grammatical structures users language tutoring designed deaf american sign explore correlation corpus error tagged texts holistic proficiency scores assigned experts order draw initial conclusions errors typically occur different levels population lower presumably represent constructions acquired higher provide insight forms range morphosyntactic work second instruction icicle generated need modeling account results analysis undertaken fulfill overview intelligent currently development primary function tutor students written essential performing ability correctly analyze user produce tutorial feedback student performance correct tailored competence target learners native distinct view skills cycle input response beginning piece writing reviewed determines responds aimed enabling perform corrections
545	present novel disambiguation method unification based grammars contrast methods approach obviates need probability models ubg shifts responsibility simpler context free indirectly obtained advantages training effectively practice parsing readings requires cubic time involved distributions mathematically clean experiment mid size feasible using unsupervised achieve accuracy exact match task introduction paper deals problem disambiguate sentences analyzed given grammar apparently different approaches formalisms market tackle common try model distribution rank competing analyses sentence briscoe carroll eisele abney bod kaplan johnson osborne bouma unfortunately proposed probabilities possible sum value discussed intensively addition newer log linear outlines loglinear prevent application dynamic programming computation probable parse complex features incorporated run complexity algorithm
546	investment effort years begun produce wealth data concerning computational psycholinguistic models syntax acquisition generated running simulations completed database word order patterns abstract languages article presents design contains sentence grammars derivations test widely divergent paradigms domain linguistically motivated current syntactic theory validated psychologically plausible checking frequency occurrence corpora child directed speech small case study simulation presented gold berwick research learnability valuable ongoing disadvantages formal modeling language certain proofs involve steps large domains complex readily lend deductive provide intermediate stages typically prove learnable priori specific trials generally require simplifying assumptions distant natural studies limitations notable practicality carried severely allow researcher hone particular model handles grammatical features single successful demonstrate algorithm able acquire aspect structure
547	paper presents natural language processing based linguistic analysis tool developed japanese second teachers program detector aims promote effective instruction anaphora basis hypothesis ideal conditions acquisition making invisible zeros visible written narrative discourse input provides specified texts underlying structures output evaluated performance terms detecting accuracy present experimental report validity practical result proven pedagogically feasible impact introduction emerging technology variety real world applications assisted learning teaching area nlp techniques contribute range indexing concordancing morphological demand dictionary look ups syntactic diagnostic error work level phenomena including pronouns referential noun phrases overtly expressed nps omitted recoverable given context relevant knowledge common poses challenge learners accurate comprehension sounding production fail understand passage correctly difficulty identifying antecedents produce grammatically correct unnatural textbooks provide systematic intensive exercises overcome difficulties consequently rely
548	title generation complex task involving natural language understanding synthesis paper propose new probabilistic model different previous statistical models treat process converts document representation information directly introduces hidden state called source divides steps step distilling observation generating estimated experiment outperforms terms automatic evaluations human judgments introduction compared provides compact helps people quickly capture main idea time details requires finding words reflects content demands ordering selected readable sequence involves nature distinguishes seemingly similar tasks key phrase extraction problem word phase goal selection appropriate order framework proposed mittal accomplished using ngram predict probability frequently
549	xml tokenisation tagging mark tools prepare corpus parsing techniques generally applicable focus medline abstracts wide coverage grammar hand crafted grammars inevitably lack failures inadequacies lexicons method gaining degree robustness interfacing pos tag information existing lexicon provide sophisticated approach pre processing helping ameliorate real language data improve parse performance introduction field technology currently distinct strands research points contact shallow chunking induction statistical syntactic analysers treebanks systems semantic approaches extensions analysis relative infancy deep strand main problems inadequate reliable select correct paper ongoing hybrid technologies address problem section modified look procedure utilise ofspeech lexical combine variety nlp process point start useful work described sections enabled paradigm converted
550	introduce probabilistic model question answering exploited context end qa noisy channel outperforms stateof art rule based similar resources propose flexible accommodate mathematical framework specific techniques range exploitation wordnet structured semi databases reasoning paraphrasing impossible understand contributes performance doesn paper new approach contribution various components easily assessed fundamental insight departs significantly current architectures core pipeline modules ir engine retrieves set documents sentences contain answers given answer identifier module sentence identifies sub string sa likely assigns score finding amounts selecting highest view explicit researchers implicitly present systems aware simplest form accepts assess likelihood contains measuring cosine similarity research demonstrates word overlap metric
551	study examines usefulness common shelf compression software enhancing existing summaries producing scratch algorithm works removing repetitive data file order compress able determine sentences summary contain judging size sentence compared picking increased hypothesized gain new information hypothesis cases varying degrees hand particularly multidocument summarization redundant presence redundancy lead lower score proportional degree overlap maximal marginal relevance method paper idea multi document want explore techniques identifying using better areas nlp biggest challenges deciding way calculating similarity groups extractive goal select best represent main point documents pick selected accomplish task comparison researchers relied stemming counting gram
552	paper presents motivations organization acl eacl workshop sharing tools resources research education concentrating possible connection repositories papers printed volume natural language software basis outline steps nlp tool order achieve goal introduction main discuss methods improvement extension existing briefly address central discussion point nl base proceedings necessity clearly recognized past topic addressed broader context conference essentially concerned question identifying supply according different describing approach mainly functionalities new version showing overcome practical problems encountered discussing problem proposing taxonomy user oriented versus developer coarse grained fine classification way strategies cooperate sure need establishing cooperation distinct approaches
553	paper first prototype pattern based analyzer developed context project pivot speech translation organize stay area consists dialogue act list possibly argument values form qui correspondent des arguments parole est en les que cette version du mis applies phrase spotting mechanism recognition output une valuation sur corpus dialogues non pour le module finds formed phrases corresponding built according instantiated client sont dans la section cet article nous qu ils features input current involved evaluation campaign unseen consisting turns results given think way future enhancements coverage development methodology introduction framework nespole funded eu nsf exploring applications automatic commerce sum contexte technique
554	support summarization automatically transcribed meetings introduce classifier recognize agreement disagreement utterances utilizing word based prosodic cues hand labeling efforts minimized using unsupervised training large unlabeled data set combined supervised small asr transcripts wer recovers nearly agree disagree confusion rate language models syntactic structure discourse history work informed studies departs significantly exploring techniques approach introduction integral component life organizations records important helping people recall place meeting audio recordings offer complete record interactions listening recording impractical facilitate browsing useful annotate topic participant interaction characteristics focus specifically identifying categories particularly decisions inferring controversial automatic addition detecting associating action items participants understanding social dynamics study detection contrasting results labels thought sort speech act categorization classification acts subject builds showed features classifying lead increased accuracy look prediction
555	cs columbia edu kathy introduction
556	demonstration built topic detection tracking technology monitors stream news stories organizes clusters represent topics presents user visually describes changes occur time mark certain interesting tracked easily tdt background research program investigates methods organizing arriving discuss ned set follow seminal event world contrast broader subject based notion particular airline crash fall organization arrive variations task allow nal organizational decisions postponed minutes hours days formal evaluation includes following tasks segmentation separate television radio distinct process needed newswire services pre segmented putting broad new appears create total number known advance carried supervision knows actually belong initial small
557	present semantic tagging temporal expressions discuss information conveyed extracted performance evaluated wrt small hand annotated corpus news messages introduction paper describes extracts defined chunks text express sort direct inferred set investigated includes dates prepositional phrases containing time expression verbs referring situation related work mani wilson focuses core neglecting prepositions main tagger employs finite state transducers based written rules trained economic articles obtained german papers online agency syntactic classification representation proposed clear cut distinction process interpretation maintained advantage approach second level created represents meaning inferences particular relations drawn establishing events mentioned article ultimate goal enterprise current stage analysis progress focus anchoring absolute line substantial subset semantics eventually cover
558	paper introduces computational framework visual perception grounded language acquisition called experience based ebla watch series videos acquire simple nouns verbs corresponding objects object relations acquiring perform basic scene analysis generate descriptions novel performance evaluated accuracy speed generated test set animations average success rates high description larger real lower rate attributed wide variance appearance systems capable learning event labels first known using vision introduction traditional research fields natural processing linguistics speech recognition synthesis great progress allowing computers process typically address perceptual understanding meaning context given word solely words logical relationships make clearer consider following webster definition apple rounded red yellow fruit tree rose family approaches able determine
559	present corpora annotated mainly syntactic knowledge paper attempt build large corpus annotate semantic dependency grammar believe words basic units semantics structure meaning sentence consist series dependencies individual built compared ambiguity problem strategy improve consistency addressed congruence defined measure tagged finally compare known introduction research tools investigators natural language processing play important role investigating diverse phenomena building statistical models evaluating comparing kinds parsing function tags added penn treebank skeletal parsers evaluated chinese phrase instance annotation scheme based proposed small testing limited work languages berkeley started framenet project produced frame descriptions thousand english lexical items backed description semantically contemporary available valuable databases describing
560	objectives explore phenomenon adjectival modification biomedical discourse genres literature patient records methods modifiers removed phrases extracted corpora original adjectives resulting compared normalization quantitative comparisons performed domain qualitative subdomains results average number phrase equivalent adjective types medline disorders procedures disorder common account occurrences corpus analyzed discussion potential applications approach discussed terminology acquisition information retrieval genre characterization previous studies demonstrated feasibility using nlp techniques shallow parsing identifying hierarchical relations terms extending existing authors explored clinical note based empirical observation data accompanied including make distinction operational administrative appears class consists primarily provide specific regarding condition distributed scale suggest kept separate order avoid combinatorial explosion idea step believe encountered receive special
561	natural language processing systems viewed intelligent able make verification validation approaches methods developed community paper addresses engineering infrastructure issues considering standard fundamentally different evaluation practices commonly nlp proposes practical applying context argue performed nl improved allows consider carried software methodologies research extends first author earlier work testing expert areas speech recognition understanding generation synthesis information retrieval extraction inference practice means building model human activities various tasks clearly view forms draw science area suffered multiplicity definitions ensuring correctly implements specific functions satisfies specification determining customer requirements examined order account
562	investigate optimal lm treatment abundant filled pauses spontaneous monologues professional dictation task questions addressed deal fp history extent distinguish positions high low likelihood results differ partly observations reported dialogues discarding histories clearly improves performance local perplexities word rankings following suggest indicate hesitations restarts proper prediction allows probability recognition experiments confirm improvements perplexity studies introduction speech disfluencies characteristic different disfluency types distinguished uh um repairs repetitions widely accepted considerably degrade unexpected sequences acoustic confusability function words publications paper instead reports analyses medical focus dominant data appear mainly associated opposed prevent interruptions dialogue partner speaker searching formulation central language modeling helpful sentence continued interruption complete preceding misleading conditioning better switchboard predicted
563	aim talk extent work text generation address fundamental problems people generating language substantiate claim tasks research carried years discourse planning lexicalisation structure driven processing thirdly triangular relationship messages structures goals changing affect present idea effect specific propositional conceptual configuration produce lack theory tend mind order exhibiting potential links discover later reorganize reveal reader writing thinking points crucial existing theories really able account imagine complex recognize fact causal link events don solid causality leave method interaction know texts generally result reasoning case emerges major shortcoming techniques model data rhetorical effects communicated global tremendous coherent devoted
564	statistical machine translation correspondences words source target language learned bilingual corpora basis called alignment models existing systems mt treat different derivatives lemma independent paper argue better exploitation training data achieved explicitly account interdependencies directions usage hierarchical lexicon introduction equivalence classes order ignore information relevant task improvement results demonstrated german english corpus approach widely accepted years successfully applied realistic tasks various national international research programs applications small amounts available desired domain pair highly desirable avoid parts costly collection process recent publications dealt problem scarce resources dictionaries report experiment groups including using assume absence linguistic knowledge sources morphological analyzers human mind capable deriving dependencies morphology cognates proper names spelling variations capability finally produced humans compared based additional complex reasoning directly accessible word form representation
565	paper addresses issue designing embodied conversational agents exhibit appropriate posture shifts dialogues human users previous research noted importance hand gestures eye gaze head conversations humans present analysis monologues suggests predicted function discourse state conversation basis findings implemented agent way generate perspective seen signal floor available correlate content accompanying language better understanding role nonverbal behaviors conveying structures enables improvements naturalness dialogue systems contributing algorithms recognizing structure speech work addressed major body correlates topic background computational linguists begun examine association section review non discuss employed formulate natural generation clauses descriptive accompanied tends occur phonologically prominent syllable shown ambiguous situation noise listeners rely introduction provides empirical support relationship
566	paper presents formal analysis large class words called alternative markers includes appear frequently dialog attention present natural language search engines perform poorly queries containing performance engine improved dramatically incorporating approximation compatible operational semantics value approach applications improve larger improvements possible case particular constrain space appropriate answers syntactic argument phrases closely bound noun phrase refer connected free dog likes going walks discussed depth forms despite fact current handle ignoring worse treating marker absent define correct makes absolutely necessary correctly interpret ir application user requires countries web browsers netscape similar properties conform wrong feature presuppositions
567	speech interfaces question answering systems offer significant potential finding information phones mobile networked devices demonstration spoken using commercial dictation engine language models customized questions web based interface allowing quick correction errors domain freely available small evaluation effect recognition precision answers returned make concrete recommendations modifying improving robustness input concludes tend limited lexical structure exploited accurate text prediction test result real acceptable related research introduction paper demonstrates multimodal asking retrieving set likely particularly appropriate screens display general pages documents pc commonly lines candidates argue traditional document retrieval method existed inputting reasonable time study kupiec xerox labs built earliest speaker dependent isolated word recognizer electronic encyclopedia reason reported success simple exploit observation pairs words occurring source keywords query later cmu
568	demonstrate spoken dialogue interface field assistant developed nasa mobile agents project consists robot agent helps astronaut space suit conducting exploration primary technical relating systems arise speech recognition noise microphone recording voice annotations capable discriminating intended purposes start tracking coordinates bio seconds current location create new sample bag label note begin originated dry bed pause continue created associate play associated table utterances introduction component studying technologies techniques work practices sophisticated human cooperation environments surface mars evolution development evaluation occurs series increasingly complex tests analog earth assists tagging samples pictures descriptive associations images help track progress survey
569	ibm model conditional generative generates english sentence given foreign process word duplicated times according probabilities fertility table translated french translation position moved offset probability distortion conditioned classes giza automatically detected bilingual clustering algorithm dominates parameter space vocabulary size grows paper focus reduce apply additional methods lemmatization lexicon extraction described expect advantages reducing memory usage allows training data improve ratio accuracy alignment say followed making follow make il que ces le lieu les ce figure lemmatizer ensure children receive
570	ambiguity high location names cities named buffalo country canada brazil china city usa main street needs handled refer visualization related extracted events paper presents hybrid approach normalization combines lexical grammar driven local context constraints graph search maximum spanning tree integration semi automatically derived default senses focus resolving ambiguities following types island town province results promising accuracy test collections introduction task identify correct sense possibly ambiguous entity nes including new york state properly converting normal form support profile construction event merging work partly supported grant air force research laboratory information rome ny contract unrestricted text kernel modules ne tagging output tokenizer linguistic pos type job change keyword company microsoft person mary position sales beijing replaced
571	general research aim extract actual intentions persons respond ended questionnaires include desire make requests expressions forth focus extracting intention request first judge responses contain intent step developed criterion judging existence based paraphrasing described paper assumption response paraphrased typical expression evaluated terms objectivity effectiveness demonstrated showing machine learning methods learn set tagged data judgments annotators reasonably consistent intuition agree means necessary achieve experiments indicate reliably introduction aspect society know knowing plays important role allowing identify solve problems improvements recent years spread electronic devices personal computers internet allowed save machinereadable texts basis development conducted element technology
572	paper attempt apply ibm algorithm bleu output different summarizers order perform intrinsic evaluation objective experiment explore metric originally developed machine translation assessing type reliably changing text evaluated automatically generated extracts setting conditions parameters according idiosyncrasies task feasibility porting natural language processing research areas test furthermore important conclusions relevant resources needed evaluating summaries effect running original document target summarization informative reduced version sets documents form abstract extract abstracts present overview main points expressed consist number sentences directly source fact nature carry single sentence qualities lead conclusion trivial compared needs able evaluate content terms grammaticality semantic equivalence quality characteristics demanding critical idiosyncratic aspects render
573	semantic knowledge base contemporary chinese large scale resource developed institute computational linguistics peking university provides information hierarchy collocation features words english counterparts pos classification represent latest progress language engineering descriptions attributes fairly thorough comprehensive authoritative paper introduces outline indicates effective word sense disambiguation mt applications likely important general processing key lexical lexicography wsd engaged research development years lexicon building project collaboration computing technology academy sciences resulted machine readable bilingual suitable translation contained complete characterization valence specifications properties thousands conducted department present great extended entries quality improved updated edition provide rich various nlp structure introduction resources play role areas
574	demonstration motivate significant properties galaxy communicator software infrastructure support goals darpa program keys scripting capabilities hub allow programmer insert simple tools filters convert data formats make modify message flow control real time simplicity passing build systems bit standard allows develop platform independent service standards recognition synthesis better understood resources members contribute generally useful participants illustrate number keywords spoken dialogue speech interfaces introduction second intended push boundaries enabling freer interchange human machine crucial technology provides common development initially designed constructed mit maintained enhanced mitre corporation highlighted distributed spoke compliant servers java python lisp based style supports routing
575	paper describes initial evaluation systems answer questions seeking definitions results suggest humans agree sufficiently basic concepts included definition particular subject permit computation concept recall computing precision problematic using length characters crude approximation nonetheless sufficient correlate subjective assessment quality trec question answering track sponsored series evaluations abilities closed class domains fact based qa relatively simple response meaningfully judged binary scale right wrong increasing complexity type slightly significantly increases difficulty partial credit responses accommodated arda aquaint program research initiative department defense aimed kinds automatic pilot planned agenda purpose develop effective methodology certain kind first implemented http www ic org index html presents demonstrated human assessors generally appear
576	paper question evaluation methods metrics resources reusable arguing set iso standards developed software general applicable natural language processing main features proposals presented number applications applied mentioned discussed constructed type support major premise minor needs truth conclusion logically depend managed convince reader explicit argument direction simply setting key approach suffice try reinforce briefly reviewing followed encouraging results hope course encourage readers apply work recorded first record thanks nigel technical editor interesting discussion colleagues eagles isle projects especially finally thank
577	named entity recognition fundamental task biological relationship mining paper employs protein collocates extracted corpus enhance performance recognizers precision increased low expense recall rate incorporated integrate results proposed filter merged candidates suggested systems inconsistent overlap partial considered basis experiments based integration better introduction entities basic constituents document recognizing step understanding famous message competition muc extraction including organizations people locations time expressions monetary percentage evaluation tasks approaches capture types terms methods employed extract chinese personal names rule approach adopted large database available training contrast rules coverage exist past mainly focuses general domains scientific documents published particular biomedical attempts knowledge goals construct base automatically new information embedded similar works explored domain
578	automatic multi document summarization hard realize circumstances believe important observe humans doing task look different strategies prepared sets similar ones duc set people following data conducted survey free style sentence extraction type axis table summary particular lead new direction research introduction single newspaper articles don notably better algorithm simple based method faces challenges possible assume given documents talking topic asked summarize authors tried first marker mark phrases sentences connect cases figuring main common topics marked making list figure overview looked result stage noticed summaries conventional sense understand overall issues
579	paper describes effort rapidly develop language resources component technology support searching news stories using english queries results first hours exercise presented development interactive cross information retrieval systems adapted accommodate new languages focus extensive collaboration university maryland johns hopkins southern california capability rapid necessary essential process planning participate surprise dry run refine procedures sharing members tides community naturally chose clir driving application goal build allow searcher posing relevant articles period immediately following bombing introduction los times reported bomb airport city second largest philippines people dead injured president characterized blast terrorist act hour time difference washington dc later participants translingual detection extraction summarization program notified chosen practice planned independently begin notification observed spoken
580	memory based learning enjoyed considerable success corpus natural language processing tasks reliable method getting high level performance building nlp systems bottleneck mbl novel testing item compared training items base reason various forms editing selecting subset employed reduce number comparisons paper investigates modified self organising map select comparison involves reducing value proportional square root tested identification noun phrases wall street journal using sections section task classification problem performed matching input similar set choosing frequent closest similarity computed explicit metric performs bringing data bear cost worst case comparing match developing techniques perform phrase chunking
581	approximate arabic rich morphology model word consists sequence morphemes pattern prefix stem suffix method small manually segmented corpus bootstrap unsupervised algorithm build segmenter large unsegmented trigram language determine probable morpheme given input initially estimated words improve segmentation accuracy automatically acquiring new stems million estimate parameters expanded vocabulary training resulting achieves exact match test containing tokens believe state art performance highly inflected languages provided create introduction morphologically present significant challenges natural processing applications conveys complex meanings decomposable segmenting systems including machine translation information retrieval paper general handling inflectional capable using table prefixes suffixes address infix correspond root various variations treat common separate atomic units
582	introduction cfg generates possible syllable boundaries context free grammars generating transcriptions syllabi ed phoneme strings expressive writing grammar rules intuitive trained cfgs training corpus extracted large newspaper second resource consists algorithm procedure probabilistic obtained models evaluated test results experiments pcfgs predicting simple yield grapheme conversion cation er splits sequence phonemes syllables german lu method described paper based manually constructed returns given string analyses describes words composed branch onset nucleus coda parts written sequences natural phone classes stops vowels interpreted individual figure shows rst rule word syl liquid
583	present large scale meta evaluation measures single document multi summarizers end built corpus consisting million automatic summaries using baselines summary lengths english chinese manual abstracts extracts queries qualitative quantitative results showing strengths drawbacks methods rank different teufel cambridge cl cam ac uk john pennsylvania upenn edu liu cis sheffield dcs shef hong qi michigan johns hopkins cs jhu agree sentences expensive paper comparison including precision recall percent agreement kappa relative utility relevance correlation types content based tend orders offer significant advantages simplistic data annotation experimental design introduction summarization field seen increasing attention nlp community recent years incorporates important aspects natural language understanding generation effective useful variety areas unfortunately evaluating standard inexpensive way task traditional evaluations don chance account fact human judges performed experiments
584	introduction recent years granularity word senses computational lexicons discussed frequently lexical semantics issue emerged prominent problem previous studies exercises sense disambiguation reported ne grained wordnet entries similar indistinguishable human annotators causing disagreement correct tags addition wsd selection inventories fundamentally critical natural language processing tasks information extraction machine translation retrieval di erence assignments ects recall precision evaluation measures response approaches proposed group various ways derive coarse groups utilize abstraction hierarchy dictionary surface syntactic patterns functional structures words current version encodes groupings related relation called cousin approach grouping linguistic phenomenon systematic polysemy set sys predictable animal meat meanings chicken refers bird food meaning quantity process observed nouns increase supply based lexico semantically motivated expresses general knowledge relatedness advantages compared
585	continue appear dynamic lexical acquisition procedure certain words usages decay lexicon nlp exist updated automatically sentence domain inappropriate make analysis new permanent dictionary attributes proposed online according paper discusses alternative approach context instead editing static accepted rejected syntactic acquire information dynamically stored currently auxiliary implemented chinese conjunction existing illustrate process subsequent processing way section discuss able sentences incomplete discovered missing info filtered lexicalized need human future devoted lexicons corpus based specific evaluation dictionaries created combining proposing different major types shows mechanism significantly acquired current improves coverage parser grammatical parts speech introduction sub categorization frames quality systems depends assumes availability heavily completeness relatively mature
586	paper describes scalability portability belief network based mixed initiative dialog model application domains networks automatically govern transitions user order produce mixedinitiative interactions simpler domain foreign exchange complex air travel information service adapted processes include automatic selection specified concepts query purpose informational goal inference detection missing spurious backward using bn enhanced capability discourse context inheritance ease implies lack training data new developed set principles hand assigning probabilities degree relationships goals atis gave promising results introduction spoken systems demonstrate high usability restricted modeling plays important role assisting users achieve assumes complete control guiding interaction task completion attains rates bound constraints conversely offers maximum flexibility determining preferred course lower relative especially request falls competence level strike balance models allows influence
587	paper presents strategy design highly efficient semiautomatic method labelling semantic features common nouns using relationships words based information extracted electronic monolingual dictionary genus data specific synonymy obtains accuracy scope regard contained real corpus million manual introduction essential nlp applications case feature animate necessary disambiguate possible basque translations english preposition spanish referring location possession ambiguity appears translating complete prove extremely expensive study aims outline expanding improving idea outlined poor results obtained dismissed possibility initial approach aimed extracting corresponding automatically instead alternative proposed context manually labelled extract promising describes work carried aim
588	introduction paper propose novel language understanding approach cooperative model dialogue combines finite state statistical learning sentence interpretation implemented project goal provide immersive environment army experience sounds circumstances encounter real world scenarios procedure processing plays role support communication computers pipeline audio signals first transformed natural sentences speech recognition understand extract information case frame future management action planning adopt overall incorporates mainly approaches currently relatively work cooperation kinds models great advantages shortcomings separate implement parsing algorithm exact expected result tedious design network hand robust failure matching produces results deal unexpected cases designing training giving set candidate confidence scores kind rules select needed applying completely satisfactory performance rest organized follows section describes
589	paper describes log linear parsing models combinatory categorial grammar easily encode range dependencies inherent coordination extraction phenomena ccg designed handle previously applied statistical assumption possible parses sentence enumerated enumerating infeasible large grammars dynamic programming packed chart efficiently estimate model parameters implementation runs cluster allows complete wsj penn treebank estimation described abney attribute value hockenmaier steedman include clark inconsistent following propose loglinear framework incorporates features loss consistency typically approaches finding probable parse extracted approach problem sample space osborne technique similar proposed johnson tsujii estimates method algorithm estimating pcfg apply automatically tree adjoining using improved iterative scaling significant memory requirements limits sentences training data version
590	chinese ne recognition problem uncertainty word segmentation flexibility language structure paper proposes rationality model multi agent framework tackle employ greedy strategy evaluate detect possible nes text treat process selecting best negotiation resulting robust able handle different types effectively test met corpus indicates achieve high values introduction named entity fundamental step processing tasks basic task message understanding conference studied intensively day reported person location organization names sub compared entities defined muc focuses loc org recent research focused machine learning approach transformation based hidden markov decision tree collocation statistics maximum entropy em bootstrapping english works examined extraction information spanish japanese approaches handcrafted rules supplemented character frequency methods require resources chen billion dictionary employed mainly internal generalization yu common context residing performed rule
591	software performing conceptual analysis text data largely language independent manner modelled content provides unsupervised supervised using concept classifiers ontology discovery key component user requirements chosen automatically ranking algorithm finding seed words reflect themes present process looks centre local maxima lexical occurrence network filling thesaurus machine learning relevant iterative derived word disambiguation technique finds nearest maximum cooccurrence early results reduced scale free small world classification tagged multiple concepts sentence resolution mapping relative frequencies form semantic scaled asymmetric scaling lattice centrality interface browser exploring depth enables characterisation indirect association segment browsing provided method strategy involves abstracting families classify sentences resulting tags indexed provide document exploration environment smaller number simple index complex relationships recording occurrences systems approaches
592	paper proposes new method automatic acquisition chinese bracketing knowledge english bilingual corpora sentence pairs first aligned syntactic structure combining parse trees statistical language model extracted automatically preliminary experiments learned manually annotated brackets proposed particularly useful acquire studied lacks tools resources second discusses applicable introduction past years seen great success monolingual parsing grammars availability large tagged syntactically bracketed penn tree bank makes possible extract grammar rules substantial improvements western powerful models limited progress achieved bottleneck real methods learn corpus depended wu called inversion transduction simultaneously brief description details refer context free generates matched output languages differs standard itg allows right hand production directions straight inverted following productions
593	propose method constructing based machine translation exploits content aligned bilingual corpus first sentences phrases languages pairs high confidence selected stored memory given input searches fitting monolingual similarity pair obtained results combined generate experiments selection showed accuracy demonstrating basic feasibility approach figure introduction idea ebmt similar sentence retrieved produce order make practical mt large number structural correspondences required naturally presupposes parsers corpora decade improved significantly availability increased despite expectations reality share newspapers broadcast news steadily type observations started research project covered aspects systems starting using finally
594	previous work argued memory based learning better abstraction set language tasks paper first attempt generalize results new area spoken dialog systems different learner examine utility various measures predicting generalization obvious characterize performance learners introduction follow study daelemans authors keeping exceptional training instances useful increasing accuracy natural involved experiments grapheme phoneme conversion speech tagging prepositional phrase attachment base noun chunking provides empirical evidence editing leads decrease compared decision tree favor provide linked property holding general properties continue track investigating hold smaller datasets features observe measure range indicate additional goal
595	paper presents set algorithms distinguishing personal names multiple real referents text based supervision approach utilizes unsupervised clustering technique rich feature space biographic facts automatically extracted language independent bootstrapping process induced named entities partitioned linked data performance evaluated test multi referent generated jim clark car driver scotland colorado film editor netscape disaster salesman kansas instructor canada science student hong kong professor gun introduction problem natural ambiguity resolution task proper noun disambiguation word senses translation ambiguities typically alternative meanings resolved context potentially refer hundreds thousands distinct individuals different contextual characteristics help distinguish resolve trace surface appear online documents search google shows web pages mentioning first unique recognized popular press reuters observed major stumbling block searches present method
596	current sentence alignment approaches adopt length cognate features trained tested documents style distribution type frequency vary significantly texts different styles based fail achieve similar performance corpora experiments measure drop approach technical manual general magazine large percentage content words source text translated corresponding translation preserve meaning target transfer lexicons regarded reliable cues aligning sentences task performed human enhance robustness robust statistical model lengths proposed paper integrating error reduction observed number gale church claimed better achieved characters adopted instead cognates language pairs derived family attacked problem considering additionally reported work indo european testing non languages wu tried hong kong hansard corpus rate indirectly complicated word models brown vogel och ney
597	paper proposes learning extracting method word sequence correspondences non aligned parallel corpora support vector machines high ability generalization cause fit training samples learn dependencies features using kernel function translation model dictionary number words speech constituent neighbor experiment results japanese english archived precision rate recall extracted demonstrates reduce cost making dictionaries addition functions linear separating boundary svms natural language processing text categorization chunk identification dependency structure analysis proposed require exist present limiting applicable domains binary classifiers linearly separate dimension vectors classes represents sample distinguished given belongs equation sign introduction multilingual machine manually great deal labor required work description consistent researches pairs automatically active
598	text representation central task approach automatic learning texts requires format allows share content words deal similar topics furthermore measuring similarities raises question organize resulting clusters paper presents cohesion trees data structure perspective hierarchical organization corpora cts operate alternative models lexical quantitative characteristics account shown realize linkages lexically homogeneous produced minimal spanning introduction approaches classification categorization require semantically relate thematic categories majority vector space bag model research formats hyperonym based effects small seriously argues ignores morphological syntactical information essential solving tasks semantic spaces proposed representing relations proximity relying sparse knowledge resources prove efficient cognitive science computational linguistics retrieval leave unanswered explore visualize signs mapped case represented points refers exploration implicit methods
599	paper presents novel language independent question answering based natural processing techniques shallow query understanding dynamic sliding window statistical proximity distribution matching performance proposed using latest text retrieval conference data comparable results reported trec documents extracted user queries users required read selected answers responsibility translation module preprocessing stemming pos tagging concept identification computation windows segments keywords weighted phrases distributions final selection frame answer introduction past decade community invested efforts advanced technologies automatic information systems decided divide traditional task called tracks cross track filtering interactive spoken document web decision mainly mature field desire expand additional areas goal development generate concise similar nature relevant work funded darpa air force contract opinions interpretations conclusions recommendations authors
600	paper improved word alignment based bilingual bracketing described explored approaches include using model conditional probability boosting strategy lexicon probabilities importance sampling applying parts speech discriminate english words incorporating information base noun phrase results shared task french chinese alignments presented discussed introduction parsing promising goal extract structure parallel sentences improve constraint transfer approach generalized automatic acquisition translation translations esp languages resources relatively scarce compared building statistical machine systems unrestricted text fails robustness respect inherent noise data important wu shallow studied probabilistic context free grammar generative analyze weak order constraints provides framework incorporate knowledge pos potentially detailed simplified brown applied training detection performance extracted post processing settings different lexicons
601	ni red ball push figure distance self correction japanese introduction constituents share semantic role regard verb refer object information utterance speaker corrects capture df detection corrections cause ill formedness restore wellformedness utterances purpose past work proposed deletion detected method works cases removes core schubert pointed problem provided procedure solve resolve merge rp constituent paper propose handle incremental dependency parser extend model problems mentioned evaluate using quasi dialog corpus discuss limitations future section describes based analysis shows deal discusses evaluation conclude look research direction makes depend postpositions omitted spoken processing requisite current speech systems
602	purpose research test efficacy applying automated evaluation techniques originally devised human language learners output machine translation systems believe provide information learning process development first experiment series experiments looks intelligibility mt showed assessors differentiate native non essays words factors decisions tested similar criteria elicited using subjects given set extracts translated newswire text expert translations outputs minutes extract determine believed sample additionally asked mark word decision results preliminary analysis involved making presented feature based informative metrics diagnostic designers users recent lines jones present reasonable idea measuring trying score english wide variety essence looking degree comparing goal scoring function quality
603	annotation discourse phenomena notoriously task carried help tools paper present perspicuous links annotator tool successfully projects briefly types annotations applied using requirements recent years need produce reusable corpora led increasing xml encoding result simple text editors addition complicated requiring specialised section important characteristics needs minimum time required learn works hide unnecessary details annotators linguists experience computers schemes designed humans provide information friendly way ensure introduced process desirable new changed build languages consistency different desired language independent presented meets appropriate introduction
604	complex nps disagreement discourse deictic expressions include demonstratives refer chunks previous greek identical form strong pronominals dropped subjects cases excluded computational linguistics volume number antecedent possessor final data set dataset included instances main sequences subordinate broken follows clauses ranking antecedents coding based earlier work entities competing ranked according following rule empathy subject indirect object direct indefinite quantified classified dative verbs easily identified normally exhaustive list enumerated language encountered verb category introduced associated clause using lower evoked cf clear multiple extra specification crucial current study constructed nouns marked genitive
605	text words frequency appearance considered keywords strong relationship subjects texts frequencies change time series variation given period traditional dealing methods search techniques importance correctly determine index word popularity paper new method proposed estimate automatically stability classes indicate based past data first learning produced defining attributes measure quantitatively extracted electronic according comparison evaluation decision tree results manually measures increasing relatively constant decreasing respectively effectiveness achieved connected changes attract attention users particular directly main subject express important characteristics especially searching similar presents estimating
606	propose question answering korean predictive answer indexer first extracts candidates document indexing time gives scores adjacent content words closely related candidate stores weighted database using technique complementary analysis questions proposed qa save response necessary extract retrieval combined traditional information improve precision closed class minimum loss documents include terms user query carefully look text order phrase precisely answers area ir attracting attention shown proceedings trec searches large collection texts filters inadequate phrases sentences approach troublesome tasks current systems problems follows correctly respond users included pre defined categories person requires searching needs deep linguistic knowledge syntactic semantic roles introduction applied successfully scale search
607	paper describes techniques unsupervised word sense disambiguation english german medical documents using umls present monolingual rely structure bilingual availability parallel corpora best results obtained relations terms given method achieves precision coverage evaluation corpus success technique shows lexical resource giving concepts index document collection high quality language paul dfki saarbr cken germany rendered referring substance kind governments law ability disambiguate essential task machine translation translating spanish need make distinctions mentioned similar ones wsd crucial applications cross lingual information retrieval search entered querying appropriately established subfield natural processing standards senseval competitions methods effectively divided require manually annotated training data gene supervised scalable costly unrealistic produce available
608	algorithm recovering non local dependencies syntactic dependency structures patternmatching approach proposed johnson similar task phrase structure trees extended machine learning techniques essentially classifier predicts nonlocal given connected fragment set structural features evaluating penn treebank shows improvement precision recall compared results presented annotated nodes first extracts fragments connect antecedents licensing corresponding extracted tree patterns match previously unseen pattern matched introduces inserting node suitable antecedent author notes biggest weakness fails robustly distinguish indexed free lexicalization needed solve problem suggests suffer using abstract skeletal helpful avoid attempt overcome problems developed extends bare matching different definition allows significantly reduce number corpus obtain general cases directly correspond specific linguistic phenomena helps understand information important recovery
609	paper explore adapt general hidden markov model based named entity recognizer effectively biomedical domain integrate various features including simple deterministic morphological pos semantic trigger capture evidences especially evaluate contributions present algorithm solve abbreviation problem rule method deal cascaded phenomena experiments genia achieve measure respectively outperform previous best published results using training testing data introduction research grown rapidly recent years huge nature language resources developed rich knowledge base technique recognition strongly demanded applied work ner systems successfully newswire explorations port existing compared high performance probably following factors ne modifiers basic nes activated cell lines regulatory element binding factor kind highlights difficulty identifying boundary share head noun conjunction disjunction construction proteins hard identify spelling forms capitalization casual
610	corpus based diachronic analysis patent documents mainly morphologically productive certain terms help tracking evolution key developments rapidly specialist field texts trade marks office line service extracted automatically chosen fast switching devices systems method presented draws ature metrics info rmation extraction linguistics aspects english morphology interdisciplinary shows word formation closely technology introduction document written pe legal authority allowed sell deal article exclusion persons ically invention claim term important refers object ideas essentially ca advances importantly language supports change requires follow template divided broadly parts first te right intellectual property overlap se forms claims crucial rights abuse pa monitoring effectiveness component ups effect author
611	hitiqa interactive question answering technology designed allow intelligence analysts users information systems pose questions natural language obtain relevant answers assistance require order perform tasks objective user submit exploratory analytical non factual russia reaction bombing distinguishing property generally anticipate constitute answer certain types expected heavily conditioned fact available topic practical viewpoint underspecified casting broad net space possible clarification dialogue needed negotiate exact scope intent introduction project arda aquaint program aims make significant advances state art automated paper focus aspects work semantics understands requests human understanding discuss preliminary evaluation results series pilot tests conducted remote internet link vs differences finding seeks pieces corresponding statement states
612	support context based multimodal interpretation conversational systems developed semantics representation capture salient information user inputs overall conversation particular present unique characteristics finegrained semantic models flexible composition feature structures consistent multiple levels allows rich contexts resolve ambiguities infer unspecified improve alignment result able enhance understanding including abbreviated imprecise complex ones discuss finally demonstrate mind process variety ambiguous interpret major processes figure unimodal discourse applies modality specific recognition components identify meanings input captures called unit combines form captured furthermore identifies relates segment group contribute goal sub evolving history reflects progress shows fragment first deictic introduction inspired
613	development spoken dialogue systems limited performance speech recognition component impact errors studied global level task completion paper carry empirical study consequences fully implemented prototype based acts formalisms report act identification discuss standard control mechanisms participate robustness assisting user repairing introduction faced limitations technologies make recurring problem studies shown correlation scores satisfaction ability complete tasks underlying suggesting certain prevent successful concentrated parsing incomplete utterances allen investigate interface electronic programme guide main advantage human breaks information exchange elementary units correspond actual criteria basis tv selected individual features cast movie genre rating assists progressively refining description requiring explicit knowledge editorial categories
614	captures semantics multimodal presentation semantic template authored application needs specify selected content intended style constraints output generated best suit given want compare diagrams items related large display devices displayed smaller pdas possible better item time switch compared figure integrated player authoring tool addition pre defined set developers write templates new written scratch built existing ones facilitate task providing graphical development environment provides support testing managing interface reduces needed syntax direct manipulation visualization allows developer test newly constructed easily immediately verified helps prevent errors constraining way modified values slots constrained context sensitive pop menu choices tions text realization using attribute grammar proceedings first international natural language generation conference pages israel susan based dialog journal uncertainty knowledge systems
615	paper explores problem finding non local dependencies first isolate set features useful task second develop step approach combines trace tagger state art lexicalized parser finds nonlocal parsing outperforms makes better detecting pre processing reported performance using unlexicalized parsers tested models main claim coupled postprocessing model collins generalized handle types distance architecture general contribution gives important insights nature recovering semantic relations regarded successes simple outlined help determine incorporated order improve recovery overall organization follows section sketches material experiments discuss finite detects extraction sites knowledge phrasestructure cues recover antecedents finally investigate detection antecedent integrated stochastic introduction broad coverage statistical able
616	developing techniques extracting general world knowledge miscellaneous texts process approximate interpretation abstraction focusing initially brown corpus apply interpretive rules clausal patterns modification concurrently abstract propositions resulting formulas person believe proposition children live relatives methods currently yield report efforts evaluate results judging scheme aimed determining pass reasonable claims opinion human judges nearly extracted favorably judged according given judge percentage multiple lower sufficiently high suggest tackling standing acquisition bottleneck ai following entered room bringing washed clothes clauses sentence individual enter female sleep fact treebank bracketing programs produce output shown named entity english glosses generated automatically work focused data
617	investigate problem summarizing text documents contain errors result optical character recognition stage process tested error effects analyzed possible solutions suggested experimental results current approaches developed deal clean suffer significant degradation slight increases noise level document conclude proposing ways improving performance noisy summarization based analysis suggest automatic systems hope learned initial investigation shed light future directions ascertain studying useful number applications constitute percentage encounter everyday life output ocr speech typically various degrees purely electronic media email free summarize need develop techniques addition working core algorithms successfully handle greatly influence final quality summaries researchers studied problems relating information extraction sources work focused arise somewhat different propose finite state modeling approach extract sentence boundary audio using gram pause duration precision recall achieved combining kinds features palmer
618	interpreting multilingual queries databases domain information described particular language address problem word sense disambiguation fledged semantic classification construct automatically manually purpose propose disambiguate senses source lexical items augmenting simple translation dictionary database terminologies implemented query interpretation combinatory categorial grammar framework ip ta person mary john body oy foot sin object ca tong cha ko yang color status sa table sample introduction objects names attribute wish interpret english korean disambiguated matching similar selection machine palmer target different formal natural difference prompts make instead general classifications disambiguating shown buy brown old car
619	present improvements greedy decoding algorithm statistical machine translation reduce time complexity cubic linear sacrificing quality achieve integrating hypothesis evaluation creation tiling end search iteration imposing restrictions word reordering introduction current work builds replacement models developed ibm early based conventions established brown commonly referred challenges building actual mt systems framework finding candidate maximizes probability given input knight shown problem np complete task practical employ optimal decoders rely algorithms instead empirical evidence suggests perform berger attribute errors candide technically quadratic component small coefficient effect speed reasonable inputs restricted stack using metric wang waibel report error rates respectively och implemented benchmarked version
620	paper investigate multivariate poisson model feature weighting learn naive bayes text classifier new classification assumes document generated previous works consider vector binary term features based presence absence explore selection costly process small number training documents continuously provided experimental results test collections indicate proposed parameter estimation technique leads substantial improvements compared unigram language classifiers known outperform original pure similarly attractive approach task simple practically implemented great simplicity enables integrate filtering modules existing information retrieval systems easily frequency related stored general required learning complex generalization processes unlike machine methods svm boosting incremental adaptation using performed adding updating frequencies earlier extensively studied considered utilize resulting poor performances reason
621	discriminative models nlp community recent years previous research shown advantageous generative paper investigate different objective functions optimization methods affect performance classifiers learning framework focus sequence labelling problem particularly pos tagging ner tasks experiments changing function effective features included model introduction common approach growing successful theoretical advantages discuss section empirically favorable fixed variety label ofspeech named entity recognition studied applications chunking pitch accent prediction speech edit detection differ aspects nature sequences difficulty evaluation given think worthwhile optimizing affects varied scale manner using combinations designed optimized despite intuitions vary
622	paper compares number generative probability models widecoverage combinatory categorial grammar parser trained tested corpus obtained translating penn treebank trees ccg normal form derivations according evaluation unlabeled word dependencies best model achieves performance comparable figures given collins linguistically expressive contrast gildea significant improvement modeling translation grammars characterized larger category sets standard distinguishing classes verbs different subcategorization frames result lexicon extracted purpose training categories compared pos tags hand rules limited small simple unary binary schemata function application composition results smaller pcfgs introduction currently single statistical parseval scores underlying permissive measures certain semantically decisions predicting null elements arising deletion movement potential benefit wide coverage parsing lies constrained transparent capture extraction coordination present syntactic clark conference estimated evaluating
623	paper addresses recent results mandarin spoken dialogues introduces collection large conversational dialogue corpus context data processing principles transcription proposed accordingly tool specifically developed conversations introduction speech corpora indispensable current linguistic research information science applications dealing concretely provide real phonetic empirical driven knowledge features language presented composed contain considerable variety phenomena acoustic variations furthermore wide range issues acts turn lexical prosodic conversation diachronic point view archives contemporary daily given general speakers subjects words times occurrences core make overall tokens interestingly expected distribution token frequency highly symmetric instance verbs located say want frequently pronouns negation don high word right grammatical particles discourse markers known differentiates written texts spontaneous literature consistent definition
624	successful application multi view cotraining algorithms relies ability factor available features views compatible uncorrelated potentially preclude problems coreference resolution lack obvious feature split bootstrap classifiers propose evaluate single weakly supervised algorithm different learning lieu required training addition investigate method ranking unlabeled instances fed bootstrapping loop labeled data aiming alleviate problem performance deterioration commonly observed course introduction paradigm learns task small set large pool using separate redundant ensure guarantees assumes input satisfies fairly strict conditions first sufficient target concept second conditionally independent given class empirical results artificial sets confirm sensitive assumptions applied successfully natural language processing tasks factorization named entity classification success number reported applying nlp result researchers begun procedures require explicit zhou steedman multiple
625	grammar association technique machine translation language understanding introduced levin statistical structural models involved process automatically built bilingual optimal new sentences efficiently dynamic programming algorithms paper presents discusses state art including model introduction promising facing tasks first proposed combines set sentence pairs input basically consists modelling task output describing certain elements view particular case aimed representing meaning related corresponding using performs follows parsed giving rise derivation given assigns weight rule search carried associated interested designing systems based principles
626	paper presents unicode based chinese word segmentor handle text simplified traditional mixed mode strategy divide conquer recognition personal names numbers time numerical values preprocessing stage tagging information work disambiguation adopting modular design approach different functional parts separately implemented using modules module tackles problem providing flexibility extensibility results added pre processing accuracy increased easily adaptive applications objectives components introduction segmentation overlapping ambiguities foreign organizations unique systems achieve high heavily rely manual getting trained certain language environment need look cost competitive quickly new requirements limited resources available report internally dictionary wide operating window xp data written form exist likely reality first objective ability
627	chat gained popularity tool real time conversation standard systems problems lack timing information tackle problem built following functions function making typing state visible floor holding start evaluation results sys tem new significantly increases number turns indicates effectiveness smooth communication survey showed different concerning adjusting utterances conversations using introduction previous work tools indispensable everyday life proliferation network include mail bbs users increasing dramatically nature despite allow message appears screen mean reading waiting leaving user sends pressing return key means know complete face participants signal difficulty inserting fillers pauses send kind
628	document current summarization systems produce uniform version summary users personalized summarizations necessary order represent preferences interests annotation getting important sharing collaborative filtering fact record dynamic behaviors compared traditional steady profiles paper introduce new based annotations contexts extracted features sentences given different weights representation produces versions summaries generic considering kind personal data tailored user extent experiments help improving performance consideration time make extensive study annotating distribution propose variety techniques evaluate relationships number affects summarizing similar work first author visited microsoft research asia introduction information internet hard read published materials potentially interesting great present condensed way using extracts abstracts generalize content article text process distilling source abridged particular task quickly general idea decide deserves
629	isle project continuation standing eagles initiative carried human language technology programme collaboration american european groups framework eu international research operation supported nsf ec concentrate paper current position computational lexicon working group provide description simple lexicons built basis previous recommendations point basic methodological principles applied phases followed definition multilingual lexical entry introduction number subsequent projects funded commission stands expert advisory engineering standards launched general linguistic continued joint preparatory work years setting oriented hlt objective support national industry developing promoting widely agreed demanded guidelines resources tools exploit le products aim accelerate provision common
630	natural language processing critical improvement healthcare process potential encode vast clinical data textual patient reports applications require coded function appropriately decision support quality assurance order applicable domain performance nlp systems adequate valuable application detection infectious diseases surveillance associated produces significant rates manual patients challenge studies demonstrated automated using tools useful adjunct management effective tool control practitioners paper presents study aimed evaluating feasibility based electronic monitoring identify estimated sensitivity specificity positive predictive value comparing clinicians judgments results method feasible introduction technology variety techniques analyze structure narrative provide encoding outcomes analysis research additionally mining knowledge discovery automate development rules detect conditions interpreting generated output potentially invaluable enables access rich varied source
631	paper presents domain textual question answering feedback loops enhance performance combine new way statistical results syntactic semantic pragmatic information derived texts lexical databases contribution loop overall human assessed precise answers introduction defined trec competitions task identifying large collections documents text snippet answer natural language lies constrained span frequently keywords extracted immediate forming paragraph paragraphs identified automatic autonomous systems incorporate index collection retrieval mechanism recent evaluations series workshops organized national institute standards technology designed advance state ofthe art techniques sufficient finding high precision fact adopt architectures semantics questions captured prior later extracting processing goals achieved first need know expected type words looking second look identify
632	recent text speech processing applications mining raise new general problems related construction language models present efficient algorithms address report experimental results demonstrating usefulness algorithm computing efficiently expected counts sequence word lattice output recognizer arbitrary weighted automaton technique creating exact representations gram automata size practical offline vocabulary words order simple constructing class based allows represent implementation techniques incorporated software library modeling includes grammar functionalities statistical crucial components modern natural systems recognition information extraction machine translation document classification cases model combination sources rank alternative hypotheses assigning probabilities classical various smoothing references survey comparison arise counting constructed deriving statistics large input texts adaptation purposes
633	paper standard outputs information extraction systems named entity annotations scenario templates enhance access text collections browser prototype designed support workers pharmaceutical news archive industry watch function report results preliminary qualitative user evaluation broadly positive indicates work needs interface make users aware increased potential enhanced browsers applications error readily end complexity integration produce incorporated larger sophisticated application gain benefit present approach project addresses second third problems testing goal develop advanced facility large corporation specifically aims provide largest newsletter order increase effectiveness employees involves broad current awareness tracking people companies products particularly progress new drugs clinical trial regulatory approval process introduction technology promoted defined darpa message understanding conferences ace component tides resulted impressive abilities extract structured texts
634	paper presents chinese word segmentation improved models sentence generation words defined following types lexicon morphologically derived factoids named entities provides unified approach fundamental features level language processing morphological analysis factoid detection entity recognition performance evaluated manually annotated test set compared state ofthe art systems account fact definition varies introduction initial step tasks attracted attention research community challenging problem standard define entries present solution problems boundaries written text unlike english desirable separate solutions previous work methods proposed reviews include roughly classified dictionary based statistical hybrid approaches given input character string stored identified depends
635	decoding algorithm critical success statistical machine translation decoder job likely according set previously learned parameters space possible translations extremely large typical algorithms able examine portion solutions paper compare speed output quality traditional stack based new decoders fast greedy slow optimal treats integer programming optimization problem introduction mt translates french sentences english divided parts language model assigns probability string pair strings unseen sentence tries maximizes equivalently brown introduced series tms word substitution reordering include source target languages constrained order linear viterbi applied ordering limited nodes binary tree carried high polynomial arbitrary np complete sensible strategy subset choose course way returns exists called search error wang waibel
636	title document roles compact summary lead reader read conventional generation focuses finding key expressions author wording pays attention make play second role properly indispensable clarify content titles effective attract target article first identify typical aimed general readers comparative study technical papers headlines rewritten newspapers results questionnaire survey effects knowledgeable shows common different tendencies importance word approach similar text summarization techniques selected keywords strongly reflect words centered cases generated poorly fail sufficient look important pay necessary features relationship based knowledge possible extract information attractive include
637	profile occurrence clausal extraposition corpora different domains demonstrate pervasive phenomenon german addressed sentence realization present approaches modeling based machine learned decision tree classifiers differ view movement operation approach models multi step intermediate nodes ultimate target node compare resulting trained data discuss differences types results obtained introduction stage natural language generation derives surface string abstract representation numerous complex operations necessary produce fluent output including syntactic aggregation constituent ordering word inflection argue needs included accomplish task applying learning techniques comparison english illustrates possible languages material right periphery clause following relative man left ask question der mann ist war um eine zu infinitival leave country das land complement ill ein ger er unlike obligatory phenomena wh subject pragmatic variability widely cited factor influencing
638	paper presents maximum entropy chinese character based parser trained treebank word parse trees ctb first converted level ofspeech tags constituent labels derived pos corpus segmentation parsing unified framework average label measure achieved results improve significantly higher syntactic dictionary helps accuracy introduction characters linguistic data consortium released developed upenn various statistical parsers built techniques english shown working fairly applied text boundary written manually segmented words labeled described operate assumption input sentences pre studies problem unsegmented motivation directly natural language applications requires separate segmenter second important reason availability large high quality annotations provides opportunity create highly accurate widely known hard multiple showing agreement native speakers upper lower human subjects
639	increasing shift evaluating natural language generation systems nlg specific issues hinder effective comparative quantitative evaluation field paper starts describing task based black box hypertext examine problem glass module focus machine learning methods text planning introduction discussed differences understanding nlu techniques applied main problems lack defined input output different assume kinds depending domains tasks target media makes particularly comprehensive review hard obtain objective measure quality texts especially genres normally evaluated respect usefulness particular established measuring user performance extrinsic referred evaluates presents experiment issue reusing resources questionnaires designs examines brief
640	novel method detecting errors task based human dialogues automatically deriving semantic tags examined hc darpa communicator air travel domain comparing user inputs responses look slot value discrepancies manually automatic labeled corresponding slots filled frames course applied algorithm detect tagged label directly analysis results tagging methods indicates possible way needs work reduce number detected finally present discussion differing utterances view state annotate accumulation revision information paired hypothesized representation straightforward views dialogue differ difference originated beneficial annotation independent reasons measurements concepts turn bit rate currently active given hypothesis correct viewing filling additional different systems participated data collection conducted program summer
641	paper proposes machine learning based question classification method using kernel function hierarchical directed acyclic graph directly accepts structured natural language data levels chunks relations computes value practical cost time reflecting structures examine proposed experiment japanese questions labeled types results demonstrate improves performance conventional methods bag words combinations bytes large set news odqa task considered extracting exact answers instance qa given born answer typically systems following components achieving analysis analyzes determines type keywords text retrieval finds paragraphs documents match result component candidate extraction extracts candidates retrieved selection selects plausible extracted important processes listed identifying target intention determine sought process determining called
642	ken department computing science university purpose study propose new method machine translation projects report generation weather forecast economic produced languages english japanese french german input data stored xml db applied stage pipelined architecture implemented transformation processes regard language neutral intermediate form employ called sublanguage approach process kind interlingua instead conventional structure transfer variety users accessing common resources world wide web importance multimedia multilingual information presentation technology increased essential presentations researchers pursue independent structures semantic frame feature developed attributes embedded hand store databases relational style numerical format necessarily features gap technologies support structured function structuring techniques useful represent linguistic based figure document planning microplanning surface realization produces
643	references included multi document summaries problematic paper present corpus study performed derive statistical model syntactic realization referential expressions interpretation probabilistic data helps gain insight extractive rewritten efficient manner produce fluent read text news stories containing words drawn different newswire agencies order form noun phrases people realized interested occurrence features type number premodifiers presence reference constructed large automatically annotated merging output charniak parser ibm named entity recognition nominator contains section given focus mentions distinct types titles external modifiers capitalized conventionally recognized president george bush constitute irish james major categories distinguish prepositional phrase modification relative clause remarks verb initial modifications category names corresponding general european american structure include sum target np examined
644	concrete make world sources ontological categories observation reasoning choice first step designing database knowledge base object oriented logic introduces topic ontology historical including aristotle kant goes develop illustrated trees multidimensional matrices lattices representation formalisms occasional conceptual graph algebra set theory predicate extensive discussion distinctions contained extremely worthwhile includes discussions roles adjectives vs related different terms collection type category space time granularity philosophers terminology cited texts annoying depending reader attitude chapter summarized appendix sample diagrams english explanations sentences representations style especially list nineteen thematic mentioned book discussed begins section engineering application task building computable models domain purpose basically introduction organized principles davis
645	limited coverage available translation lexicons pose challenge cross language information retrieval applications present techniques combining evidence dictionary based corpus backoff outperforms technique merging introduction effectiveness broad class term depends accuracy lexicon types commonly knowledge extracted bilingual dictionaries corpora provide reliable lack preference contrast better source translations newly coined terms statistical analysis produces erroneous results paper explore question best combine sources format appear particular order ranked target unigram statistics calculated large comparable english portion forum collection smoothed brown balanced covering genres single word ordered decreasing frequency followed multi finally entries ordering effect minimizing infrequent words non standard usages misspellings lists strand requires associated set en
646	paper degree countability english nouns predictable semantics predicted using ontology nodes predictability aid non native speakers determine building bilingual machine translation lexicon introduction heading noun phrases typically countable uncountable modified numbers morphologically marked plural form dog dogs quantifiers number distinction equipment knowledge important translating source language obligatory distinctions target make japanese german chinese generating know head determines range possible determiners particularly closest research second author visiting ntt communication science laboratories equivalent different languages mark means choice largely responsibility generation component measure semantic classes predict obviously answer depends sense word belongs
647	coding scheme machine translation spoken taskoriented dialogue covers levels speaker intention domain independent speech acts dependent actions database contains tagged sentences english italian german argue relevant discourse unit improving quality specific approach scales large domains explosion coded high inter coder reliability research sites furthermore number order times sparseness problem training classifiers identifying action work developing accuracy act core source language analysis module nespole information party traveling children ages request existence facility available ice view bus icon figure constructed compositionally inventory concepts allowable combinations formalized human readable specification document supported community recognized potential nlp systems hypothesized predicting utterance improve recognition reduce ambiguity
648	paper presents results using belief functions rank list candidate information provided noisy dialogue input consideration intended task performed completion access multi domain currently contains knowledge different domains callers calling ended help prompt receiving reply caller extract word evidences recognized utterances model turn determine intends perform built require speech recognizer trained specific set key words grammars understand spoken inputs guided series prompts supposed speak choices way systems new know say early encoded grammar motivated work problem accessing naturally allow natural ultimate aim provide exact piece looking interaction reported first attempt want useful
649	paper describes allows users browse search voicemail messages content gui based navigation realized automatic speech recognition information retrieval extraction human interaction technology addition browsing querying functionalities acoustics caller id proposes names existing acoustic models trained user feedback browser provides note capability comparing regular interface study performed better terms objective subjective objectives steve julia aer research att com vt edu jones description first retrieved server processed asr transcription message audio passed ir email servers language model recognizer hours hour corpus transcribed hand labeled telephone numbers times dates greetings includes approximately speakers recorded rest cellular speaker phones gender balanced non native mean duration seconds median introduction baseline decision tree state clustered triphone tied states emission probabilities modeled component gaussian mixture distributions vocabulary automatically generated labs text
650	examine purpose dialog metric serves propose empirical methods evaluating systems meet include protocol conducting oz experiment basic set descriptive statistics performance claims using data collected ideal benchmark gold standard making comparative judgments provide practical means optimizing component analysis cost valuation maintain designers need make better ones exist end first wizard introduction face number complicated issues hand ultimately created user usability factors satisfaction likelihood future final criteria subjective highly dependent features interface turned objective metrics success rate completion time unfortunately interactive nature correspond effective experience furthermore different contradict leaving tricky task interactions correlations instead
651	unsupervised grammar induction systems commonly judge potential constituents basis effects likelihood data linguistic justifications constituency hand rely notions substitutability varying external contexts distributional operate principles using speech tags contextual features advantages disadvantages examined including precision recall trade offs error analysis extensibility overview early work showed small artificial context free grammars induced em algorithm chunk merge studies large natural language shown methods completely acquisition generally ineffective instance charniak describes experiments running random starting points produced widely extremely poor quality kinds results vast majority statistical parsing focused supervised learning problem remains entirely method produce linguistically sensible accurately parse text compelling motivations building training requires considerable resources time expertise furthermore investigating shed light phenomena implicitly captured parser information explicitly modeled difficulty correctly attaching subjects verbs objects cfg ordering implicit given structure vp likely learn attachment order reliably model goal highquality accuracy
652	central problem word sense disambiguation lack manually tagged data required supervised learning paper evaluate approach automatically acquire sensetagged training english chinese parallel corpora disambiguating nouns senseval lexical sample task investigation reveals method acquiring promising subset accuracy difference approaches narrow disregard advantage coverage analysis highlights importance issue domain dependence evaluating wsd programs introduction determine correct meaning context fundamental natural language processing ability disambiguate accurately important applications machine translation information retrieval wordnet id translations descriptions path electrical signals pass passage water relatively body means communication access tube television station table actual senses noun channel implemented hong kong news laws hansards treebank xinhua total size texts million characters
653	paper presents dependency language model captures linguistic constraints structure set probabilistic dependencies express relations headwords phrase sentence acyclic undirected graph contributions fold first incorporate gram capture distance word second present unsupervised learning method discovers using bootstrapping procedure finally evaluate proposed models realistic application experiments best achieves error rate reduction trigram introduction deal obstacle mentioned approximate similar skipping bigram prediction conditioned exactly linguistically related lies arbitrarily past interpolated headword keeping number parameters combined manageable overcome given expectation maximization manual syntactic annotation required opening possibility building performs wide variety data languages evaluated japanese kana kanji conversion achieving significant recent years efforts utilize modeling practical reasons dominated based
654	extracting sentences contain important information document form text summarization technique key automatic generation summaries similar written humans achieve extraction able integrate heterogeneous pieces approach parameter tuning machine learning attracting attention paper proposes method sentence based support vector machines confirm performance conduct experiments compare existing methods results challenge corpus offers highest accuracy clarify different features effective genres large quantity training data available effectively realized recent years attracted field aone kupiec employed bayesian classifiers mani nomoto lin decision tree overfit given need select carefully robust number svms shown categorization chunking dependency structure analysis present verified introduction means lost result lack coherence basic technologies generating useful
655	paper issue document structuring addressed achieve task advocate segmented discourse representation theory expressive framework sketch planning mechanism aims producing paraphrastic structures possible set factual data encoded logical form campus bp france fr lattice paris case pl linguist includes conceptual relation cause events plan sdrs goal produce wide range paraphrases want texts different communicative correspond goals issues fred left mary burst fit tears leaving brought start plans underlying result expresses predicate similar explanation instead commentary defined ensure cohesion add following constraint definition requires element coreferent
656	introduce factored language models generalized parallel backoff flm represents words bundles features induces probability model covering sequences extends standard general conditional tables variables heterogeneous types obvious natural order exists multiple dynamic strategies allowed methodologies implemented jhu workshop extensions sri modeling toolkit paper provides initial perplexity results arabic penn treebank wall street journal articles significantly produce bigrams lower highly optimized baseline trigrams multi pass speech recognition context create first bigram lattices best lists relevant word technique arbitrary techniques considered isolation methods particularly suited particular method greatly facilitate production better performance viewed vector factors wt ft including morphological classes stems roots inflected languages data driven semantic useful sparsely clearly factor generalizes class based product probabilities form
657	answering precise questions requires applying natural language techniques order locate answers retrieved documents presented paper participated question track trec evaluations exploits analysis based search multi word terms variations indexes select minimal number processed indices comparing sentence representations comparison advantage module recognition numeric named entities introduction recent need sophisticated paradigms information retrieval generally refers encyclopedic factual require concise current ir enable area calls processing provide rich linguistic features output nlp modules deeply integrated matching components answer selection performed addition collaborate resulting cope large scale broad coverage text databases deriving benefit added knowledge developed evaluated framework qa tracks comprises term entity extraction specific concern conflation variant described extensively publications present contribution terminological variants adding
658	dimension emphasis denotational indirect fuzzy stylistic force expressed attitude emotive collocational selectional subcategorization error mistake woods forest drunk slim father task job pass die stressed frequency conveyed degree dimensions variation previous illustrates merely broad type general synonyms differ respect aspect meaning variations sense including propositional peripheral aspects dialect register expressive structural syntactic building earlier analysis hirst stede types synonym discrimination dictionaries edmonds classifies subcategories categories table gives number grouped discuss kinds involve denotation easily terms clear cut abstract features classic opposition connotation precise needs word literal explicit context independent ideas color emotions attitudes implications tone style simply ambiguous term
659	information era keywords useful retrieval text clustering news domain attracting large attention majority articles indexing manually costs highly aiming characteristics resources available paper introduces simple procedure index based scoring process make relatively mature linguistic techniques tools filter meaningless candidate items furthermore according hierarchical relations content words restricted extracting methods improved experimental results given analyzed showing quality extracted satisfying introduction life important lead people gain time possible solution brief summary document quickly interested read carefully save addition key research topic search frank cost automatically great interests main pay unfortunately small fraction documents field compared unrestricted extract following firstly length phrases repeat secondly
660	corpus based natural language processing tasks popular languages english french studied satisfactory achievements contrast nlp absence annotated training data furthermore hand annotation reasonably determined features ofspeech tags proved labor intensive costly paper suggest solution partially overcome resource shortage vietnamese building pos tagger automatically word aligned parallel transformation learning method bootstrap results exploiting information corresponding words directly project available alignments manually corrected phrase chunker parser sense disambiguator introduction tagging assigning text proper tag context appearance classified various defined attributed definite sentence able perform following order proceed methods hidden markov models memorybased transformationbased maximum entropy decision trees neural network machine general tbl particular prove effective popularity present achieve equipped exactly corpora
661	proalign combines different approaches order produce high quality word alignments competitive linking constrained search scoring em based methods probability model rank possible goal paper bird eye view encourage discussion comparison alignment algorithm glance submitted shared task received aer english french results null data output formatted work explicit works iteratively improving creates initial using constraints correlation scores similar process learns current conducts time according continues validation set begin indicate fitting purposes links words sentence pair describing define following notation let fn link exist ei fj translation correspond defined similarly sentences
662	investigating interactive approach domain qa constructed spoken odqa derives disambiguating queries draw additional information test efficiency requested user initial question combining addition combination answer extraction experimental results revealed potential generated target domains interfaces interactions users accomplish set tasks shown table text speech denote input respectively term represents queried systems separate derived questions data structure specific knowledge db unstructured chat introduction extracts answers large corpora newspaper texts intensively investigated retrieval conference return actual response written natural language first sufficient yield desired collecting needed construct precise friendly interface interaction human beings machines goal includes automatic recognition clarify problems presented building
663	named entity extraction useful natural language applications coarse categories ne extractors work prove insufficient complex question answering ontology generation examine category entities persons method automatically classifying person instances subcategories present supervised learning considers local context surrounding global semantic information derived topic signatures wordnet reinforce algorithm advantage presence multiple contexts text unlike case location names exhaustive lists exist relied training test set finally domain presents challenge individual represented differently different points subcategorization trivial task humans illustrate using simple substitution subtypes politician remarkably classify based sentence unfortunately immediate family cooperate making film idea introduce said dangerous right government wrong told nixon bob introduction recent past concerning automated categorization advances systems successful
664	statistical methods extracting chinese unknown words suffer problem superfluous character strings strong associations extracted solve paper proposes set general morphological rules broaden coverage hand appended different linguistic constraints increase precision representation disambiguate rule applications reduce complexity matching merging algorithm extraction proposed merges possible morphemes recursively consulting dynamically decides applied first according priorities effects priority strategies compared experiment experimental results performance method promising introduction related work sentences characters delimiters mark word boundaries initial step processing segmentation occurrences listed dictionary degraded significantly performances key technology regular structures personal names commonly improving restricting list kinds especially irregular characteristics variable lengths flexible proper abbreviations approaches play major roles previous important issue resolve competing ambiguous extractions include erroneous phrases
665	paper present stage statistical word segmentation chinese based bigram models evaluated peking university corpora first international bakeoff results discussions evaluation known section describes hybrid approach unknown identification report sighan program final conclusions work words introduction important language processing aims recognize implicit boundaries text past decades great success achieved remain problems ambiguity resolution developing practical large applications employ model segment input second develop algorithm perform incorporating contextual information formation patterns rest organized follows presents solution sense process disambiguation viterbi resolve boundary ambiguities particular character string possible wm according given dictionary appropriate
666	annotation graphs provide efficient expressive data model linguistic annotations time series paper reports progress complete source software infrastructure supporting rapid development tools transcribing annotating generalpurpose underlying allows developers quickly create special purpose using common components application programming interface library graphical user interfaces described experience shown straightforward task new based general figure architecture systems ldc developing cooperation nist mitre atlas project widely consortium dialogue interlinear transcription cases transcriptions aligned digital audio signal cover following points manipulating graph importing formats inter component introduction past standardized file coding practices greatly facilitated sharing reuse proved impossible work universally agreed codes contend hope interests better served models
667	increasing concern english korean transliteration previous works direct converting methods alphabets main research topic paper present model using pronunciation contextual rules unlike method phonetic information phoneme context word formation words greek origin shows significant performance increase accuracy introduction technical terms domain specific text especially science engineering foreign written original forms transliterated various makes handle natural language processing retrieval meanings treated different ones possible solution dictionary contains practical mainly cause problem rich productivity automatic languages japanese formula generate given lee defined unit chunk graphemes mapped divided units board oa ao pus represented ith pu sequences km ki generated according
668	investigation chinese named entity recognition confronted principal challenges ensure quality word segmentation speech tagging consequence adverse impact performance ne flexibly reliably accurately recognize nes order cope propose architecture divided phases first phase reduce pos errors leading second possible purpose utilize machine learning techniques repair design finite state cascades automatically constructed depending rule sets shallow parser advantages reliable accurate maintenance additionally special work corresponding strategies enhance correctness experimental evaluation shown total average recall precision types reasonable effective introduction research information extraction topics project collate main motivation investigate language especially linguistic phenomena build model implement application component developed mainly based parsing adopt football competition news corpus exist variety entities relations
669	automatic text extraction techniques proved robust summaries coherent paper propose new method local coherence means improve overall quality algorithms sentence selection proposed evaluated scientific documents evaluation showed noticeable improvements obtained longer produced algorithm selects sentences using evolutionary introduction generally accepted main approaches producing first called extract extracts important tries arrange way methods introduced late similar widely second approach attempts understand generates abstract reason referred generate best known described given domain dependent required preferred currently advanced produce making reading presents novel summarisation cohesion structured follows section present hypothesis possible better enforcing continuity principle corpus abstracts analysed learn holds human combine
670	statistical machine translation generation hypothesis computationally expensive arbitrary permitted search problem np hard hand restrict possible word reorderings appropriate way obtain polynomial time algorithm paper compare different reordering constraints itg ibm comparison includes theoretical discussion number connection known der numbers evaluate tasks verbmobil task canadian hansards evaluation consists parts first check viterbi alignments training corpus satisfy second resulting hypotheses experiments baseline sufficient present extension extended increase alignment coverage introduction given source language sentence fj translated target ei sentences choose highest probability argmax decomposition knowledge sources eq called channel approach allows independent modeling
671	paper presents paradigm evaluating context sensitive understanding capability spoken language dialog peace basis french media project systems various academic industrial sites tested evaluation campaign coordinated elra despite previous efforts eagles disc ongoing american darpa communicator community lacks common reference tasks widely agreed methods comparing diagnosing techniques automatic solutions nowadays sought make possible comparison different approaches means reliable indicators generic methodologies reduce development costs achieving independence task performed evaluations tackled based measurements free information proposal aims shortcomings extracting real corpora test sets synthesize contextual introduction generally speaking compare diagnose lacking discussed section objective assessment reuse work advance theories complex high integration factor tight coupling modules present slds unfortunately accepted architecture exists major problem remains dynamic nature consequently researchers
672	paper present approach term classification based verb complementation patterns automatically learnt combining information corpus ontology belonging biomedical domain learning process unsupervised implemented iterative reasoning procedure partial order relation induced specific first recognition performed looking dictionary terms listed applying nc value method subsequently verbs identified finally classes typically selected arguments considered classify newly recognised precision reached introduction basic notions describing problem concepts attributes identification linguistically represented step automated acquisition knowledge textual documents new intensively expanding representing created dynamic domains biomedicine static models discoveries rise ap makes automatic tools essential efficient atr sufficient organizing acquired assorted groups formed model relations needs reflect property consistently able adapt advent discovered words extracted need incorporated
673	reliably recognizing disambiguating normalizing storing displaying geographic names poses challenges associating geographical point location final stage need understand role document association adjacent text paper develops points discussion different types historical texts rich descriptive gazetteer entries travellers narratives concludes discussing limitations existing mark systems area great britain gis large assembly information sense tied particular places earliest data late established relational database entire content statistical locational acquired collaborators substantial fraction published reports population england scotland vital registration areas general coverage ends early relevant began digital form comprises values closely linked mapping containing changing boundaries various reporting units approaching material formed basis studies economic social change largest source current funding focus grant uk national turning line resource life learners practice means
674	paper investigate cross linguistic phenomenon referred complex prepositions frequent type multiword expressions languages based empirical data point problems traditional treatment cps lexical categories propose analysis using formal paradigm hpsg tradition objective provide approach convincingly explains consistent underlying framework require extensions modifications existing description apparatus computationally tractable french en face au spanish swedish av med lp st english view spite polish du na german hand von mit auf traditionally assumed prepositional character case question arises analyzed make suitable machine processing linguistically motivated applicable computational platforms intended developing typed feature structure grammars starting investigations summary facts indicated considered focus exclusively explicit convincing evidence motivates supports assert proposed discussion various strategies analyzing mwes listing
675	developing corpus based techniques identifying semantic relations intermediate level description paper classification algorithm relationships word noun compounds simple approach using machine learning domain specific lexical hierarchy successfully generalizes training instances performing better previously unseen words baseline consisting introduction exploring empirical methods determining constituents natural language current project focuses biomedical text poses interesting challenges possible make inferences propositions hold scientific concepts texts important technical proliferation typical article title shown consists cascade phrases linked prepositions labeled term study efficacy safety acute treatment real concern analyzing different finding appropriate attachments tackle prepositional phrase attachment problem way analyze meanings goal extract propositional information step according want characterize disease relationship versus method intended combined produce larger variety interpretation paradigms abductive reasoning
676	paper describes indexing substrate typed feature structures efficient retrieval engine given set istfs efficiently retrieves subset elements subsumption relation query structure efficiency achieved calculating checking table prior finding best index paths dynamically introduction tfss retrieve tfs ultimate purpose aimed construction large scale intelligent nlp systems ir qa based unificationbased grammar formalisms recent studies shown using wide coverage noun taxonomy quasi logical form abductive inference outperform bag words techniques accuracy enables knowledge represent symbolic forms output parsing unification grammars documents algorithm concise basic idea necessary condition let defined pv path exist research partially funded fellowship young scientists finds order
677	systran chinese word segmentation important component english machine translation module rule based approach large dictionary fine grained linguistic rules works generalpurpose texts different regions comparable performance participated tracks first international bakeoff paper gives general description results analysis began project months changes convention regarding distinction words phrases new developments mt engine implemented remain unchanged lookup matching using finite state technology expressed context free formalism improving maintainability implementation generates multiple associated probabilities allow disambiguation later stage process possibility applications introduction standard preprocessing steps chineseenglish development issue addressed algorithm early version borrowed japanese program ran list contained entries time basic strategy possible matches entire unit solve overlapping focused
678	paper describes automatic techniques mapping entries database english verbs wordnet senses initially grouped classes based syntactic features provides resource supports disambiguation multilingual applications machine translation cross language information retrieval make training set disambiguated representing verb word sense probabilities frequency counts tagged corpus semantic similarity class probabilistic correlations data attributes best results achieved precision recall versus lower bound assigning frequently occurring upper human judgment chine drop multiply ambiguous potential translations spanish specifies interpretations depending context source inclusion enables selection appropriate target final count belongs selected corresponds meaning prices dropped task differs standard ways first words lexical tokens text second sample approach small number
679	discuss grammar development process generate trees wide coverage lexicalized tree adjoining english xtag project result coupling becker metarules simple principled hierarchy rule application approach successful large set verb small initial syntactic category lexicon word selecting appropriate templates figure shows typical template selected lexical items combined structure derivation right contains history generated derived left np vp vt det pp dt introduction ongoing university pennsylvania aiming natural language resources based grammars experience construction tag ideas initially developed grew larger consistent maintenance harder ltag elementary operations adjunction substitution derive structures sentences driven locality principles given head expected contain projection slots arguments keeping easily number required huge reasonable phenomena engineering
680	introduction
681	paper focus domain ontology acquisition chinese corpus extracting rules designed phrases noun sequences speech tags experiments process construct prototypes efficiently effectively introduction important large scale natural language application systems recognition question answering knowledge management organization memory information retrieval machine translation grammar checking help software perform better understanding building laborious time consuming previous works suggest iterative includes keyword collection structure revised refined filled iteration order hyponym human editor observe sentences containing related hyponyms finding cycle iterates refines obtain quality pairs work try speed labor intensive approach designing applied recursively certain need integrate various linguistic commonsense making inferences consists concepts associated attributes activities forms tree taxonomy defines reference nodes connect different branches integrating semantic network classifies relationships types concept function root
682	define data model storing geographic information multiple sources enables efficient production customizable gazetteers separates names features relationships stored variety allow multiplicity naming categorized axes facilitate selection filtering figure gazetteer process introduction order justify overhead single entity possible output designed different goals perform operations entries comparing entry common language dictionaries determine occurrences documents geographically relevant task export scripts paper focus heart section describes relates handles ambiguities inconsistencies finally outline classification storage interested collecting largest set entities able produce extremely comprehensive currently produced search direct indirect geospatial references text tailored custom applications historical queries purpose provide place supporting mechanisms maintaining know collection
683	paper presents architecture automatic generation interface specifications ontologies ensuing interfaces preserve significant knowledge originally encoded ontology approach relevant engineering large scale language technology systems successfully deployed complex multi modal dialogue smartkom manage enable straight forward mapping respective representation inference introduction important computational infrastructure challenging task especially domain numerous processing modules great extent successful operation depends high quality representations exchanged individual traditionally represent employed various linguistic tasks semantic interpretation anaphora metonymy resolution propose additional way employing modeled basis defining semantics content information lt typically exchange messages parser word lattices input produce corresponding later discourse manager increasing employment xml based agent blackboard communication sets facto standard syntax expressive capabilities structure resulting software licensed free project package documentation obtained http org projects oil allow handling immediately
684	paper improve unsupervised learning method using expectationmaximization algorithm proposed text classification problems order apply word sense disambiguation improved stops em optimum iteration number estimate propose methods experiments solved noun wsd japanese dictionary task senseval score match best public furthermore confirmed effective verb introduction expectation maximization original works causes worse avoid natural language processing converted inductive strategy successful problem requires labeled data expensive manually overcome huge unlabeled boost performance rules learned small referred state art target hoped applied important
685	paper present rich semantic network based differential analysis implemented measures account common features words section industrial applications introduction textual semantics lexical item text broken list intended differentiate word naive feature express difference chair course time define typologies provided discussions nature studies concerning human approach texts called concepts problem formalism allows simple description dynamically inferred dictionary mention door questionable walk important point interpretation sentence context reason pustejovsky introduced nineties notion generative lexicon deal proposes associate core add additional activated notions chains coherence
686	paper present method semantic tagging word chunks extracted written transcription conversations work ongoing project information extraction field search rescue purpose automatically annotate parts texts concepts sar ontology approach combines knowledge sources similarity measure classification evaluation carried comparing output key answers predefined templates process extract reject according tag context rationale relevance depends strongly domain believe reasoning tags instead way getting problems small scale corpora focus based specific overlapping coefficient semantically words first corpus overall explain different components tagger preliminary results experiments finally directions future introduction aiming implement originally conducted defense research establishment develop decision support tool help producing plans given collection transcribed dialogs goal
687	paper discuss experiments applying machine learning techniques task confusion set disambiguation using orders magnitude training data previously string context problem attempt determine current methods benefit additional analyze residual errors learners issues sparse significantly mitigated finally results possible directions empirical natural language research community field remained static confusable word choosing correct given words commonly confused prototypical nlp level identical problems including sense determining lexical features pronoun case determiner number translation speech tagging named entity labeling spelling correction formulations skeletal parsing involve disambiguating relatively small tokens based possess fortunate property supervised free differences members surface apparent written text papers published topic sets million explore happens larger corpora suggest make concentrate considerably effort enlarging addressing scalability
688	paper argue wellknown ambiguity directional prepositions intrinsic relative readings lexical interpreted framework assignment type observed temporal domain drt semantics constructed unified model applied board universal frame types introduction great deal energy spent semantic analysis relations sentence sentences crucially established intensively studied fact eventualities reference respect obtain events instance past tense verb tends absence external clue temporally time utterance say typical contribution simple assessed centred case understood encoding precedence relation event described alice walk river notice larger discursive context speaker control frames order express spatial instantiated indo european languages single configuration expressed different ways depending activated referring unique setting le chat est la cat
689	word dependent dominated first dependency grammars recent proposals link projective projectivity implied definition theories grammar axioms defining acceptable surface structures presence property trees sense equivalent phrase head selection reason determined robinson categorial classical lambek calculus formalisms affects complexity parsing rule allows dynamic programming lead time polynomial algorithms norm natural languages european regular non constructions wh relative clause extraction topicalization comparative specific language french pronominal clitics left terms structure corresponds discontinuity form center discussions ies various based approaches problem framework meaning text theory dependencies nonterminals structured follow distinguish syntactical nonterminal alphabets finite features unification means polarized words specifying enter valency expression intuitive positive node right
690	explore virtual improve performance text classification support vector machines propose techniques create based assumption category document unchanged small number words added deleted evaluate proposed methods reuters test set collection experimental results svms especially training sets introduction corpus supervised learning standard approach achieve high natural language processing weakness need annotated size reasonably large method problem annotation labor intensive expensive order overcome including minimally active spirit utilize labeled maximally following using generated discussed terms lewis gale mentioned forward possible classifier created documents requested human teacher label field pattern recognition kind studied first report sch demonstrated significant improvement accuracy hand written digit
691	paper focus performing lsi low svd dimensions results nearly linear surface local query region using dimensional capture obtain better performance vsm comparably global surprisingly small requirements dimension resolve computation restrictions condition relevant sample documents available application yielded comparable ir rf different manner analysis information set promising way solve computationally demanding task large collection computational complexity david introduced interesting method routing problems basic idea apply known reduced space concentrating able compute flexible efficient algorithms emphasis dimensionality regions filled ideal experimental cases involves surprise experiments obtains best moved try return sets ad hoc worked practical setting
692	key challenge users designers spoken language systems determining form commands recognize using hours interactions quantitatively analyze acquisition vocabulary novice contrast performance term expert developers successfully learn requests achieving significant decrease ill formed utterances working converge significantly smaller rate speech recognition errors remains higher finally observe user small shared indicating importance flexibility conversational interface allows preferred keywords lexical entrainment introduction currently deployed interactive employ restricted syntax constraints provide greater accuracy faster tion times require developer command expressive accomplish tasks designed flexible allow wide variety different levels experience turn constrained understood attempts step rigid single set wellformed inputs varied natural admit range synonymous terms constructions demonstrated substantial synonymy choose
693	paper proposes new dialogue control method spoken systems plan minimize estimated number turns complete depending current speech recognition accuracy probability distribution user request proposed reduces task type different required information determining ambiguous errors various types requests possible case important choose confirm first useless items unlikely affects efficiency cases multiple confirmed intuitively efficient include candidates attributes vocabulary cause misrecognized item say know correct methods previous works account confirmation changes domain specific rules training prevent dialogues accepts estimates expected certain approximated
694	paper focuses exploiting different models methods bilingual lexicon extraction parallel comparable corpora specialized domains first special attention given multilingual thesauri search strategies based investigated method combine presented results combination significantly improves hierarchical information contained thesaurus umls mesh primary importance lastly terminology enrichment discussed introduction growing availability internet distribution agencies providing newspapers articles languages led researchers develop extract lexicons order enrich existing dictionaries help cross language barrier retrieval obtained encouraging completely satisfactory reports chinese english pair accuracy correct translation candidates figure believe consider manual revision furthermore evaluation carried words reaches non studied number work relies assumption mutual http www fr elra home html nlm nih gov lexical model bridges translations frequent collocates likely standard approach consists building context vectors source target word aim capturing
695	categorization text ir traditionally focused topic internet mail increases key area research users demand methods documents work investigates classification format style genre demonstrates complementing significantly improve retrieval information paper compares presentation features word combination thereof using na ve bayes svm classifiers results combined feature sets yields accuracy sorting genres language consistent topics different vary greatly note classifications politics considered broad areas people experiencing growth volume electronic sources include news services online journals time scan source potential equal continuing expansion makes increasingly hard relevant user needs search engines way solving problem dominated hits match requirements yahoo provide hierarchical sites organize web type hierarchies cover fraction largely hand built automatic method building site categories conjunction identification speed hierarchy construction allow frequent updates authors believe classifier
696	simple baselines provide insights value scoring functions starting points measuring performance improvements technological advances paper presents baseline unsupervised techniques performing word alignment based geometric edit distances supervised fusion results using nearest neighbor rule presented work approach problem binary classification task random randomized created coin mark alignments bias chosen maximize measure trial dataset resulting gives insight inherent difficulty categorization balanced exactly half paired tokens marked aligned precision recall best non shifted range suggesting pairs aligner worse perform better predictions introduction methods number align texts lacks benefit large corpus advantage general knowledge language pair relative simplicity speed allow places
697	paper introduces novel support vector machines based voting algorithm reranking provides way solve sequential models indirectly presented risk formulation framework applied parse problem achieved labeled recall precision wsj section penn treebank introduction successfully machine learning tasks unlike algorithms svms search hyperplane separates set training samples contain distinct classes maximizes margin ability maximize believed reason superiority classifiers addition achieve high performance input data dimensional feature space especially kernel trick incorporation remains obvious output svm distance separating probability possible solution map results probabilities sigmoid function viterbi combine approach conflicts purpose achieving called global optimization first constrain local features right scanning strategy furthermore markov suffers mean quadratic maximization label bias means transitions leaving given state compete model intuitively normalization
698	neats multi document summarization attempts extract relevant interesting portions set documents topic present coherent order best performers large scale ion duc outline performs content selection filtering presentation section gives brief overview evaluation procedure discusses metrics results conclude future directions introduction recent years text period revival workshops automatic held area past efforts focused single standard test sets evaluations reported available research community tipster summac address issues understanding conference sponsored national institute standards technology started united states challenge task ntcir project japan tsc aim compile training collections shared researchers provide common multiple participants paper extraction based leverages techniques proved effective term frequency sentence position words
699	question answering systems rely keyword index named entity tagging corpus qa attempt retrieve answers mixed case text numerous corpora consist insensitive documents speech recognition results paper presents successful approach preprocessing module designed restore sensitive form document pool restored feeds remains unchanged restoration implemented hidden markov model trained large raw demonstrated leads limited degradation benchmarking mainly underlying information extraction support introduction natural language recognized capability great potential nist sponsored retrieval conference driving force developing technology track trec voorhees significant progress research recent years harabagiu real life applications robust handle diverse textual media degraded different degrees challenges treatment broadcast transcripts foreign service sources intelligence domain majority archives orthographic written important source particular basic relies heavily recognizing proper names ne utilize related features available
700	paper propose automatic quantitative expansion method sentence set contains sentences meaning task regarded paraphrasing features rules dynamically acquired hierarchical phrase alignment equivalent large generated substituting source syntactic structures experiments average correctly acquisition machine translation applied acquire bilingual simplified carried following characteristics lexical phrasal based structural substitution phrases extracted semantically grammatically generates ungrammatical evaluation quality methods evaluate measuring similarity results translations humans accuracy increases multiple references translated target expressions suitable purpose introduction represented various transfer technique roughly structured
701	realize telephone based collaborative natural language dialogue involves various expressions large number voicexml scripts need prepared handle possible input patterns flexible management user utterances generating dynamically address appropriate modeling order generate cooperative responses specifically set dimensions models skill level knowledge target domain degree automatically derived decision tree learning using real data collected experimental evaluation shows adapted individual users serve guidance novice increasing duration skilled keywords spoken model strategy systems database retrieval ivr speech recognition technology practical simplest form according spread cellular phones enable obtain information places special friendly interaction able accept mixed initiative currently operate script prescribe procedures dialogues behaviors corresponding prescribed procedure basically designed initiated asked required items mixedinitiative allowing combination
702	type say inanimate candidates rejected nps sentence omitted linguistics volume table percentage validity types different configuration characteristics training corpus intrasentential intersentential ed np included pp preposition en proper noun indefinite
703	paper describes fully implemented fusing related news stories single comprehensive description event basic components underlying algorithm explained computationally feasible robust notion entailment comparing information stemming different documents discuss issue evaluating document fusion provide preliminary results conflicting accurate depending sources possible user compile parts original ignoring duplicate typical users include intelligence analysts compiling integral work obviously manually process laborious involves numerous comparisons number length aim approach generate containing repeating conveyed described closely area multi summarization analyzed frequently occurring segments identifying relevant included summary differs focus disregarding contrary aiming shortest instance background allows reader
704	training procedure statistical machine translation models based maximum likelihood related criteria general problem approach loose relation final quality unseen text paper analyze various directly optimize make proposed automatic evaluation metrics new algorithm efficient error count significantly better results obtained criterion account measure success task ideally train model parameters end performance application optimal investigate methods efficiently respect measured word rate bleu log linear let assume given source sentence translated target possible sentences choose highest probability tasks natural language processing simply counting number wrong decisions makes parsing mean average precision ranked retrieval multi reference techniques starts simplifying assumption scoring instance incorrectly
705	query expansion pseudo relevance feedback established technique mono cross lingual information retrieval enriching disambiguating typically queries provided searchers comparable document relatively recent development motivated error prone transcription translation processes spoken language case perform points investigate relative impact pre post mandarin chinese yields highly significant improvement effectiveness improvements combination reach significance identify key factors segmentation orthography limit english benefit concepts expressed documents matching process complicated variety different ways terms available express needs addition dramatically need match expressions languages using automatic speech recognition compensate variation expression underlying researchers developed representation enriched selective topically related large collection techniques proved useful range applications multilingual text context particularly interesting presents multiple opportunities improving
706	paper concerned learning categorial grammars gold model contrast valued classical lambek learnable strings result shown variants question left non associative variant nl class rigid obtained specific construction limit point considered product operator provides points hierarchy including recent aims clarifying possible directions future algorithms expresses difficulty need adequate structure introduction studied field natural language processing adapted perspectives completely lexicalized actual way research determine sub classes remain sense recall consists define algorithm finite set sentences converge obtain grammar generates let wish learn positive formally denote associated given alphabet function sets words exists
707	paper proposes uncertainty reduction machine learning methods training bilingual bootstrapping referred general term collaborative indicates important factor enhancing performance new measure representing degree correlation classifiers analysis furthermore algorithm basis experimental results verified correctness demonstrated significance introduction consider problem includes begins small number labelled data large unlabelled trains label repeats process help exchanging different feature structures class abney conducted theoretical analyses directly studies cotraining propose study point performances classifier defined portion instances make classification decisions
708	latent semantic analysis intelligent tutoring systems assessing students learning evaluating answers questions domain based word document cooccurrence statistics training corpus dimensionality reduction technique doesn consider order syntactic information improve knowledge representation lead better performance present approach called syntactically enhanced lsa generalizes considering neighborhood given speech tag preceding unit experimental results task evaluate basic science comparison presented terms cognitive measures able correctly correlation human evaluators provides discrimination tion need continuous monitoring natural language processing understand contribution circsim atlas parser derive various levels rules determine dialog perform limited arbitrarily free text input port domains limitations alleviated using developed retrieval understanding modeling essay assessor summary street statistical
709	present going work topic learning translation models image data text captions approaches problem assume flat oneto mapping segmented region word assumption restrictive vision standpoint fails account important properties segmentation objects consist multiple parts captured individual regions capture structural relations words outline general framework allowing structured descriptions sides paper extensions probabilistic model brown enable creation demonstrate progress set annotated images derive labeled presence visual linguistic representations implicit semantics using names features referents goal automatically acquire object associated time assignment labels subparts multimodal datasets contain ubiquitous including medical dataset mention world wide web possibility associating textual information way crawler encountered containing particular
710	paper presents empirical studies closely corresponding theoretical models performance chart parser exhaustively parsing penn treebank cfg grammar dramatically affected rule representation tree transformations vs strategies discuss grammatical saturation including analysis strongly connected components phrasal nonterminals model sentence length increases effective size regions yielding super cubic observed time behavior configurations parameters varied transforms encodings list trie min introduction topdown bottomup originated examining exhaustive active using initial experiments yielded surprising result speed led look structure resulting builds presentation charniak extends elucidating non terminal basis build simple predict particular explain originally grammars induced directly local trees entire wsj section parameter setting sentences evenly distributed parsed derived coverage default settings shown bold face possible
711	paper investigates ofspeech taggers using training iteratively trained output noisy question newly labelled add set investigate selecting directly tagger agreement unlabelled data method theoretically empirically motivated literature results based significantly improve tagging performance small seed datasets form considerably outperforms self simply cases yield comparable fraction computational cost introduction variants applied number nlp problems including word sense disambiguation named entity recognition noun phrase bracketing statistical parsing case successfully bootstrap model larger pool previous approaches typically score assigned indicator reliability different approach theoretical work abney selected greedy algorithm explicitly maximises pos pair speech markov tnt maximum entropy yarowsky knowledge
712	maximum entropy model estimated conforms equality constraints feature expectations constraint inappropriate sparse unreliable features study explores box type inequality violated reflect evaluate using text categorization datasets propose extension results natural integration gaussian map estimation experimental demonstrate advantage models proposed introduction attained great popularity nlp field power robustness successful performance various tasks event decomposed indicate strength certain aspects uniform satisfy ep fi represents expectation training data respect powerful robust possible specific general required need independent avoids overfitting spite advantages suffers lack imposes empirical calculated limited size inevitably careful treatment especially applications
713	variety algorithms proposed ne recognition principle language independent applying languages chinese japanese deal certain specific issues build character based model word segmentation errors affect interact related capitalization useful feature identifying nes english spanish dutch lack features performance first paper discuss particular hidden markov various hmm classifier similar described second investigate combination set diverse classifiers statistical combined experiments including mentioned transformationbased learning maximum entropy robust risk minimization remainder organized follows section describes experiment data discusses presents approaches combining annotated corpora ibm corpus foreign broadcast information service offers extensive collection translations transcriptions source monitored worldwide topics military affairs politics economics science technology consists approximately
714	present unsupervised extraction sequence correspondences parallel corpora sequential pattern mining main characteristics method fold first propose systematic way enumerate possible translation pair candidates rigid sequences falling combinatorial explosion second efficient data structure algorithm calculating frequencies contingency table candidate empirically evaluated using english japanese million words results indicate works multi word translations giving accuracy token coverage type introduction paper addresses problem identifying multiword known proceed highlights need finding previous focus include noun phrase fixed flexible collocations gram arbitrary length non compositional compounds named entities approaches common identification meaningful units number factors make handling complicated appears mapping potentially leads necessarily contiguous hampered adjacency constraint third segmentation ambiguous segmented languages chinese resolve ambiguity apply solve effectively avoids inherent concatenating pairs sentences single bilingual applying
715	outline text summarization challenge evaluation conducted tasks ntcir workshop first briefly previous introduction tsc explain including participants data methods task brief report results keywords automatic research hot topic nlp needs discuss clarify issues evaluate systems summac tipster project document understanding conference united states need importance japan kind years realized order researchers field collect share make clearer measures japanese texts newspaper articles set single intrinsic extrinsic evaluations produce summaries recall precision fmeasure extracts subjective free rates follows second information retrieval indicate accuracy
716	audio music encodes high statistical acoustic emotional cultural information important linguistic described great record reviews fan sites news items highlight current ongoing research extracting relevant features simultaneously learning language linked results query task learn perceptual meaning automatically discovered single term descriptive components method uncovering semantically attached terms recent work semantic basis functions parameter spaces description encode highest variance space quiet figure mean spectral characteristics different uncovered frame based attachment magnitude frequency axis introduction listening radio day argue gain knowledge perception grammar develop parameters completely autonomously relations english adjectives learned using new severe multi class algorithm support vector machine training data consists internet correlated entertainment media rights responsibilities recordings reviewed trained obtain perceptually grounded lexicon
717	set paraphrase patterns questions derived corpus report result using automatic recognition question paraphrases aim factor different syntactic variations interrogative words adds sentence making analyze rules map surface structures semantic case frames serve canonical representation process acquired test data results obtained promising introduction phenomenon human languages essentially inverse ambiguity given ambiguously meanings meaning formulated various constructions reason poses great challenge natural language processing tasks notably text summarization nl generation problem important answering systems return answer ask expressed ways work utilized way potential general paraphrasing declarative carry subject reformulation addition rest
718	paper present contextual extension scoring sets concepts basis ontology apply contextually enhanced task alternative speech recognition hypotheses terms semantic coherence conducted annotation experiments showed human annotators reliably differentiate semantically coherent incoherent identify overall best hypothesis given list original correctly assigns highest score corpus inclusion conceptual context increases number correct classifications yield baseline cases introduction following allen distinguish controlled conversational dialogue systems restricted interactions user increase understanding accuracy reliable deployed various real world applications public transportation information predictable users utterances processing increasingly unreliable employ domain discourse specific knowledge bases called ontologies represent individual entities relations algorithm measuring using performance improved means creating method measurement applied estimate fits respect
719	annotation graphs provide efficient expressive data model linguistic annotations time series paper reports progress complete software infrastructure supporting rapid development tools transcribing annotating general purpose underlying allows developers quickly create special using common components application programming interface library graphical user interfaces described experience shown straightforward task new based communication permits reuse design tailored maximally tasks project http www ldc upenn edu ag available repository linked architecture existing level systems demonstrate logical independent physical levels represents built instantiate figure shows currently developed ones discussed signal visualization handled extensible event language support formed operations applications abstract file format issues deal purely keywords transcription coding graph interlinear
720	paper present empirical study potential limitation sentence extraction text summarization results single document generic task defined duc needs carefully reflected low inter human agreement word high upper bound summaries performance achieved oracle extracts promise algorithms first need raise able achieve level compression promising direction ratio affects average introduction automatic systems existing extract parts original documents output compute unigram occurrence score pair manual candidate summary reference scores words best achievable using scoring metric possible contained generated exhaustive search combinations popular majority participating past understanding conference large scale evaluation effort sponsored government based information discourse analysis exist focus limitations hope progress
721	production accurate complete multiple document summaries challenged complexity judging usefulness information user aim determine identifying sub events news topic help capture essential produce better first experiment asked human judges relative utility sentences related larger data create different methods compared automatically created second results applied cluster based automatic summarization experiments examine inter judge agreement metric accounts determining sentence quality relation produces best included manual producing measure subtleties relevance using event approach generally expected performed designed multi summarizer relied clustering method tested policies devised creating technique developed work preceded informed paper allan summarizing novelty recognizes topics consist series distinguish difference differs
722	representation real world information generated shown figure crossmarc multi agent architecture includes agents web page collection extraction data storage presentation communicate blackboard crawling defines schedule invoking focused crawler ben maria institute informatics telecommunications gr net division university edinburgh ed ac uk di tor info jose com proceedings hlt naacl demonstrations pp demonstration first user interface accessed presented prototype supports menu driven querying product databases domains enters preferences matching products including links pages contain offers main shows site results individual modules time sites realtime project languages english french italian greek screen various parts available http www demo images htm acknowledgments research funded european commission written refined human
723	automatically acquiring synonymous collocation pairs turn obj light switch corpora challenging task general large monolingual corpus limited bilingual methods apparently inadequate low precision coverage paper propose method resources optimal compromise first candidates based word thesaurus selects appropriate using translations second language obtained statistical translation model trained small information proved effective select experimental results indicate average recall approach respectively outperform introduction addresses problem extracting english pair includes collocations similar meaning identical wording term refers lexically restricted certain syntactic relation instance verb object means probabilities considered extension concept expressions conventionally include words
724	dipper architecture collection software agents prototyping spoken dialogue systems implemented agent comprises speech input output management supporting define formal syntax semantics information state update language independent particular programming languages incorporates procedural attachments access external resources using introduction complex frameworks involving integration recognition synthesis natural understanding generation interaction domain specific applications components written different running platforms furthermore current developments technology obtained shelf particularly lesser extent parsing overall behaviour controlled component managed flexible way allowing plug play adaptation new domains challenging task architectures paper presents tailored based supports useful approach modelling trindikit regarded first implementation impressive occasions tends impression machine relatively straightforward updating help declaratively stated rules transparent operation
725	existing difficulties cross language information retrieval web search lack appropriate translations new terminology proper names different conventional approaches previous research developed approach exploiting anchor texts live bilingual corpora reducing query term translation undoubtedly valuable multilingual wide scoped hypertext resources particular pair languages contains sufficient extract corresponding generalized applications paper extend adding phase transitive intermediate propose model exploit text mining extraction preliminary experimental results obtained using extracted improved introduction addressing special need users retrieve relevant documents written indexed important issue application practical services lived expectations suffer major bottleneck lacks lexicons containing popular terms nouns enable capability clir ir systems rely dictionaries lingual queries submitted source normally translated target means simple dictionary lookup based techniques limited real world given contain kind dealing corpus
726	approach construction evaluation large scale database called contains categorial variations english lexemes prevalence cross language variation multilingual applications resource serve integral diverse range natural research reported overlaps heavily machine translation lexicon information retrieval communities apply metrics precision recall evaluate accuracy coverage respect human produced gold standard reveals achieves high degree additionally demonstrate improves porter stemmer public release freely available community expect contribution widely recognized future incorporation additional nlp word certain partof speech related possibly different hunger relation basic surface critical work generation focuses rest paper discuss resources differ build present ways heavy mt headline divergence bilingual alignment finally multi component
727	automatic classification textual answers students questions topics physics computing attractive approach diagnostic assessment learning present language expressing rules classify text based presence relative positions words lists synonyms abstractions single word version spaces algorithm learns categorize student responses answer trained written captured online poses multiple choice asks justify explanations reasoning experiments described examine effects negative data tagging original question parts including forum class discussions annotation interface teachers tools displaying various formats philosophy facilitates small group teacher monitor intervene obvious time follow closely observe make conceptual transitions major motivation work paper way reduce burden want information afford needed discussion analyzes selections writing order sentences identify common partially automated analysis markup consisting patterns rule
728	propose gold standard evaluating types information extraction output noun phrase chunks technical terms built notion different semantic syntactic variants arguably correct fully satisfactory assessment quality include task based evaluation conducted experiment assessed subjects choice index access showed significant preference longer measured number words complex prepositions identified human indexer serve experimental protocol reliable rigorous method set important advantage win providing better individual subject experiments time consuming interface test materials data analysis programs completely usable introduction metrics nlp systems precision recall given list units identify performed perfectly principle discrepancy useful particular application preferred beings forms summarization generation sufficient cases challenge designers users distinguish provide generally
729	modern dialog information systems increasingly based distributed component architectures cope kinds heterogeneity enable flexible existing software components contribution presents testbed powerful framework development integrated multimodal paper provides general overview approach foundations describes advanced sample applications realized using integration platform compares related works motivation central element research field intelligent user interfaces construction natural language demonstrate high potential human interaction technology way fundamental products exemplified microsoft speech windows java api novel prototypes constitutes demanding challenge state art combine practical results various areas tend complex simply monolithic desktop application elaborate designs required order assemble heterogeneous fully operational typical project involves work groups different partners leading broad spectrum practices preferences govern particular common needs support programming languages operating extended account costs feasible start implementation scratch important aspect rapid prototyping accelerated progress leads
730	machine learning methods applied natural language processing tasks winnow algorithm argued particularly suitable nlp problems robustness irrelevant features theory converge data remedy problem modification called regularized proposed paper apply new method text chunking achieves state art performance significantly computation previous approaches convergence guaranteed linearly separable practical applications non consequently direct application lead numerical instability modifies original solves optimization converges case stability implies compare algorithms order conll shared task dataset publicly available http ac advantage using large number statistical readily results reported achieved newly furthermore achieve result earlier systems comparable
731	communicator state art speech enabled telephony based application allows end user select reserve airline experiment explores structure information presented complex lists influences experience ability subjects successfully complete selection task presenting relevant needed decision factor positively influenced successful completion preferred hearing flight initiating additional dialog additionally rates improved flights intervening questions desired air travel itinerary selecting multiple possible visual domain relatively simple criteria listed single page likely higher cognitive load candidate serially leading demands result errors sample prototype showing follows help plans yeah fly newark san francisco ok new jersey california trip need arrive pm nd united airlines option number stop departs
732	paper introduces efficient analyser chinese language efficiently effectively integrates word segmentation speech tagging partial parsing based hidden markov model hmm tagger components engine advantage using single largely decreases code size makes maintenance optimise improve speed plays critical important role applications finally performances benefit optimisation existing algorithms adoption better experiments achieve state art high efficiency introduction traditionally text parser outputs complete parse tree input sentence achieving order words second mining necessary unacceptable process millions thousands documents reasonable time compromise performance described shown figure means current node chunked convenience regarded special chunk normal chunks represented tuple ci th sequence wi
733	msr mt large scale hybrid machine translation development language pairs ability acquire primary knowledge automatically parsing bilingual corpus hundreds thousands sentence aligning resulting logical forms demonstrates promise overcoming called customization bottleneck trained english spanish technical prose blind evaluation shows integration rule based parsers processing statistical techniques produces translations quality exceeds commercial systems domain introduction commercially available limited cost effectiveness overall utility need typically includes identifying relevant terminology entering lexicons making additional handle formatting syntactic idiosyncrasies goals data driven research overcome automated semi extraction corpora address variety created described literature employ produce dependency structures aligned obtain transfer rules extract represented linear patterns varying complexity ebmt substantial collections manually crafted reviewed correctness identified efforts report accuracy results fully automatic modest amounts training previous work area raises possibility manual review crafting required bases sufficient coverage
734	text normalization important aspect successful information retrieval medical documents clinical notes radiology reports discharge summaries domain significant general problem abbreviation acronym disambiguation numerous abbreviations routinely texts knowing meaning critical data document paper demonstrate method automatically generating training maximum entropy modeling acronyms using promising technique report results experiment involving number models normalize sample accuracy introduction background marked hand train classifier involves decision tree spectrum fully unsupervised learning methods clustering successfully hybrid class machine techniques wsd relies small set labeled bootstrap larger corpus regardless process context word appears way account encode type discourse
735	present new approach extracting keyphrases based statistical language models pointwise kl divergence multiple scoring informativeness unified single score rank extracted phrases introduction real world text mining technologies analysts required deal large collections documents unfamiliar domains familiarity domain necessary order leverage analysis tools browsing data efficient way understanding topics events particular analyst concerned area hybrid cars harvest messages online forums want rapidly construct hierarchy content addition cases harvested search sort requirement obtain rich effective set terms technology described paper phrase finder capable delivering indicative given target car result process shown figure honda toyota electric motor cell insight battery pack sports si lx focus cells tour sol years daily driver
736	paper present approach acquisition geographical gazetteers instead creating resources manually propose extract world wide web using data mining techniques bootstrapping investigated study allows create new small seed dataset addition produces classifiers online determine class perform average accuracy introduction reasoning locations essential nlp tasks information extraction knowledge place names normally named entity recognition module unfortunately state art systems support coarse grained classifications distinguish non main components gazetteer huge list preclassified entities shown ne performs reasonably classes reliably identified obviously needs sophisticated including various types important possible solution lists existing digital collections task feasible course compatible formats merged automatically timeconsuming compiled provide highquality drawbacks first items simply missing islands mountains contain classified
737	contexts formed natural language expected input information communication systems grammar independent answer users needs requires intelligent able interpret reasonable accuracy time propose method allowing purely semantic based analysis sequences units algorithm inspired idea chart parsing known processing stores intermediate results order bring calculation introduction mass international exchange increases icons mean cross barriers specific symbols needed renewed given rise important works field design reference books history development matter newer studies fields human interaction digital media particularly interested technology nearly possible areas office software operating richer managed instance alternative augmentative designed speech paired people help communicate second learning learners desire master structures target retrieval visual symbolic advantages makes assumption impaired
738	pipelined natural language generation systems grown increasingly complex architectural modules added support functionalities referring expressions lexical choice revision given rise discussions relative placement new overall architecture recent work aspect multi paragraph text discourse markers indicates time consider marker insertion algorithm fits present suggest nlg best approach strongly tie component finally evaluate working page introduction historically focused integrating major disparate sentence planners surface realizers discovered components create highly readable prose types introduced deal newly desired linguistic phenomena pronominalization adding module typically entailed designer justify reason including integrated reasonably optimal pp argued implemented converging facto minimal nonexistent feedback architectures proposed opposition linear arrangement research projects continued actively pursued addition reiter concludes complete integration theoretically idea practical engineering terms inefficient operate actually implement significantly states fully
739	present new approach summary evaluation combines novel aspects content comparison gold standard factoids pseudo semantic representation based atomic information units robustly marked text consensus case individual summaries future work source imperative experiments indicate ranking regard single insufficient rankings randomly chosen dissimilar stable expected larger number collected similarity measurement using unigrams shows similarly low correlation compared factoid introduction say measuring quality hard fact summarisation community task past years effectively aimed finding viable strategies largescale conferences summac duc unfortunately shown weak results current measures distinguish automatic effective human written principle best way evaluate try perform meant first place measure basis degree success executing extrinsic evaluations time consuming set day needed development practice method intrinsic
740	wide range parser grammar evaluation methods reported literature cases evaluations parsers independently effect different real applications measured paper compares link functional dependency parsing systems despite based return types dependencies making direct comparison impossible intrinsic accuracy compared converting grammatical relations using methodology carroll extrinsic impact practical application context answer extraction differences results significant modules work unambiguous defined structures representing sentences expected performance nlp quickly degrades returns incorrect syntactic coverage important according sparck jones main criteria relating objective function role relation setup purpose analyse returned stand broader currently attempt achieve english language substantial
741	paper project concerned development integration base technologies demonstrated laboratory prototype support automated multimedia indexing facilitate search retrieval databases stress role linguistically motivated annotations coupled domain specific information play environment demonstrate innovative technology components operate multilingual create meaningful database introduction develops integrates basic automatic programme material various operating offline generate formal events data processed form basis integral online consisting user interface allowing querying videos video relevant going eu funded society program european union section human language http cs nl projects line time codes extracted documents purpose makes different media sources languages build specialized set lexicons ontology selected non text applies speech recognition techniques extract annotation core linguistic processing consists advanced extraction identifying collecting normalizing significant elements critical appropriate case soccer fact accessing distinct
742	paper presents workbench tree adjoining grammars currently developing includes tools resources based markup language xml convenient format exchange linguistic introduction primary concern lies development efficient parsers various grammatical formalisms natural processing tag important point view possible design work confronted lack standardization especially dealing wide coverage xtag provides implicit standard readable lacks explicit specifications studied presented variations noted problems following lt considered choice represent possibility providing logical specification dtd textual read humans easily exchanged maintained finally exists supports handle store results shared derivation forests output starts brief tags section different encodings designed representation maintenance servers access kind informations interfaces
743	paper propose competition learning approach coreference resolution traditionally supervised machine approaches adopt model preference relationship antecedent candidates determined accurately contrast adopts twin candidate present criterion reliably ensure preferred selected furthermore applies filter reduce computational cost data noises training experimental results muc set outperform based introduction process linking multiple expressions given entity key solve problem determine referring expression document common compete anaphor coreferential various algorithms proposed mitkov knowledge poor pronoun method scores indicators rank centering sort ranking forward looking centers recent years widely achieved significant success normally single classifier judges confidence value values generally best first selection link
744	paper demonstrates polysemy verb grow result natural extension individual meanings basic literal meaning disambiguated applying simple rules elimination argument structures contexts make particular senses viable second section discuss sense focusing semantic components arguments relationships demonstrate required disambiguate third followed sections implications conclusion extended introduction claims connotations develop independent requiring different features new context structure demonstrated computational treatment disambiguation necessary involved application sufficient thank alan john mark lee organizing workshop entitled lexicon figurative language acl japan thanks anonymous reviewers valuable comments responsible errors contain viewed using thematic roles verbs goal source shows interesting relationship according
745	length constituent rhythm plays important role chinese syntax paper systematically surveys distribution constructions statistical data acquired shallow tree bank based survey feature practical parsing task using augment pcfg model results probabilistic significantly improves performance parser introduction syntactic research indicates prosodic features including stress intonation impact structure normally coordination construction interchangeable say change word order meaning quirk gives following man woman obviously explained gender preference reasonable explanation words playing first tends shorter second syllables english verb object equal longer verbs plant grammatical ungrammatical allow nouns objects noun phrases formed
746	paper proposes method analyze japanese anaphora pronouns refer preceding entities unlike case general coreference resolution detected prior expressed discourse integrates probability parameters perform pronoun detection single framework first parameter quantifies degree given second entity antecedent compute efficiently corpora annotations anaphoric relations effectiveness way experiments introduction crucial natural language processing specifically analysis english partially motivated message understanding conferences number methods proposed languages spanish expressions omitted ellipses related obligatory cases termed identifying antecedents pleonastic determined process analyzing different existing classified fundamental approaches rule based statistical anaphors identified handcrafted rules typically rely syntactic structures gender agreement selectional restrictions produce exhaustively developed specific necessarily effective
747	methodology proposed queries requests expressed natural language input answering charts organizing interaction felicitous dialogue graphics languages important modes communication especially frequently people analyze huge data interactively order characteristics resolve questions paper raises problem situations correctness depends context proposes framework core logical form includes specifications user perspective proper treatment handling utterance fragments implemented confirmed appropriate introduction considering importance automatic design suitable achieving given communicative purpose studied actively demonstrated drawn chart intention achieved task accomplished using play roles designing multimedia documents coordinate text research systems assertion conveyed goal pre sentation drawing restricted presentations particular quantitative helps useful
748	significant work devoted develop learning techniques generate partial analysis natural language sentences parse set evaluate direction worthwhile comparing learned shallow parser best parsers tasks perform identifying phrases conclude directly advantageous terms performance robustness new lower quality texts np billion pp earlier concentrated manual construction rules recent motivated observation syntactic information extracted using local examining pattern nearby context speech past years advances statistical methods acquisition progress recognize parsing patterns words participate relationship research inspired psycholinguistics arguments suggest scenarios realistic strategy sentence processing engineering viewpoint first noted applications sufficient noun sequences useful large scale including extraction text summarization second training
749	homograph ambiguity original issue text speech disambiguate efficient approaches proposed gram bayesian classifier decision tree hybrid methods need words pos tags surrounding question homographs disambiguation languages thai chinese japanese word boundary delimiter solving identify boundaries paper propose unique framework solves segmentation problems altogether model employs local longdistance contexts automatically extracted machine learning technique called winnow viewed task number feature based tried tasks nlp including lists hybrids superior previously combine evidence various sources apply treat pronunciation decide using context actually intended instead type syntactic employ synergy types features following previous works adopted collections test presence particular target collocation pattern contiguous extract discriminative space investigate problem select kinds
750	research goals procedures paper interruptions important elements interactive character discourse resolution issues cognitive uncertainty planning representing graphically local global coherence brought systematic phrase prosodic patterns specific pitch height interruption varies expression emotion signals attention getting forms potentially usable spoken dialogue systems provide intelligent responding responsive human motivations dialogues introduction characteristic conversation highly spontaneous mutual information building demands ongoing negotiation process cause informational adequacy desired topic direction play key role signaling resolving bringing mutually satisfactory accommodation interests knowledge states participants act mediate content conversational exchange packed respect communicative pivot points understand communication determine accommodated flexible efficient study goal look distribution occurrences natural speech investigate respective functions characteristics questions address following different types present extent features significant distinguishing underlying factors occur
751	summary disease documents information variant treatment diag extract designed prevent reduce minimize symptoms controlled drugs highlighted differences file content additional topics included available files include definition manual medical contains extensive topic figure healthcare generated indicative half categorizes difference distribution specifically focus problem planning multidocument generation address say section examining document features important summaries starting single context generalizing yields rules thumb guiding calculation reporting norm query implemented module summarization summarizer architecture follows consensus nlg including stages follow sample based shown focusing remainder paper potential structure higher level typically occur strings text approach identify
752	paper outlines central role range human language technologies play emerging discipline knowledge management articulate grand challenges illustrate early successes recommend areas continued research presentation generation promise enhance access information interaction increasing awareness artifacts activities intersecting interests key elements km include cataloguing existing discovering expertise creation new briefly discuss turn introduction mapping past years received attention industry academia government effective cited capability competitive advantage global technology plays article aims elucidate field enhancing organizational performance sharing learning application indicator importance corporations traditionally measured financial aspects value beginning measure intellectual enabled including limited enhanced retrieval extraction summarization times primary issue organizations knowing know providing explicitly captured written policies strategies documents presentations provide individuals tremendous power efficiency material created organization daunting tools required automatically generate classifications taxonomies explicit corporate world success services yahoo
753	standard ir systems process queries web internet enabling users interested avoid documents computing retrieved query irrelevant negated term implement results retrieval remove containing unwanted string letters paper describes evaluates theoretically motivated method removing meanings directly original vector models negation operator quantum logic spaces modelled using vectors orthogonal terms form reduces occurrence synonyms neighbours compared boolean methods altering removes strings application applied semantic tasks word sense acquisition disambiguation benefit similarity pairs continuous function automatically ranking giving judgment addition freely built unlabelled text entirely unsupervised accurate reflection way words practice combined complicated statements commutative bag fashion proved effective certainly leaves room improvement genuine natural language understanding rely solely building
754	paper describes dialogue management attempt factor declarative theory context updates procedural generating interpreting utterances background resources text processing computational linguistics useful distinction drawn models language specify constitutes correct proper sentence discourse interpreted generated virtually ubiquitous structure grammar construct parser generator consults systematic way iteration order interpret create sentences idea systematicity important instance chart process parsing broken sequence operations exactly general form search set rules creation new edge successful fact benefits thinking module consulting grammatical resource clearly seen component expressed systematically increasingly common treatments extended monologues overtly theories texts grosz sidner generation interpretation make reference marcu summary methods respectively attractive feature algorithms envisaged
755	present evaluate initial version combines information extraction based summarization natural language generation support multidocument summarizer turn domain supported evaluation briefly level scenario template contains document agent elements denoting person group organization text disaster encode standard named entities contain event related fields final product set templates user directed summary difference goals influences number design issues first distinguish different reports views multiple sources result creates separate account include reporting time location possible addition damage best grouped according finally slight task necessary extracted constrained noun phrases particular adjectival adverbial reporter confidence sentences clauses relief effort progress appear beneficial creating informed summaries figure shows texts tracking earthquake manually annotated phrase coreference involved relation appears underlined running employs traditional architecture house implementation tipster
756	zipf law states frequency word tokens large corpus natural language proportional rank investigated languages english mandarin ngram phrases single words shown valid high gram combined list order follows accurately lowest frequencies curves identical log figure curve unigrams extracted introduction discovered empirically analysing manually novel james joyce contains vocabulary different types associated following discovery experiments aided appearance confirmed correct small corpora processed time slope vary slightly highest ranked straight line suggested modifications particular constant drawn
757	paper present detailed scheme annotating expressions opinions beliefs emotions sentiment speculation news discourse explore inter annotator agreement individual private state low level annotations useful producing higher subjective sentence introduction states newspaper articles general term covers mental emotional directly observed verified observe evidence happy happiness natural language expressed using composed mixture factual material writers editorials frequently include facts support arguments reports mix segments presenting objective verbal reactions processing applications retrieve extract information summarize answer tions focused primarily benefit knowledge traditional extraction retrieval systems learn concentrate objectively presented question answering identify speculative certain addition realized text new tasks opinion oriented ability appear documents multi document summarization seeking different perspectives trying based questions annotation
758	paper phrase based unigram model statistical machine translation simpler set parameters similar models units blocks pairs phrases decoding block word trigram language training learned source interval projections using underlying alignment experimental results selection criteria counts length various papers systems shown improve quality single introduced present specifically compute probability sequence bn composed conditional probabilities chain rule figure jointly generates target generated approach illustrated given axis types eq defined templates internal structure adjacent computed first clump bi final words exponent
759	paper proposed new supervised word sense disambiguation method based pairwise alignment technique generally measure similarity dna sequences obtained improvements accuracy experiment wsd words loaded bird shot useful deciding serve clue leading discharge case approach association selectional restriction appropriate clues direct syntactic dependencies hand consider sentence edr corpus police said immediately force introduction recognized important subjects natural language processing especially machine translation information retrieval ous methods classified major ones target represented window relations say verb object including necessarily result worse vice versa suppose want distinguish terminate employment brown cousin carried officer opposite rose wall sentential
760	paper gives overview stochastic modelling approach machine translation starting bayes decision rule pattern classification speech recognition resulting architecture structured parts language model probability string search procedure generates word sequence target discuss properties components report results spoken dialogues verbmobil project experience obtained particular largescale end evaluation showed resulted significantly lower error rates competing approaches sentence rate comparison computational linguistics concept statistics years overlooked statement fact automatic faced problem decisions exactly statistical theory success based equation asr acoustic linguistic similarly expressed mt low level description image signals widely accepted framework allows efficient coupling observations models described processing advantage using distributions offer explicit formalism expressing combining hypothesis scores probabilities directly
761	paper proposes method speech intention understanding based dialogue spoken corpus tags regard input utterance sentence similar degree similarity calculated according correspondence morphemes dependencies sentences weighted context information experiment inference intentions using large scale car shown accuracy furthermore developed prototype processing restaurant retrieval task confirmed inferred detailed level act question wh speeches given advance defined extending annotation scheme called arrived kinds presently peculiar enables linking directly operations technique calculation morphologic dependency maximum score accepted
762	paper investigate polysemous adjectives meaning varies depending nouns modify acquire meanings large corpus propose probabilistic model provides ranking set possible interpretations identify lexical semantic information automatically exploiting consistent correspondences surface syntactic cues evaluate results paraphrase judgments elicited experimentally humans correlates reliably human intuitions highly probable rated plausible subjects problem language cook soup fast extensively studied semantics literature properties known vendler adjective noun combinations paraphrased verb modified question corresponding adverb solve easily order account points cases family verbs needed observes figuring combination subject object paraphrasing triggers interpretation trigger learn speak write allow
763	paper presents unsupervised learning approach building non english stemmer stemming model based statistical machine translation small parallel corpus sole training resources text needed phase monolingual unannotated improve allowing adapt desired domain genre results given arabic applicable language needs affix removal resource agreement state art proprietary built using rules lists human annotated addition component task evaluation information retrieval indicates improvement average precision performance introduction process normalizing word variations removing prefixes suffixes work summer ibm tj watson research center point view add additional meaning cases efficiency effectiveness processing applications improved rule new arbitrary time consuming requires experts linguistic knowledge particular supervised large quantities labeled data target quality declines completely methods reach compromise inexpensive readily available conjunction goal develop generator relatively independent trainable
764	natural language processing nlp programs confronted various di html xml documents potential produce better results linguistic information annotated source texts developed annotation lal compliant tag set assisting tools parsers machine translation accept input addition editor allows users annotate graphically seeing tags conducted experiment check quality improvement using introduction increasing applying systems keyword extraction automatic text summarization internet obstacles make cult technologies perfect result problems general added greatly helps follows related helpful know boundaries levels sentence phrases words word dependency relations instance following st possible meanings street saint determine consists sentences went newark paul lived years interpretations interpretation likes people
765	new features algorithms hpsg parse selection models address task creating annotated material train evaluate ability sample methods reduce number sentences necessary achieve given level performance best method achieves reduction training loss accuracy needed inducing lexicalized tree insertion grammars penn treebank suitability active learning type explored paper addresses problem minimizing human effort expended using selective sampling context redwoods contains analyses verbmobil appointment scheduling travel planning domains metrics based entropy disagreement different significantly match according random furthermore combining ensemble require fewer achieving outperform model trained randomly selected results suggest significant reductions realized linguistically rich grammar formalisms basis approach create log linear perceptron previously feature biases types sufficient diverse members committee exactly respect
766	key issues spoken language translation deal unrestricted expressions spontaneous utterances research centered development chinese paraphraser automatically paraphrases prior transfer japanese paper pattern based approach paraphrasing proposed morphological analysis required addition construction method described patterns efficiently learned paraphrase corpus human experience using implemented obtained experiment conducted results evaluated focused cases certain targets reported work rewriting source machine focus reducing syntactic ambiguities titles transforming structures achieve readability summarization noun modifier phrase techniques natural applied pre processing information retrieval introduction resolve problem paraphrased process aims bridge gap input limited translate fact actions seen daily communication listener understand speaker said says
767	natural language generation produces text using input semantic data first tasks decide pieces information convey output task called content selection domain dependent requiring considerable engineering transport scenario paper present method acquire rules automatically corpus associated semantics proposed technique evaluated comparing selected human authors unseen texts able filter half set loss recall large potentially included designer examine sizable number produced different situations determine specific constraints piece goal develop algorithm learned desired outputs aligned related dictate appear conditions process provides identifying relevant viewpoints resulting later filtered ordered augmented stages pipeline focus descriptive realize single purely informative communicative opposed cases knowledge speaker intentions needed particular experiments biographical descriptions planned generate paragraph length summarizing
768	paper addresses recent progress speaker independent large vocabulary continuous speech recognition opened wide range mid term applications rapidly expanding application area processing broadcast audio information access limsi news transcription systems developed english french german mandarin portuguese languages development indexation account specificities data needing deal stream imperfect word areas mining selective dissemination media monitoring introduction major advance technology ability exemplified rapid expansion different sources pressing need automatic streams challenging contains segments various acoustic linguistic require appropriate modeling special section communications acm devoted demand includes contributions sites carrying active research spoken document retrieval support random relevant portions documents reducing time needed identify recordings multimedia databases trec evaluation showed small differences performance observed manual transcriptions key enable content based video encoded channel transcribed accessed using text tools carried multilingual
769	mobile interfaces need allow user adapt choice communication modes according preferences task hand physical social environment multimodal application architecture combines finite state language processing speech act based dialogue manager dynamic output generation tailored text planning enable rapid prototyping flexible input adaptive testbed match provides pen interface restaurant subway information new york city provide mode combination appropriate dynamically maximally effective given situation present general purpose underlying designed highly applications enables access urban environments tourists alike complex constantly changing body regarding restaurants schedules transportation topology valuable delivered effectively places plans change devices offer limited screen real estate keyboard mouse making graphical cumbersome address problem enabling combining graphics detailed overview previous work different tasks users able figure running fujitsu pda
770	explore idea creating subjectivity classifier lists subjective nouns learned bootstrapping algorithms goal research develop distinguish sentences objective first exploit extraction patterns learn sets train naive bayes using discourse features clues identified prior performed achieving recall precision introduction natural language processing applications benefit able factual information remarks variety forms including opinions speculation ideally systems non question answering speculative answers multi perspective aims present multiple user based derived different sources work supported national science foundation grants iis iri data preparation support regional center sponsored advanced development activity government entity sponsors promotes import intelligence community includes limited document summarization need summarize perspectives spam filtering recognize emotional general nearly seeks identify separate previously studied fields linguistics literary theory
771	conll shared task language independent named entity recognition background information data sets evaluation method present general overview systems discuss performance offered training test european languages english german developing includes machine learning component organizers especially interested approaches resources supplied gazetteers unannotated introduction entities phrases contain names persons organizations locations org official heads loc baghdad sentence contains person organization location important extraction work message understanding conferences developers opportunity evaluate competition produced scheme annotation development competitions dealt different concerns concentrate types miscellaneous belong previous groups spanish dutch participants section sources
772	paper describes algorithms rerank hypotheses maximum entropy tagger application recovery named entity boundaries corpus web data first approach boosting algorithm ranking problems second voted perceptron comparable significant improvements baseline considerably efficient train cost computation test statistical parser giving parsing accuracy wall street journal similar applied natural language generation results apply reranking methods extraction state ofthe art generate possible segmentations input sentence probabilities number additional global features candidate evidence max ent learning method variant initially described million words tagged contribution existing useful new domain tagging suggest task stress gives credible extremely simple implement fast viable alternative markov random field
773	paper approach annotate propositions penn chinese treebank diathesis alternation patterns make coarse sense distinctions verbs necessary step annotating predicate structure discuss representation scheme label semantic arguments adjuncts predicates complications type annotation solutions lexical database argument information ensure consistent finally possible applications resource introduction linguistically interpreted corpora instrumental supervised machine learning paradigms natural language processing encoded large extent determines learned systems crucial encode desired level automatic acquisition creation english syntactically corpus played role advances parsing technology beginning help advance technologies syntactic analysis treebanks generally oriented shallow important useful missing notably significant regularities items captured recent effort proposition bank address issue new layer sentences congress passed intuitively clear
774	present principled approach problem connecting controlled document authoring knowledge base start describing closed world situations constraining possible documents user selections additionally choices way information implicitly encoded explicit exploited simplifying new datalog kb sufficient situation description logic better adapted complex pay special attention logically sound solutions decidability issues different processes grammatical text published mda work constitutes valid provided grammars clear separation constraints organization modular solution leave grammar pertaining textual external logical theory express described constrained semantic interpretation compatible aims paper following provide formally precise computationally tractable model using form subsets trade expressivity tractability given representation community activities web starting
775	paper present implications development dialogue systems based evaluation combine interaction information extraction number issues detected concerning primarily management domain knowledge representation presented discussed introduction field question answering techniques successfully handling simple factoid questions approach reached level sophistication connected tailored background structured data capabilities allow precise formulation requests natural challenge features approaches successful combination users allowed access derived large set initially unstructured documents using functionalities history clarification developed first version supports textual bird encyclopaedia source provided text refined framework basis tasks represented ontology utilised assess insights areas need improvement carried results discussion focus ontologies combining
776	automatic restoration punctuation text application improving fluency applicability speech recognition systems explore possibility syntactic information improve performance hmm based restoring best methods reduce sentence error rate substantially additional reduction possible given improvements extraction requisite motivation isolated word connected qualitative improvement naturalness users interactions transcription sufficient make user satisfaction modest increase nonetheless retain important source dictation requirement utter explicitly order free burden reconstruct sequence certain applications instance naturally occurring originally targeted recognizer alternative performing reconstruction different marks likely respond techniques periods question exclamation large problem boundary detection paper address comma published literature limited state art represented berger lafferty review section baseline experiments simple trigram probabilities model trained fully punctuated tested precision recall reconstructing commas removed
777	named entity recognition task proper nouns numerical information document detected classified categories person organization location ne plays essential role extraction systems question answering known hand crafted large set heuristic rules maintain corpus based statistical approaches expected robust require human intervention reported literature recent japanese workshop maximum entropy outperformed decision tree propose alternative method simple rule generator learning experiments performance comparable approach trained efficiently training data improves readability introduction classi want know traditional ir techniques direct relevant documents directly answer finding possible answers build mediocre make reliable number ambiguous cases instance determine washington necessary context major building first employs
778	deep linguistic features predict semantic roles syntactic arguments perform considerably better surface oriented predicting labels lightweight parser generates performs comparably using arg john load hay truck figure propbank style representation loaded introduction syntax mediates word order meaning goal parsing ultimately provide first step giving interpretation string words attention focused semantically annotated corpora required learning available completion phase represents important annotation predicate argument structures penn treebank arc chosen specific universal paper representations effective generally previously employed specifically dependency structure results extraction tree adjoining grammar ptb accompany form basis determining role crucially produced tag suggest suited processing deeper fact expresses notions achieved wide acceptance frameworks unlike particular choices linguists
779	paper discuss performance text based classification approach comparing different types features consider automatic gene names molecular biology literature using support vector machine method range words lemmas stems automatically extracted terms simple occurrences genes documents considered preliminary experiments performed set medline abstracts shown domain specific improve compared standard bag particular classified higher confidence represented classes introduction dynamic development new discoveries biomedicine resulted huge volume constantly expanding size thematic coverage relevant useful knowledge source newly coined relationships representing linking identified created compounds drugs reactions makes existing terminological resources sources need frequently adapt advent appropriate order allow biologists rapidly acquire analyse entities group naming conventions solely reliable criteria typically systematically reflect functional property relatedness biological hand proved surprisingly predict experimental data composition proteins overcome problem methods developed rely supervised learning techniques examine
780	explore morphological analysis preprocessing protein tagging method finds names chunking based morpheme smallest unit determined helps recognize exact boundaries analyzer deal compounds offers simple way adapt descriptions biomedical resources language processing using genia corpus attains score points including families domains introduction paper describes fundamental precursor information extraction interactions medline abstracts previous work bio entity recognition categorized approaches approximate string matching handcrafted rule machine learning ignore fact entities boundary ambiguities unlike general english space character sufficient token delimiter conventional undergoes pipeline tokenization partof speech graphic word subsequent paradigm properly handle peculiarities remedy problem propose achieves sophisticated adapts effectively identifies morphemes units words avoid segmentation suppose appears substring fails segmented instead overcomes
781	paper describes method construct case frame dictionary automatically raw corpus main problem handle diversity verb usages collect predicate argument distinguished closest component order deal parsed results couples multiply millions combinations make wide coverage small analyzed addressed furthermore cluster merge different belong frames components report experimental result structure analysis using constructed kyoto ac jp unsupervised learning strategy japanese construction parse first errors problematic reliable modifier head relations sense ambiguity verbs cases depending meanings load accumulate ni friend sick wo experience
782	parser robust flexible interpretation user utterances multi modal web search newspaper databases users speak type navigate follow links using mouse clicks spoken written queries combine expressions browser commands space restrictions interpreting input fault tolerant account speech phenomena typing recognition errors meaning utterance detect correct integrates shallow parsing techniques knowledge based text retrieval allow processing coordination modes relies layered approach typical meta concerning types dates identified excluded string sent engine terms left preprocessing grouped according occurrence statistics derived corpus concern noun phrases appear texts tions specific section complex context descriptions refer previously dialogue manager stores actions results previous states supplies information order construct fully specified formal underspecified requests freedom behaviour modules needed adequate time cope spontaneous
783	developed discourse level tagging tool spoken dialogue corpus using machine learning methods information focused act relevance segment implemented transformation based procedure resulted accuracy test decision tree respectively fort end research initiative set european japanese researchers develop standard annotation schemes line effort started created scheme various aim tools following section explain relevant introduction communities need corpora recognized creating annotated needs considerable cost recording transcribing annotating checking consistency reliability data considering situation step paper algorithm suitable slash unit defined meteer taylor rules identify function viewpoint speech theory analysis tag reflect local structure improve agreement
784	aligned japanese english news articles sentences make large parallel corpus first method based cross language information retrieval align dynamic programming matching results included incorrect alignments remove propose measures evaluate validity measure article alignment similarities dp sentence clir enhance improve accuracy using successfully constructed largescale available public issues published decade tried noise selectively extract valid paper discuss basic statistics newspapers explain methods effectiveness proposed finally attracted people nlp community source data daily cover period number ranges
785	work propose new method extracting user preferences documents users end first extract candidate terms choose number called initial representative keywords fuzzy inference expanding using term occurrence similarity final extracted performance approach heavily influenced effectiveness selection effective handling uncertainty inherent selecting problem addressed paper viewed finding vector linear text classification literature usefulness compare famous methods rocchio reuters collection results outperforms approaches introduction agent technology able provide increasingly services individuals groups organizations agents developed supported grant korea science engineering foundation internet tasks information filtering presentation contract negotiation electronic commerce rely knowledge inclusion key area model represents aspects needs useful design case models constructed hand learned automatically based feedback provided systems require explicitly specify profiles set categories
786	consider question strong generative power formal increasing weak propose theoretical practical constraints problem introduce formalism maximally context free grammar finally generalize result formalisms cfg figure weakly tag introduction posed joshi important linguistic description natural language processing extension tree adjoining local multicomponent insertion regular form seen steps answering answer unless pin terms precisely first meant standard definition generates set sentences strongly structural descriptions capacity provides vagueness literature reasonably compared theories gives approach vijay shanker weir elaborated becker identify general class linear contextfree rewriting systems define large space serves common ground capacities
787	paper process guiding evaluation transformation language processing research development integrated feasibility experiment explained describing key steps providing specific help understand implement technology teams integrate scenario provides real accessible description assists directly architecture components needed build information given intent operational user typically users involved building early helpful feedback introduction objective reliable repeatable guide systems concept describes ife successfully multiple times years served framework experimentation vehicle integrating applying step people believe ideas interconnections vague incomplete actually best developed using hypothesis test cases allow plug play concepts support inclusion reuse mature plus new focus consists
788	development multi channel digital broadcasting generated demand new services smart highly functional capabilities broadcast related devices especially television viewer aim achieving friendly interface ease built prototype operates voice interactions using natural language current stage research investigate usefulness problem areas spoken dialogue operations conducted usability test targeting data broadcasts bs results revealed subjects trouble accessing hierarchically arranged finding need means desired programs tv select search operate peripheral information reply queries envisage extremely valuable function viewing environment mind set build place manual collecting introduction japan diverse recent years addition analog operating time receiving increasingly complex increasing variety video tape disk players game connected
789	address problem sentence alignment monolingual corpora phenomenon distinct parallel aligning large comparable automatically provide valuable resource learning text rewriting rules incorporate context search optimal complementary ways matching paragraphs using topic structure refining local pairs evaluation shows method outperforms state art systems developed task introduction generation emerging area research nlp unlike traditional applications input transform new satisfying specific constraints length summarization style simplification exciting direction automatic induction transformation particularly promising given naturally occurring texts convey information written different styles presented pair sentences building training set domain belong believe automating process researchers testing resources techniques align multilingual boosted machine translation paper focus language overlap stories events press agencies presenting experts lay people mt extensively studied
790	scope telri action working group investigating formation tool catalogue repository idea similar acl natural language software contents limited corpus processing tools available free cost research offer help line using paper reports setup concentrates technical issues involved creation storage display involves form interface web xml encoding xsl present print lists current entries discusses plans expansion maintenance aa linguistics institute hungarian academy sciences box budapest hu partner institutions community industry general public number goals served archive computational resources tractor features monolingual bilingual multilingual corpora lexica wide variety languages lexicon related primary aim pool partners serves making wider educational archives longer term objective substantial furthermore necessarily directly formalised structure defined process updating presenting closely initiative
791	order answer factoid questions webclopedia qa employs range knowledge resources include typology patterns wordnet information typical numerical ranges semantic relations identified robust parser filter likely looking wrong candidate answers paper describes impact performance locate source corpus course techniques combined popularity ratings web applied filtering criterion resource heuristics results simply going using return majority opinions effects fun altogether applies simplest sophisticated indicate introduction trec evaluations systems require drawn given early simple technique question word density fixed window pinpoint method accurate response answering evolved types extract query words input perform ir possibly segment resulting documents identify set segments containing apply consults different score rank select best bearing sentences frequent justification
792	paper computes semantic representation pragmatically relevant speakers select variety grammatical constructions occur current english provides condition translating adequate german equivalent computation implemented unification based formalism applied machine translation consider following cross language comparison verbs express lexical sense directional motion alongside future going french en train spanish ir introduction analyzes semantics reflecting temporal meaning generally studied linguistic change form investigation concerned synchronic variation lexically autonomous contextually dependent view allows typological study functions languages point particularly interested persistence ideal case observe different constrained sources meanings domain space source time obvious extension categorization create metaphorical transfer model
793	propose novel measure representativeness term given corpus embodies idea distribution words occurring representative biased according word bias defined number distinct occurrences saliency threshold probability automatically using comparative evaluation clarified clearly superior conventional measures finding topic specific newspaper archives different sizes introduction measuring essential various tasks natural language processing information retrieval particularly crucial automatic dictionary construction ir interfaces user indicative topics consist large documents paper proposes effective reflects following focus extracting archive articles literature nlp studies weighting strongly related sequence discrete way account let degree value expected free background noise
794	present derivation alignment template model statistical machine translation implementation using weighted finite state transducers approach allows implement constituent distribution transducer acceptor bitext word performed standard fsm operations involving benefits framework obviates need develop specialized search procedures generation lattices best lists alignments hypotheses evaluate english hansards task report performance source segmentation introduction emerged promising modeling attempts overcome deficiencies models phrasal translations overall based level target sentence phrase phrases words pairs goal paper reformulate intend perform main motivation wfst lies resulting simplicity processes compared dynamic programming decoders optimized algorithms available shelf toolkit avoids gen language
795	paper presents classifier combination experimental framework named entity recognition diverse classifiers combined different conditions gazetteer additional training resources attains performance english development data integrating location person gazetteers systems trained general reduces measure error factor decision arbitrary feature types hmm dependent prespecified path search methods employed maxent construct model rely sequence viterbi algorithm identify best overall starts frequent classification dynamically models interaction classifications effectively performing time differ output return single probability distribution remainder organized follows section describes features briefly algorithms analyzes results obtained introduction investigates set statistical including rule based transformation learning forward backward extension described hidden markov similar bikel robust risk minimization regularized winnow method maximum entropy particular multiple dimensions making
796	paper compares range methods classifying words based linguistic diagnostics focusing task learning english nouns propose basic approaches feature representation distribution simply looks features corpus data agreement analyses level multiple preprocessor systems additionally compare single multiclass classifier architecture suite binary classifiers combine preprocessors finally present evaluate selection method preliminaries introduction lexical acquisition described process populating grammar skeleton items mapping word lemmata types depending precision base complexity simple speech tagging constrained subcategorisation frame clusters constructional particular deep respect interested developing techniques fixed set classify according general exemplified countability syntactic property determines noun singular plural forms affects permissible modifiers countable uncountable lemmas section classes resources research extraction greater baldwin bond classified belonging possible bipartite
797	paper introduces phrasenet contextsensitive lexical semantic knowledge base based proximity simply relation words isolation context english nouns verbs contexts appear organized capture underlying concept connected relations respect contextually sensitive information makes wordnet important source enhances synset contextual refines relational structure maintaining constraints allows supporting functionalities compared natural language researchers linguists learners gain accessing word token retrieve relevant design construction preliminary experimental evidence usefulness nlp researches prepositional phrase attachment reference resolution text summarization necessary component inference providing level abstraction robust decisions inducing ate cake fork grammatical function depends hypernyms noun senses listed different choosing correct decision manually constructed provides database lexemes widely tasks
798	duluth word alignment participated hlt naacl workshop parallel text shared task english french romanian perl implementation ibm model approximately aligned sentences training data language pair results somewhat better varied distortion parameters values observe significant differences performance result introduction crucial machine translation process determining words given source target sentence translations token level meaning corresponding learns probabilistic align consists determined said introduced statistical models general composed components decoder tells probable indicates likely particular
799	trying paraphrases japanese news articles information extraction focused fact single event reported article different ways certain kinds noun phrases names dates numbers behave anchors unlikely change key idea identify comparable extract portions expressions share way convey obtained generalized templates stored future paper first basic paraphrase acquisition method divided roughly steps explained turn illustrate issues encounter real texts solve problems introduce techniques coreference resolution structural restriction possible finally discuss experimental results conclusions systems scan retrieve specific required domain defined advance currently tasks performed pattern matching receives sentence people died hong kong number die location inventory apply slots obtain performance dependent designed patterns natural language sentences expressed need prepare various interested clustering
800	recent contributions statistical language modeling speech recognition shown probabilistically parsing partial word sequence aids prediction leading structured models potential outperform grams existing approaches construct nodes parse tree underlying words predicted paper presents different approach based probabilistic left corner grammar extends focused accurate somewhat robust search space core new model fast context sensitive lexicalized algorithm dynamic programming preliminary perplexity accuracy results appear competitive previous ones speed increased current relies right estimates occurrence given preceding called obviously huge large training corpora contexts occur prohibits reliable probability estimation needs mapped smaller essential information retained spite shorthand denotes wb simplicity trigram lm reduces hard improve main component state art systems
801	arc program paper describes work achieved research project supported coordinated auf deals evaluation term semantic relation extraction corpora french participants public institutions industrial corporations involved responsible producing suitable tasks elaborating protocol order evaluate objectively terminology acquisition tools expression covers respectively extractors classifiers reports methodology comparing classifier campaign products first nlp development recommended corpus list terms characterizing field available giving details results assessment difficulties advantages disadvantages adopted limits proceed future testing group founded started promote aim test software capabilities systems submitted designed canadian private businesses extensively described previous phase
802	manually constructing inventory word senses suffered problems including high cost arbitrary assignment meaning words mismatch domains overcome propose method assign bilingual comparable corpus dictionary clusters second language translation equivalents first target basis aligned distribution patterns produces hierarchy relevant meanings defined set effectiveness demonstrated experiment using consisting wall street journal corpora edr introduction sense disambiguation important subtask necessary accomplishing natural processing tasks machine information retrieval great deal research wsd past decade contrast acquisition human activity inventories constructed lexicographers based intuition division application address problem lines sets enable unsupervised correspondence translations need prepare synonymous conventional dictionaries group according grouping differs addition specific
803	broad coverage lexical resources wordnet extremely useful include rare senses missing domain specific present clustering algorithm called automatically discovers concepts text initially set tight clusters committees scattered similarity space centroid members committee feature vector cluster proceed assigning elements similar evaluating quality task new evaluation methodology based editing distance output classes extracted experiments outperforms known algorithms create state names contain features airport business subway fly introduction applications word sense disambiguation questionanswering words dog company hyponym person make coreference resolution enforce constraint personal pronouns refer hand misses user dialog way deal problems cities using single representative problematic individual element idiosyncrasies
804	present evidence importance low level phenomena dialogue interaction motivate multi layered approach processing architecture separates content communicative processes provide details specific implementations number trips incremental parsing techniques handle range related believe greater focus appropriate lead benefits building systems robust natural paper outline layer shallow maintain smooth participants managing introduction real human involves contribute communication relate directly interactive process includes turn management providing feedback utterance fillers error start timing recent work language general acknowledged presence speech cases role treatment generally standard model parsers able um versions inspiration clean separation sources clark distinguishes separate tracks calls meta simultaneously occurring communications first dealing information hand relating performance refers signals refer delays phrasing mistakes repairs
805	paper deals way temporal connectives affect structure discourse narratives presents contrastive study french puis peu plus tard framework segmented representation theory shows marker narration relation blocks weaker considered weak involving succession addition result different relations hold first sight contribution difference matters simple direction work inspired showing differences behaviour according stake grounded previous studies adverbials location spatial role build spatio showed context relational counterpart roles process locating eventualities space time given spatiotemporal interpretation tackle comparative analysis chosen effective methodology investigating formalizing linguistic clues interact semantic pragmatic interface recover text briefly present sdrt
806	widely recognized proliferation annotation schemes runs counter need language resources standards linguistic increasingly mandatory answer developed representation framework comprised abstract model variety different types instantiated ways depending annotators approach goals paper provide overview demonstrate applicability syntactic contribute comparative evaluation merging parser output diverse introduction particular general flexible extensible accommodate theoretical practical approaches time enabling pivot format serve basis parseval development reusable editing processing tools implemented various instantiations using xml schemas resource definition rdf enable description data models means interpret information encoded according conventions results incorporated eagles guidelines
807	paper present parser based stochastic structured language model exible history reference mechanism slm alternative gram speech recognizer advantage ability return structure given sentence slms expected play important spoken understanding systems current refer prediction introduce called act acts experiment built compared parsing accuracies accuracy higher result shows improves great importance introduction currently state art recognizers dictation satisfactory continuing attempts improvements predictive power needed modeling area research topic results coming focus models proposed purposes powers reported slightly word tri interpolated contrast syntactic covering preceding words step grows parallel able structures
808	paper introduces glarf framework predicate argument structure report converting penn treebank automatic methods achieved precision recall test sentences plans corpus hand corrected output extensions japanese applications mt discussed complement pps adjunct useful likely idiosyncratic interpretation object john angry mary locative distinguished case attempt gap begun project add information using procedures annotation implementing mapping pred arg representation correcting manually particular encode enable greater level regularization linguistic structures possible ptb grammatical logical designed objectives mind capturing constructions represented terms canonical counterparts representing phenomena simple data typed feature consistently labeling arguments adjuncts phrases clear heads producing consistent conjoined named entities trying bar customized representations reflect head properties believe needs satisfy adequately cover uniform treatment relations
809	paper explore power surface text patterns domain question answering systems order obtain optimal set developed method learning automatically tagged corpus built internet bootstrapping process providing hand crafted type altavista extracted returned documents standardized calculate precision pattern average applied answers new questions using trec report results cases determined web introduction recent questionanswering external knowledge tools answer pinpointing include named entity taggers wordnet parsers corpora ontology lists qa evaluation winning resource fairly extensive list apparent surprised decided investigate potential acquiring measure accuracy noted certain types expressed characteristic phrases typical mozart born gandhi suggest given machine technique build large starting pairs similar techniques investigated extensively field information extraction greatly aided fact
810	information animacy nouns important wide range tasks nlp paper present method determining english using wordnet machine learning techniques firstly senses annotated corpus order classify sense known evaluation results accuracy classification noun animate entities identify inanimate ones argued desirable obtain concerning specific gender np referent instead effective define property singular plural number referred pronoun set course discuss verbs expressions denote heads nps referring agents typically previous work investigated determine discourse fact verb derived unique classes called beginners classified hypernym indicative subjects classifying belong
811	paper present learning approach scenario template task information extraction filling multiple sentences tested muc achieves accuracy competitive best systems built manually engineered rules analysis reveals parsing state art algorithms contributed performance knowledge first research demonstrated scale achieve rivaling jan people bomb san juan said path members responsible attack police sources stated involving caused figure snippet document aid benchmark data sets evaluate approaches semistructured texts extracting free series message understanding conferences provided evaluation subtasks identified named entity extracts person names organization location element centered acronym category company relation relations entities finally deals generic items tackle st needs merge general needed discourse processing
812	demonstrate unlexicalized pcfg parse accurately previously shown making simple linguistically motivated state splits break independence assumptions latent vanilla treebank grammar performance better early lexicalized models surprisingly current theart result potential establishing strong lower bound maximum possible accuracy compact easier replicate interpret complex lexical parsing algorithms simpler widely understood asymptotic complexity optimize probabilistic methods work investigation context free grammars results utility pcfgs disambiguation language modeling somewhat disappointing conviction arose key tool high approach great success word gram speech recognition drew strength broader demonstrations dependencies resolving ambiguities pp attachments following decade terms achieved various brought question large role lexicalization plays parsers johnson showed penn improved enormously simply annotating node parent category covering poor freedom embodies way makes
813	propose method interactive paraphrasing enables users interactively paraphrase words document definitions making syntactic annotation word sense managing smooth integration original retrieving correct definition way documents paraphrased fit context preserving semantics improving readability time extra layer necessary showing conventional methods natural language processing techniques summarization translation voice synthesis easily applied results introduction large number great diversity web makes understand lack background knowledge particular technical terms jargon contained unfamiliar meanings encounter unknown scientific proper nouns look dictionaries ask experts friends work looking consuming facilitate effort need machine understandable online automated consultation effective lookup application consults user clicks certain page shows window case accesses inner
814	paper describes new default unification works efficiently gives informative results maximizes information result robust processing framework hpsg extract grammar rules parsing using series experiments extracted robustly coverage manually developed penn treebank greatly increased overgeneration introduction considered crucial natural language efficient wide extensively pursued literature study aims head driven phrase structure extend grammars meaning limited ill formed sentences spoken includes writer expectation studies based explored researchers classified errors analyzing categories make tractable constraint violation missing extra elements focus recovery feature values agreement fall category grammatical components written constraints represented structures expected recovered proposes types application originally ied develop
815	columbia newsblaster tracking summarization robust clusters news events categorizes broad topics summarizes multiple articles event outline current work days producing summaries update user new information outlining perspectives coming different countries clustering summarizing non english sources multilingual version built sharing structure components add capability first web sites foreign languages stores language encoding files extract article text html pages extraction component using independent statistical features computed blocks machine learning classify title image caption trained tested japanese russian data successfully applied french spanish german italian plan train extractor future cluster documents existing document module translated phase simple fast translation techniques available potentially process thousands run developed dictionary lookup interface systran adding arabic performed
816	paper describes new approach generation referring expressions propose formalize scene labeled directed graph content selection subgraph construction problem cost functions guide search process preference solutions resulting algorithm seen meta sense defining different ways allows mimic improve number wellknown algorithms primarily concerned descriptions using properties target object consequently generating relational received attention deserves general relations include description perspective main advantages first attractive dealing structures branch bound finding relevant subgraphs arguably proposed function various known second advantage theoretical framework run problems fact formalized way edges third combined usage graphs natural integration traditional rule based
817	information theoretic argument interpretation mechanism embedded interactive receives input entered web interface generates candidate interpretations terms underlying knowledge representation bayesian network applies minimum message length principle select best results preliminary evaluations encouraging generally producing plausible users arguments keywords discourse networks impact attentional focus process contributions paper follows incorporate formalism described evaluate investigate based argumentation facility detective game following section discuss outline provide overview approach incorporated evaluation reported related research followed concluding remarks introduction essential component dialogue systems developed afford limited opportunities express views constitutes step solving problem builds previous work bias reasoning designed complete eventually engage unrestricted interactions
818	possible learn contexts linguistic operations map semantic representation surface syntactic tree sentence realization high accuracy cast problem learning classification tasks apply straightforward machine techniques decision training data consist features extracted representations produced analysis target links syntax trees evidence consists german code named amalgam case assignment verb position extraposition aggregation introduction stage natural language generation creates string abstract mapping direct employ intermediate significantly constrain output furthermore performed purely rules application statistical models combination systems learned approach linguistically informed allows deal complex phenomena discovery relevant domain facilitates adaptation new quantitative nature permits finer distinctions ranking solutions substantiate claim provide overview input level graph fixed lexical choices content words
819	paper reports work aimed developing distributed learning environment ollie researchers experiment different machine methods information extraction required level performance reached ml algorithms speed manual annotation process browser client data storage training performed servers unified programming interface integration new ones straightforward introduction line application corpus power order make annotator task easier efficient normal working session starts user set documents selecting method supplied choosing parameters module starting annotate texts initial phase learns background actions certain degree confidence making suggestions pre annotating initially erroneous makes necessary corrections learn mistakes increase leading reduction human input implementation based server architecture java enabled web responsible storing models providing access services users implemented pages small number tasks capabilities provided html comprises
820	paper propose integrated knowledge management terminology based acquisition integration xml retrieval combined using tag information ontology tools main objective facilitate query answering documents domain molecular biology integrates automatic term recognition variation context clustering inference intelligent implemented interval operations prove powerful means textual mining aim provide efficient access heterogeneous biological data databases enabling users integrate wide range non resources introduction recent increasing importance electronic communication sharing internet exist increasingly growing number publicly accessible sources form factual intrinsically dynamic autonomously developed maintained independent organizations different purposes constantly new revised added removed nature kss current affiliation dept engineering university tokyo ku japan approaches linking relevant suggested semantic web framework aims link manner resource description express content semantically retrieved manual expected rdf solution known difficulties development mismatches provided automated required
821	bilingual concept mrd significance mt wsd reasonably build lexicon exist ontologies evolution challenging paper forth new approach building wordnet pivotal algorithms characteristic emphasize inheritance transformation existent monolingual hand extracted common knowledge semantic basis developed visualized developing tool lexicographers interactively operate express semantics gradually natural process benefited employing peking university introduction processing content information nowadays center nlp increasingly great sure computational linguists indispensable useful facing ambiguities languages applications time princeton years development profound influence lexicons chinese english issue compatibility account words corresponding vice versa offer better reusability institute linguistics
822	unambiguous chinese geographic represented english text pinyin needs recover characters present approach transliteration problem based processes bilingual lookup suggestion using place character pair frequencies confirmation collection monolingual names www evaluation shows correct recovered candidate depending employed introduction referring entities ambiguous different given encounters foreign texts complication arises alphabet represent native writing uniquely adequately information age documents events news stories commentaries reviews analysis originate various sources languages authors reference necessary accompany actual useful build automatic algorithm decode map original representation language written contiguous string white space cities mountains border regions longer unlike person preferred closed set family gb encoded theoretically admissible refers alphabets process romanization
823	paper presents primarily data driven chinese word segmentation performances closed track using corpora first international bakeoff consists new words recognizer base algorithm procedures combining single characters suffixes checking introduction participated academia sinica corpus beijing university refer segmented texts training unsegmented testing details dictionary frequency assigned dynamic programming technique applied highest probability sentence enumerating possible segmentations respect consider text fragment probabilities computed estimated relative assume steps described section automatically extracted added consisting line xi ts
824	procedure arranging time line contents news stories describing development situation parts deal breaking sentences event clauses resolving explicit implicit temporal references evaluations performance compared humans problem reconstructing chronological order events complicated separate written different times case multidocument summarization judicious definition make hard selecting specific items assign points measuring correctness high leave text address assigning point clause approach break constituent intervals analyze ones result work prototype program input set broken produces output combines articles organized introduction linguists analyzed noticed narratives temporally ordered logical happened presented sequence paper states important reconstruct underlying narrative analysis meaning
825	natural language generation flat semantics np complete problem makes necessary develop algorithms run reasonable efficiency practice despite high complexity convert tag problems dependency parsing useful optimizations recent parsers based constraint programming tackle exactly combinatorics make hard initial experiments display promising runtimes introduction existing realization input exponential worst case different approaches improving runtime suggested literature heuristics smaller subproblems solutions achieve measure success making efficient contrast striking theory problematic explained fact using context free grammars showed shake bake first contribution paper proof stronger completeness result allow semantic indices grammar fix single alternative shows clearly essentially sources word order languages noted easily main point encode variant tree adjoining particular dg topological developed specifically mind mere existence encoding
826	evaluate english french word alignment data shared tasks phrase perspective discuss peculiarities submitted test based evaluation closely related phrases align types set consists samples canadian hansards pre tokenized containing number offset indicate exact translation supposed format sentence tokens shows sample submission plot introduction asking detailed explanation doing je ne ai pas demand sur ces submissions task parallel texts token corresponds permitted restricted allowed aligned segment train systems unrestricted additional resources performance compared hand institutes participated total sets
827	sekine cs nyu edu grishman central issues information extraction cost customization scenario research automated acquisition patterns important portability scalability paper introduce tree based pattern representation denoted path dependency sentence outline procedure acquire japanese annotated text extracts relevant sentences training data tf idf scoring common paths parse extracted yangarber triples predicate subj obj arguments pred challenges careful examination revealed language arise regardless languages free word ordering order significant problems analyzing capture possible given need list separately constraint number cover simple facts rise high keywords introduction systems commonly matching new written customize costly hand led recent minimal pre annotation riloff reported successful result needs
828	paper compare relative effects segment order segmentation contiguity retrieval performance translation memory selection bag words sensitive string comparison methods run word segmented data combination range local models distinct datasets indexing according simple character bigrams produces accuracy superior tested ngram optimum configuration shown equivalent terms faster provide evidence findings scalable complexity price computational overhead follow lead baldwin tanaka asking question empirical effect different match approaches defined speed ideal method offering fast response times high choose focus japanese english tr context key area non segmenting language force approach treating sequence characters alternatively technology partitioning orthogonal sensitivity mechanism treat multiset attempt best preserves original input tackle issue implementing sample representative
829	listen communicate new paradigm human interaction data sources integrate spoken language understanding intelligent mobile agents mediate users information built demonstrate application approach called lcs marine using tactical personnel converse place supply request passed agent execution appropriate database instruct status changes complete demonstrated capability field exercises currently developing applications technology domains overview consists major components sls collection access real world operational databases communications networks connect user underlying architecture mit galaxy conversational distributed middleware product designed plug play specialized servers handle specific tasks translating audio text compliant central server known hub manages flow control handles traffic provides state maintenance speech sent recognizer recognitions parsed prior context added processed natural verify input validity turn manager determines proceed conversations generates response nl converts synthesis verbal
830	define noun phrase translation subtask machine enables build dedicated subsystem improves currently best general statistical methods incorporating special modeling features achieved accuracy german english task vs ibm model tackle maximum entropy reranking framework treating problem instead search pair integrate empirical symbolic knowledge sources outperforms known previous work defining subtasks performed named entity introduction recent research challenges exciting combining prior linguistic power lies quick acquisition vast amounts data analysis provides fitting contributes additional useful finding correct translations present successfully defines phrases demonstrate experiments feasible beneficial treat opens path types syntactic constructs verb clauses issues subcategorization play role focusing narrower allows computationally expensive consider prepositional
831	domain esprit mind spirit wit certain authors impossible translate word level propose recourse conceptual theoretical alternative concepts thought depend human cognitive abilities general shared correspondence words remains controversial topic study concept opposition relevant model translation specific organization breakdown individual language matching operation place substrate set meanings cuts form first present devised languages explain source target spreading method based semantic similarity initially developed basis synonymy note data independent framework organize types lexicon kinds knowledge spatial internal representations world objects proximity reflects object wordnet eurowordnet conceptually network terms associated partition ji maps synsets differs deals lexical semantics perceived miller approach respects grain units structure generation mode resulting geometry
832	memory based learner timbl names english german newspaper text first training data number gazetteers results beneficial case type token generalization applied reduced performance second derived unannotated corpus ratio capitalized versus word strategies gave increase basis nearest neighbours set classification assigns weights features marking importance learning task higher treated important lower parameters adjusted order improve ner described paper varied looks determines feature metrics given way similarity values computed parameter separately weighted overlap modified value difference introduction description describes approach provided material shown better helpful extra
833	introduction statistical machine translation defines task translating source language sentence target traditional framework presented assumes generative process passed noisy stochastic produce formally stated finding search component commonly referred decoding step template based syntax analyzing models assume atomic unit lexical content word ordering effects applied level illustrate assuming correspondence modeled motivate joint probability model explicitly generates phrase languages presents bracketing method reordering phenomenon effectively significant computational expense tend scale sentences reasons introduce knowledge sources effective improving quality addressing problem local boundaries methods attempt fundamentally modify ibm incorporate phrases typically prohibitive cost present technique begins improved create represent global phrasal context robust alignments corpus delivering high
834	define implement evaluate novel model statistical machine translation based shallow syntactic analysis source target languages able distance constituent motion phenomena requiring parse language examine aspects lexical transfer suggesting exploring concept coercion parts speech lemma probabilities holds promise improving low density experiments performed arabic english french demonstrating efficacy proposed techniques performance automatically evaluated bleu score metric paper canonical sentence level order verb means commonly requires entire phrasal constituents cite pair characteristics great influence history work key motivation objective build feature space handle described phenomenon effectively prior pioneered ibm grounded noisy channel similar related problems handwriting recognition original smt exhibits relatively linear correlation sequence common local observed adjective noun swapping adequately modeled relative position distortion models classic approach unfortunately effective japanese substantially different sentential word orders longer wu jones
835	generation internet applications feature ability understand spoken written natural language text gestures body importantly able engage user dialogue application paper design multimodal action management module comic demonstrator aimed understood structures stacks augmented transition networks novel way obtain flexibility needed mixed initiative applied aim overcome immense difficulties using perceptual interfaces combine human sensing perceiving capabilities social skills conventions requires rich communication environment freely constraints given opportunity interact convenient support speech typed pen input facial expressions posture main features regards project addresses problems objectives developing software improve usability services demonstrating form concentrate responsible maintaining
836	present question answering technical domains makes intelligent paraphrases increase likelihood finding answer user implements simple efficient logic representation questions answers maps underlying semantic terminology dealt separate process detects surface variants comparatives vs superlatives better best subordinate clauses sentences linked anaphoric pronouns tree growing new bark grew inference costs price located capital country course combinations different types possible oswald killed kennedy combination knowledge linguistic resources needed deal type using resource wordnet needs effective parsing mapping syntactic structures common deeper structure possibly repository nominalisations complex approaches generic world required instance know implies expressed form axioms following iff paper focus role targeted note reverse perfect paraphrase introduction
837	representation hmm decomposition word position figure represents state note relative values different based const sentence assigning transition probabilities computational linguistics volume number particular consideration model easily transformed absolute replaced possible document pair positions assigned way section abstract formal description viterbi algorithm likely sequence maximizes probability prob using bigram approximated indicated earlier information needed solve problem supposing occurs times guaranteed steps constant compared mn force search slightly revised application initialization step equal chance assumed first iteration special measures handle
838	paper propose integration selforganizing map semantic networks wordnet text classification task using new reuters news corpus neural model based significance vectors benefits presentation document clusters hypernym relation supplements analyse relationships headlines contents series experiments hybrid approach symbolic successful achieve rates articles results demonstrate scale large real world potential memory learning according theory organisation biological systems similar functions placed idea proposed som unsupervised principle multi dimensional dataset low space learns place data areas people choose relevant documents impossible encompass continuously growing source cases categories arranged hierarchy adaptive structure incremental grid cell structures hierarchical coordinates explanation possibly weakness ann models robustness algorithm appealing visualization effects introduction categorization respect set predefined traditional techniques problems present easily adding extra
839	paper roughly described procedures segmentation including methods resolving ambiguities identifying unknown words ckip group academia sinica participated testing closed tracks beijing university hong kong cityu evaluation results performs hk track acceptable pk explanations analysis presented introduction first international chinese word bakeoff algorithm applied process corpora character code conversion gb corpus modifications different standards difference processing lexicon trained specific consulted enhance collection known major difficulties ambiguous earlier work mainly focused using regular expressions handle reduplication compounds adopt variation longest matching heuristic rules resolve achieve success rate counting mistakes occurred existence paying attention problems extracting extraction divided steps detection
840	paper proposes new method word translation disambiguation using machine learning technique called bilingual bootstrapping makes small number classified data large source target languages constructs classifiers parallel repeatedly boosts performances classifying exchanging information regarding experimental results indicate based consistently significantly outperforms existing methods monolingual sense factory corresponds yarowsky refer propose developed order evaluate performance conducted experiments mb related work introduction address problem instance concerned ambiguous english multiple translations chinese goal determine correct given sentence contains actually special case viewed classification addressed employing supervised
841	previous approaches pronominalization largely theoretical applied nature frequently methods based centering theory deals resolution anaphoric pronouns clear complex mechanisms satisfying explanatory power necessary actual generation first illustrate various domains simple method generating implemented multi page present evaluation performance introduction important element automatic creation paragraph texts using natural language authors routinely spanning types genres newspaper copy science fiction academic papers quickly confusing readers begin pay attention writing style content makes text informative enjoyable worse incorrect lead draw inferences furthermore current strategies ill equipped deal wide variety reasons naturally occurring exception focus described ignoring multitude possible certainly make motivated reference addition oriented anaphora parsing ignore structures discourse plan typical include vital information time clause boundaries ordering propositions semantic details verbal arguments algorithms attempt coherence structure work
842	word alignment plays crucial role statistical machine translation aligned corpora excellent source related knowledge present model computing probability given sentence pair allows integration context specific features experiments effective tool improving existing introduction alignments first introduced intermediate result systems researchers interested learn lexicons transfer rules classifiers safe segmentation points addition ibm models proposed number alternative methods involve using statistic log likelihood ratio create score measure strength correlation target words measures guide constrained search produce shown baseline created improve results refined scoring metric based melamed competitive linking explicit noise new turn creates better paper simple flexible designed capture information compute incorporation probabilities critical reader pose question
843	new statistical method called bilingual chunking structure alignment proposed different existing approaches align hierarchical structures sub trees conducts chunks finished simultaneous algorithm using constrains chunk correspondence source language target dramatically reduce search space support time synchronous dp lead highly consistent furthermore unifying pos tagging process alleviates effectively influence deficiency result experimental results model produce precision introduction address problem accepts input sentence pair work author visiting microsoft research asia paper english chinese parallel text relatively extended pairs zhou beijing com chang ning huang produces output parsed sides correspondences machine translation cross information retrieval providing phrase lexicon templates popular methods try parsing technology accuracy guaranteed parser handle authentic sentences strategies suffer shortcomings instance parse matching regards separate successive procedures suffers inconsistency grammars languages
844	present unsupervised learning strategy word sense disambiguation exploits multiple linguistic resources including parallel corpus bilingual machine readable dictionary thesaurus approach based class definition model generates glosses translations senses applied resolve ambiguity words tagging procedure effect produces semantic concordance train wsd systems languages involved experimental results trained longman contemporary english chinese edition lexicon effectively turning tagged data development large untagged training noun homograph method offer explicitly given inventory li huang described similar text noted minimal hand improved methods yarowsky showed bootstrapping small led rivaling supervised extended using corpora bootstrap process effective limited lack systematic preparing seed suffers errors propagating iteration alternative involves surrogate gale church exploited
845	propose statistical method finds maximum probability segmentation given text require training data estimates probabilities applied domain experiment showed accurate state art major characteristic methods research segment texts hearst similarity word distributions consequently exist property important information retrieval summarization tasks deal independent documents application continuous broadcast news story individual stories systems relying supervised learning achieve performance plenty domains algorithm described paper intended speeches able handle requires incorporate available discussed section selects optimum terms defined model new approach previous approaches lexical cohesion topics exam introduction
846	approximately words manuscripts written english guidelines electronic submission style files available http www org cl submissions specified categories papers include word counts reviewed slightly different procedures journal pages receive review reviewers paper contain description single experiment algorithm technical result authors accepted expected submit final versions weeks notification standard longer results large research project dissertation normally exceed length held standards presentation quality letters editor category includes statements opinion issues relevant readership editorial board evaluate appropriateness contributions inclusion hard copy copies sent julia hirschberg labs room park avenue box nj email acl att com phone fax squibs discussions articles reporting algorithms new computational linguistic data tools generally double spaced submitted pierre isabelle xerox centre europe xrce france
847	present unsupervised approach recognizing discourse relations contrast explanation evidence condition elaboration hold arbitrary spans texts relation classifiers trained automatically extracted massive amounts text distinguish accuracies high explicitly marked cue phrases south africa afford sales actually makes profits sale expensive technology systems designated aircraft electronic tactical anti mobility introduction field research widely agreed sentences clauses understood isolation given level explaining nature providing definitions surprising robust programs capable identifying consider sentence clause pairs standards preclude arms states currently subject crisis able legally buy markers help figure holds unfortunately signal corpus rhetorical structure trees built observed
848	named entity phrases translate new appear domain specific bilingual dictionaries present novel algorithm translating using easily obtainable monolingual resources report application evaluation arabic entities english compare results obtained human translations commercial task introduction introduced news stories daily basis form personal names organizations locations temporal monetary expressions identification text received significant attention bikel translation problem especially challenging important tool nlp applications cal machine systems component handle phrase order improve overall quality crosslingual information retrieval identify relevant documents based provided question answering benefit substantially answer factoid questions involve paper arabicenglish technique applicable language pair require obtain rest organized follows section overview
849	paper propose practical approach extracting relevant paragraphs original document form summary thai text idea exploit local global properties property considered clusters significant words paragraph relations combined ranking summaries experimental results real world data sets encouraging excerpts concatenating shorter recent works research area based extraction argue makes hard read lack coherence depends objective summarization need generate indicative topics addressed alert source content function capable handling kind tasks researches problem initial stage developing mechanisms automatically summarizing documents challenge summarize extremely different written english similar chinese japanese writing boundaries adjoining explicit sentences fortunately structure indicated blank lines spans level
850	paper presents ongoing task construct daml oil compliant chinese lexical ontology mainly comprises components hierarchical taxonomy consisting set concepts relations describing relationships entries associated axioms constraints currently contains excluding hypernym hyponym associating introduction semantic web relies heavily formal ontologies structure data comprehensive transportable machine understanding constructing applicable influences success largely consists upper limited abstract generic domain broad articulate constructed cyc approximately terms organizing knowledge base kb working group ieee trying standardize specification called expected enable computers utilize applications natural language generation information retrieval extraction services estimated contain plus roughly definitional statements term research refer
851	previous attempts identifying translational equivalents comparable corpora dealt large general language words address task specialized domain medicine starting smaller non parallel initial bilingual medical lexicon compare distributional contexts source target testing weighting factors similarity measures test set frequently occurring best combination correct translation ranked first candidates additional reverse filtering step improves precision candidate recall background salton demonstrated carefully constructed thesauri cross retrieval perform monolingual experiments training statistical models compilation disambiguation query limiting factor expensive investment human effort collecting size chen nie potential solution automatically web pages texts composed independently respective communities communicative function prevalent development lexicons information research easier collect proposed correlation cooccurrences translations fung associations word context seed preserved different languages designing procedures retrieve crosslingual lexical peters
852	framenet project developed lexical knowledge base providing unique level possible syntactic realizations specific semantic roles evoked roughly units basis annotating sentences extracted corpora version data released widely new portable software available researchers including spanish demo poster briefly explain principles frame semantics demonstrate unified tools lexicon building annotation search tool finding patterns annotated discuss content format releases nlp introduction lexicographic research aims produce containing detailed information relation tween syntax verbs nouns adjectives substantial subset english basic unit analysis defined type event state participants associated elements frames range highly abstract replacement fes old sentence pat replaced sense verb replace constituting apply cook food
853	anaphora resolution important research topics natural language processing english overt pronouns definite noun phrases company anaphors refer preceding entities japanese omitted omissions called major approaches pronoun heuristic approach machine learning various factors consideration combination rules attractive requires large training data paper propose method combines ranking simple effective account results experiments gives better performance previous introduction topic instance translation systems identify antecedents source achieve quality target studying domain question answering expect qa benefit typical try answer user finding relevant corpora correct phrase keywords given succeed correctly resolve answers represented chances increase motivation developing ability text newspaper articles
854	regular improvement speech recognition technology past decade solved problem systems tuned particular task porting new requires substantial investment time money expertise state art rely availability large amounts manually transcribed data acoustic model training normalized text corpora language obtaining consuming expensive requiring trained human annotators supervision paper address issues recognizer portability activities aimed developing generic core order reduce manual effort required development main axes pursued assessing wide domain models evaluating performance tasks investigating techniques supervised exploring transparent methods adapting specific achieve higher degree introduction seen impressive advances capability recognizers able transcribe unrestricted continuous broadcast acceptable arise increased accuracy complexity closely related spoken faster cheaper computational means enabled implementation better decoding algorithms despite extent progress recent years extremely sensitive environmental conditions speaking style channel quality speaker characteristics background work partially financed european commission ist
855	paper presents results applying latent semantic analysis methodology small collection parallel texts french english goal determine reveal regarding difficulty level task text alignment perfectly corpus exactly aligned expected word distributions languages symmetrical machine translation low deviate lsa contribute understanding mt ta tasks credits discusses implementation available hlt naacl daily house journals canadian parliament edited procedures implemented statistical computation graphics written john university techniques generate abstract numerical representation relationships words documents identify symmetry exists pattern associations occurrence language exact correspondent shows
856	present empirical corpus study meaning usage time phrases weather forecasts based novel analysis technique align forecast text data extracted numerical simulation previous papers summarised discussed substantial variations discovered individual writers surprising finding paper procedure results considerably discuss current work using parallel corpora learn meanings types words evening apparently meant people possibility variation acknowledged past ignored recent lexical semantics published key findings notably individuals described purpose research introduction nlp systems interact world need models mean terms non linguistic determined analysing manually written texts human examined writing textual first aligns fragments segments infers phrase statistically aligned
857	paper proposes method collecting dozen terms closely related given seed term proposed consists steps first step compiling corpus collects texts contain using search engines second automatic recognition extracts important nakagawa extracted candidates final filtering removes inappropriate based engine hits evaluation result shows precision web figure configuration acquisition technical certain domain studied methods require large manually prepared target contrast requires word compiles produces introduction study aims realize case natural language processing expected collect morphological analysis parsing information retrieval machine translation application semi compilation glossary dictionary recursive enables list
858	examine clarification dialogue mechanism refining user questions follow context domain question answering systems develop algorithm recognition analysis collected data dialogues importance evaluated shown successfully recognize occurrence majority cases simplify task answer retrieval aim determine searching response collection documents order achieve narrow search using information techniques select subset paragraphs containing keywords concept corresponds correct type exact sentence sought attempting unify semantically kind logical transformation form pattern matching single meet goals elaboration required enable refine understanding questioner needs number researchers looked theoretical point view oriented aware work ones presented trec workshops apart experiments carried qa workshop seek partially address
859	present document compression hierarchical noisy channel model text production first automatically derives syntactic structure sentence overall discourse given input statistical order drop non important constituents generate coherent grammatical compressions arbitrary length outperforms baseline based operates simplifying sequentially sentences results support claim knowledge plays role summarization introduction single systems proposed fall following classes extractive summarizers simply select user comprehensive overviews methods algorithms accomplish headline generators probabilistic trained large corpora pairs produce sequences words indicative content simplification capable compressing deleting unimportant phrases extraction outputs contain fragments hypothetical summary shown table compacted clause win summaries informative repeatedly applying algorithm time compress generated way likely incoherent information
860	conversational interfaces offer greater flexibility users menu driven navigate figure architecture nla menus rigid structure permit ask queries directly words understand terminology designers identifies concepts constraints label hyperlinks website hierarchical product attributes telephone websites textual user input mediate mapping executing simple transactions available products specifications finding information paper implement business logic present dialog natural language assistant manager current requirements formulates helps shop notebook computers discuss action plans perform end operations results studies conducted constructs response based discourse history sends presentation displays prompts features assists satisfy needs relevant context mixed initiative engaging turn provides answer specific question incremental feedback understanding provide shows match encouraging iterative refinement query deployed external
861	natural language data case original symbolic researchers convert numeric process feature extraction ad hoc nature differs nlp task neat formulation generating vectors semantic grammatical structures texts kernel methods suitable devised convolution kernels demonstrate build discrete strings trees graphs remarkable properties methodology retains representation objects algorithms manipulate simply computing functions inner products pairs means map explicitly representing efficient calculation pair defined method widely adopted machine learning support vector addition function described similarity satisfies certain measure important factors tasks application areas translation text categorization information retrieval question answering paper proposes hierarchical directed acyclic graph handle cal definition defines nodes contain dags basic chunking parsing analyze semantically grammatically levels chunks phrases named entities sentences bound
862	ambiguous sentences traditional semantics construction produces large numbers higher order formulas reduced individually underspecified versions produce compact descriptions readings known perform reduction using constraints constraint language structures based dominance extend parallelism binding operation trivial knowledge essentially reduce described deriving description paper reductions performed framework clls approach extends work presented defines shows obtain complete solution procedure reducing problem previous necessary local disambiguations add new mechanism class permits steps disambiguating general plan start introduce core present apply illustrative introduction approaches employ logic derive semantic representations compositionally applied simplify input sentence require enumerated
863	paper describes outline linguistic annotation framework development iso tc sc international standard provide architecture creation manipulation resources processing software described results meeting approximately experts field determined principles fundamental structure goal maximum flexibility encoders annotators time enabling interchange annotated introduction language bodies electronic data support research applications area natural typically enhanced information morpho syntactic categories discourse reference aligned correspondences past years increasingly large created engineering community certain representation widely adopted stand xml attempts generalized mechanisms formats developed remains case vary considerably resource satisfy constraints imposed particular recognized commonality interoperability imperative enable sharing merging comparison organization standardization formed sub committee technical devoted management objective prepare standards guidelines effective multilingual society end
864	paper describes creation script framework ontological semantics formal representation complex event bankruptcy serves basis discussion general motivations including scripts nlp discovery process format purposes processing coreference inferencing required high end applications introduction immediately adjacent text acme actually moment employees laid sketch section status deals heuristics information goes sort knowledge engineering presents resulting formatted certain grain size discovered briefly problems acquisitions poses advanced new called massive effort acquisition events provided ontology inception reasonably welldefined constantly adjusted consecutive releases early mid lower meaning based mt necessitate heavy generation higher similar make necessary recognize individual effects
865	dictionary based protein recognition first step practical information extraction biomedical documents provides id recognized terms unlike machine learning approaches problems large number recognitions mainly caused names low recall spelling variation paper tackle problem using method filter positives present approximate string searching alleviate experimental results genia corpus filtering naive bayes classifier greatly improves precision slight loss resulting better score introduction rapid increase readable texts makes automatic attractive especially extracting interactions medline abstracts regarded important tasks extract proteins recognize text kind studied field natural language processing named entity provided annotated gold standard evaluating training algorithms research efforts techniques biological entities drawback provide identification purpose interaction swissprot indispensable integrate extracted data sources hand intrinsically
866	paper argues computational cognitive psychology linguistics offer science language adopting research strategy called starting testing success important real world problems education offers ideal putative applications latent semantic analysis presented lsa works doesn successfully automatic essay grading content coverage feedback computing optimal sequences study materials partially automating metadata tagging insufficient scoring mathematical textual answers revealing reasons explained measuring occurrence measure similarity words effect passage meaning bush advisor war course funding structure modeled national institutes large industrial laboratories bell labs ibm microsoft shows trajectory followed dramatic scientific advance exception rule summarized view relations table figure minor additions modifications pure pragmatic engineering illustration conception slightly modified upper left driven desire understand nature chosen natural phenomena pervasive intuitively interesting particle physics
867	paper proposes algorithm causality inference based set lexical knowledge bases contain information items event role hierarchy relevant relation antonymy features mainly symbols hownet types questions experimented test effectiveness proposed particularly question form dealt works introduction virtually linked base designed utilize pre constructed dynamic mode actual domain answering architecture consist various components processes include resources speech tagging parsing named entity recognition processing passage retrieval answer extraction justification consider following doctors patients obtained commonsense follows patient suffered disease doctor hospital pay occupation money earn hypernym roles partially filled entities shift agent source overview component figure word entries dictionary concept facets converse described linguistic human syn possession target
868	tiered approach evaluation spoken dialogue systems tiers measure user satisfaction support mission success component performance numerous fielded studies conducted military tier metric scheme evaluates multiple aspects lcs effectiveness set subjective measures introduces perceptions assessment overall respect definition scores individual role collection input essential reasons first necessary consider perspective achieve better understanding needs second preference influence interpretation measurements tradeoffs inefficient producing higher users willing overlook efficiency guaranteed opt helps determine relative importance quantify defined differently different establish early process applications derive domain knowledge acquisition potential important evaluate components individually evaluations reveal distinctive flaws negatively impact failure prevent completion tasks marine fails recognize signing radio network ignore subsequent utterances
869	paper introduces set guidelines annotating time expressions representation times refer applications benefit annotated corpus include information extraction question answering summarization machine translation visualization values communicated addition handling fully specified rd handles context dependent significant recent study mani wilson revealed print broadcast news ones local months hot global subclass indexical require knowing speaker speaking determine intended value weeks keywords annotation temporal semantics iso introduction processing poses numerous challenges nlp progress accelerated based methods scheme described novel features goes message understanding conference muc terms range flagged importantly representing normalizing
870	depth study using dictionary web search engines boost performance automated question answering webclopedia definition questions results indicate applying based answer reranking increase set trec mean reciprocal rank score finding answers introduction attempt progress information retrieval research text conference sponsored national institute standards technology started series large scale evaluations domain independent systems continued ntcir initiated evaluation effort challenge participating coming qac focused problem closed class fact collection bear similar structure analysis identify keywords submitted recognize types suggest expected rely taxonomy number nodes varies widely single digits thousands abney hovy harabagiu taxonomies named entities wordnet special added necessary passage sentence aims provide pool manageable size extracting candidate performing methods passages sentences extraction extract according
871	mitre work darpa tides program preparing series demonstrations showcase integrated feasibility experiment bio security current demonstration illustrates resources available analysts monitoring infectious disease outbreaks biological facilitate integration multiple stages linguistic processing ife provide richer modules contributed participants include additional functionality real time broadcast news feeds new machine translation components support questionanswering cross language information retrieval multi document summarization automatic extraction normalization temporal spatial automated geospatial displays keywords detection tracking topic highlights basic required analyst including capture sources mail digital library material groups web based categorizing orthogonal hierarchies useful region source various text select relevant portions named entity event spanish portuguese chinese english access group reader allows organize save share familiar readily accessible environment display alternate forms color tagged documents tables summaries graphs map introduction term goal delivery demand live line
872	demonstrate source lkb teach fundamentals constraint based grammar development groups students active considerable number researchers worldwide introductory book implementing grammars typed feature structure formalisms using completion demo outline overview environment distributed lingo tools implemented common lisp standalone application run linux windows macintosh license required includes parser generator support large scale inheritance hierarchies various manipulating semantic representations rich set graphical analyzing debugging extensive line documentation sizes written languages linguistic frameworks categorial headdriven phrase initially developed gone multiple versions successfully demonstration concentrate relatively small teaching type practical exercises english fragment linked textbook formal syntax illustrate conjunction traditional materials linguistically oriented course parses discuss way parse selection mechanisms incorporated
873	research dialog systems concentrated interactions single user machine paper identify novel directions arising multi party human interaction scenarios participants interact introduction current work spoken involves recent years initiative commonplace commercial telephony applications important advances mixed modal possible collect large amounts data benefited empirical methods based automatic training addition evaluation frameworks improved utterance accuracy measures decade level subjective quantitative advanced new area developing recognition analysis meetings talk shows proceedings industrial settings pose challenges speech speaker tracking frequent talker overlap noise room reverberation introduce discourse modeling using corpora hours collected environments remain error handling response generation technology point envision tackling combined problem key motivation domain supporting humanhuman collaboration scenario plays role conversational agent interacts
874	coreference resolution systems attempt suitable antecedent noun phrase recent studies definite nps anaphoric claim obviously holds study try learn automatically classifications relevant problem small training corpus acquire data internet combining classifiers sequentially achieve precision recall discourse new entities expect provide improving speed performance introduction proceed following way first identify possible markables check candidate pairs trying members coreferent final step ranked using scoring algorithm order appropriate partition classes approaches require substantial processing worst case total number poesio shown exhaustive search needed phrases prior referents higher account types non conclude engine benefit pre filtering identifying save time discarding half second hope reduce
875	using finite state automata text analysis component speech problematic respects rewrite rules compiled write maintain resulting large inefficient converting knowledge represented explicitly efficient format indirect route learning decision tree representation data tapping information contained existing increases performance compared exclusively pronunciation lexicon principle huge monolithic transducer time practice feasible enormous sizes machines reasons space efficiency certain computations run significant impact clear need human expert experts deal aspects ideally constructed automatically individually meaningful features supplied practical content methods address issues make legacy systems moving new way building tts entail starting scratch case study transition achieved letter phoneme french described construct produce alignment convert aligned training instances induced
876	tap xl automated analyst assistant application designed help write topical report information large multilingual multimedia data gives users ability spend time finding relevant task translingual reach languages leveraging human language technology description exploits monitor user interactions provide suggestions analysts maximizing spent reading documents writing reports document passage fact saves deemed valuable suggests related located stream force learn suite distinct tools suggestion metaphor employed technologies pull bring value additional interfaces metaphors learned separately cited create citation button places selected excerpt hyperlink original source triggers entities included deleted seen figure addition mechanism employ traditional keyword based query locate process results feedback loop allow
877	present methods automatic creation parallel corpora previous work construction focused harvesting web examine existing bootstrap data new language pairs first extend using training machine translations selectively added multiple source texts retraining translation models yields modest improvements second simulate pair corpus available starting human german english produce model accuracy languages suggests method useful scarce resources explains simple terms reasons large amounts ensures quality program sees particular word phrase thousand times likely learn correct increasing material leads improved illustrated figure plots frenchenglish trained incrementally larger produced increases items graph trend continue notice rate improvement slow manually provided sentences change performance sufficient statistical access millions aligned approach proposed
878	paper develops method recognizing relations entities sentences mutual dependencies account kill relation oswald johns depends identifying people identified location turn enforces framework classifiers identify first learned local information sentence constraints induced entity types perform global inference accounts preliminary experimental results promising approach improves learning separately determine problems errors named recognizer propagate classifier degrade performance significantly boston person classified second crucial resolving ambiguous recognition instance victim unlikely novel problem probabilistic separate trained output represent conditional distribution given observed data make inferences probable assignment
879	report current state development document suite applications collection tools flexible robust processing documents german based xml unifying formalism encoding input output data process information organized modules limited responsibilities easily combined pipelines solve complex tasks strong emphasis laid number techniques deal lexical conceptual gaps typical starting new application computational linguistics text technology low possible experience consequences design work project guided following principles abstracted experiments realistic introduction designed implemented workbench electronically available decided exploit accompanying formalisms framework expect deliver results format ist precursor sgml offers annotate pieces texts precise seen sequence characters allows associate arbitrary markup subsequences contiguous linguistic units represented strings encode substring interpreted meaningful unit directly occurrence straightforward idea
880	paper describes distributional approach semantics verb particle constructions report first framework implementing evaluating models implementation techniques using statistical acquired corpus data infer meaning introduction semantic representation multiword expressions target renewed attention notably area hand written grammar development items cause considerable problems semantically grounded nlp application simply function constituent parts based empirical shown limited problem work approaches compositional compound nominals szpakowicz hearst idiosyncratic largely ignored attempts identification noncompositional phrases valuable means end matter unique challenge posed mwes precisely fall cleanly binary classes non populate continuum extremes reason lack computational linguists established gold standard construct evaluate evaluation tended fairly ad hoc key firm foundations notion compositionality given background aims treatment
881	paper presents approach ellipsis resolution framework scope underspecification argued improves previous proposals integrate application processes anaphora require disambiguation work directly underspecified representation furthermore shown presented cope discussed dalrymple problem noted introduction explicit computation configurations apt slow nlp considerably ambiguities important prerequisite efficient processing tasks arguably best performed fixed order formalism support execution aims upgrade existing discourse theory structures thanks discussion motivation colleagues saarbr cken literature single quasi logical forms constraint language lambda primarily aimed devising methods quantifier scoping interact closely end description languages modelled steps derivation need executed explicitly recorded constraints final structure evaluated finally interpreted contrast providing supports interpretation theorem proving understood
882	paper proposes hidden markov model hmm based chunk tagger named entity recognition built recognize classify names times numerical quantities able apply integrate types internal external evidences simple deterministic feature words capitalization semantic important triggers gazetteer macro context way ner problem resolved effectively evaluation muc english ne tasks achieves measures respectively shows performance significantly better reported machine learning consistently handcrafted rules introduction word document predefined categories taxonomy computational linguistics falls domain information extraction extracts specific kinds documents opposed general task management seeks extract form main content step intelligent atomic elements attractive trainable adaptable maintenance cheaper rule representative approaches maximum entropy decision tree variant eric brill transformation applied aberdeen higher reason
883	categorial grammar traditionally calculus represent meaning present alternative dependency based perspective linguistic situate computational setting formalized terms hybrid logic rich perspicuous propositional ontology enables wide variety semantic phenomena represented single formalism finally couple formalization combinatory produce interpretations compositionally semantics discuss representations indexes identify subparts logical forms introduces evaluates respect criteria frameworks shows build using ccg unification intonation information structure incorporated approach indexed captured building parallel inference lexical entry verb wrote given introduction enjoyed years standard encoding grammars grammatical recent work highlighted inadequacies concerns representing natural language couples resource sensitive proof theory formalize paper context properties framework linking follows briefly introduce links syntax write rules combination defined
884	present application ambiguity packing stochastic disambiguation techniques lexical functional grammars domain sentence condensation incorporates linguistic parser generator lfg transfer component parse reduction operating packed forests maximum entropy model output selection furthermore propose standard evaluation methods automatically evaluating summarization quality systems experimental shows correlation automatic based manual generated strings overall proposed state art guaranteed grammaticality constraint original document extraction choose unix implementations apples appears advantage condensed introduction recent work statistical text forward merely extract concatenate sentences learn generate new summary ext tuples depending chosen task single headlines multi provide module designed combination challenge guarantee need syntactically wellformed retain salient information approach mittal ordering terms bagof words models grams produce summaries indicative content gram insufficient grammatical formedness
885	classification task integral named entity extraction received attention biomedical setting partly fact protein recognition focus majority work field study problem different sources information utilized investigate extent contributions domain developing specific algorithm names main make simple techniques verify intuitions usefulness characters words text separate phases believe gain examining tasks sufficiently distinct identification importantly perspective current hope help solving similar approaches internal external clues situation specialized biomedicine need investigation large number methods proposed focused extracting class recognized directly address identifying string constitute explicit manner
886	introduce probabilistic models identify elementary discourse units build sentence level parse trees syntactic lexical features parsing algorithm implements derives error reduction state ofthe art decision based parser set empirical evaluations shows model sophisticated yield accuracy matches human levels performance bank says attribution enablement network channel investments figure structure rhetorical relation span labeled nucleus satellite distinction nuclei satellites observation expresses essential writer purpose represented graphically style shown arrows link holds linked horizontal lines correspond text spans vertical paper information exploited process identifying building evaluation indicates propose achieve task deriving working produced segments introduction
887	evaluating competing technologies common problem set powerful way improve state art technology transfer poorly designed evaluations waste research effort mislead researchers faulty conclusions important examine quality new evaluation task establish reliability paper provides assessment analyzing trec question answering track analysis demonstrates comparative results stable empirically estimates size difference required scores confidently conclude runs different metric based human language muc duc continue proliferation understand communities accelerate advance costs addition financial resources support researcher time focus defined validity assess workshop series encourage text retrieval realistic applications providing large test collections uniform scoring procedures forum organizations interested comparing conference focused primarily traditional information retrieving ranked list documents response statement need includes tasks called tracks areas particularly aspects started
888	present language models based immediate head parser conditions events constituent accurate statistical parsers variety previous grammatical model technology perplexity significantly improve trigram base line best grammarbased better improvements respectively suggest improvement underlying term potential properties descendants assigned probabilities conditioned lexical figure probability vp expands np pp choices sub heads ball experience parsing community design worthy note generative sentence try parse defined equation arg max interesting insofar compute define assign possible sentences computing sum introduction
889	term translation spotting refers task identifying target language words correspond given set pair text segments known mutual translations article examines context sub sentential memory support tool capable proposing portions sl sentence extracted archive existing different methods proposed based statistical model advantage certain characteristics application produce tl submitted constraints contiguity compositionality experiments imposing allows important gains accuracy regard probable alignments predicted sequence word tokens si output sets answer respectively figure shows ts italics represent query bold answers seen contiguous possibly satisfying way linking finds applications bilingual machine focus subsentential section discuss fits type propose series specifically adapted
890	kernel based learning successfully applied hard problems natural language processing nlp feature combinations crucial improving performance heuristically selected methods change situation merit effective combination implicitly expanded loss generality increasing computational costs text analysis shows excellent terms accuracy slow apply large scale paper extend mining algorithm convert classifier simple fast linear experimental results english basenp chunking japanese word segmentation dependency parsing new classifiers times faster standard named entity recognition known features contributes significant improvement instance task confirm correct relation single set head modifier relations determined information phrases previous research manually significantly depended selections case methodology polynomial mapped space maximal margin strategy svms gives generalization compared manual selection main reason delivered great field
891	present carmeltc novel hybrid text classification approach automatic essay grading evaluation demonstrates outperforms bag words approaches lsa naive bayes purely symbolic introduction paper using technique analyzing answers qualitative physics questions tutorial dialogue contrast previous automated goal assign letter grade student essays instead purpose set correct answer aspects previously systems auto tutor research methods perform type content analysis performed successfully task domains literacy demonstrated poorly causal base predictions included functional relationships propose alternative rule learning bases features extracted carmel deep supported onr cognitive science division grant number nsf circle syntactic analyses texts obtained rainbow evaluate domain highly demonstrate
892	aper first addresses series issues basic evaluating usability spoken language dialogue systems including types purpose evaluation evaluate methods user involvement present discuss comprehensive set criteria introduction increasingly important issue development companies pay large amounts know exactly features make sldss attractive users spite key importance resources invested aspect years slds component technologies neglected surprisingly research related reactions field linguistic behaviour main factors determine overall satisfaction growing recognition partly independent technical quality constitutes competitive parameter walk shared goal tasks expected undertake extensive training read manual help available online needed infrequently possible systematic understanding account optimise consensus ideally
893	chunk parsing focused recognition partial constituent structures level individual chunks attention paid question analyses combined larger complete utterances desirable deeper syntactic analysis constitute necessary prerequisite assigning function argument structure present paper offers algorithm functional labels subject object head complement basis input evaluation concentrated measuring quality performed german english treebank using different annotation schemes results correct validate general approach data coverage versus traditional parsers aim narrowly defined set particularly promising widely kind main insight underlies strategy isolate non recursive highly efficient architecture realized cascade finite state transducers pursues leftmost longest match patternmatching despite popularity gap current research comparison
894	propose novel training method statistical parsing algorithm input small corpus annotated parse trees dictionary possible lexicalized structures word set large pool unlabeled text iteratively labels entire data using empirical results based wall street journal parser combined labeled strongly outperforms zhou previously train classifiers applications sense disambiguation document classification named entity recognition apply complex domain unsupervised techniques language processing machine learning exploit successful attacking problems nlp aspects considered issues adapting new domains testing higher performance limited amounts separating structural problem lexical ones improve unseen particular success moving promising approach combining seed unlimited bootstrap parsers paper technique successfully tasks web page early work area speech tagging reported high pos hidden markov models
895	generate sentences metonymic expressions systematically intended literal referent appear singular definite form approaches aspects deviate characterization pustejovsky generative lexicon addresses first aspect proposes theory qualia explanation systematic polysemy applying type coercion enables arrive cases ordinary metonymy grounded terms semantics lexemes word senses termed logical reading book sentence mary enjoyed contexts reflect prototypical knowledge derived agentive telic roles lexical entry prominent structure nouns particularities acceptability leaving relation implicit indirectly second account scoping relations impacts pronominal reference introduces distinction referential predicative depending argument accessible subsequent manifests different scope hold arguments corresponding forms argue usage resulting strict accessibility hahn address interactions extension anaphora resolution handle textual ellipsis references apply extensive language independent conceptual definitions relational path classifications preference rules corpus indefinite nps indication objects approach cardinalities extended accordingly augment representing cardinality information
896	dynamic programming matching carry approximate string deletions insertions document effectiveness efficiency poor large scale information retrieval paper propose method effective conventional capable efficient keywords corpus based japanese yamamoto proposed acceptable search report improves introducing idf weighting schema strings contribute similarity calculate weights words improved speed slower typical aim improve keeping mathematical point view changed definition structure remains new makes possible build creating index advance surprise observed introduction known ability edit distance applied measure documents
897	headed tree terminal word uniquely labeled governing grammatical relation labeling summary syntactic analysis eliminates reflects aspects semantics relations nearly uncontroversial define notion expected governor markup sums vectors indexed governors scaled probabilistic weights quantity computed parse forest representation set analyses given sentence using vector scaling probability flow figure percolated lexical heads reads work trees terminals addition forms derived lexicon lemmas chains node head written subscripts notation vertex ordinary category label triple represents environment chain vertices maximal parent constructed domains sets addresses relative address negative integers child positive domain finite sequences
898	goal paper integrate conceptual mapping model ontology based knowledge representation order demonstrate metaphor analysis restricted eventually automated particular propose operational definition principles explanations conventional source target domain pairing examine random economy mandarin chinese postulate frequency delimited grammar english lexicon underlying dealing metaphorical meaning necessary treated different cognitive level really case general extracted proposed lexical constrain contemporary theory analyzes linguistic correspondences determine reason pairings formulated terms principle postulates constraint says select domains involve unique idea building food reasons addition cm able explicate polysemy inherent given presupposes conventionalized linguistically priori supported psycholinguistic experiments correctly predicted processing differences involved novel metaphors
899	proposed method hidden markov model based word segmenter support vector machine chunker chinese segmentation firstly input sentences analyzed produces best candidates class information confidence measures secondly extracted words broken character units annotated possible position features finally brings determine boundaries first decide number states assume belong classes probability problem defined search sequence cn given wn target maximizes following arg max methods participate closed test sets data bakeoff steps sentence segmented assigns measure trained baum welch algorithm tag derived
900	task named entity annotation unseen text successfully automated human performance involves identifying scope span class grounding aspect neglected paper geo spatial entities grounded using geographic coordinates results visualized shelf software compare textual surrogate newspaper story visual based tagged newswire resolved place names introducing new graphical document section deals usefulness question answering presents related work concludes gazetteers large lists enriched information size location appendix identifies publicly available sources official gazetteer united nations freely web site contains locations countries database geographical including relationships state province county country region known recognition evidence kind finite nature makes limited classification relating linguistic subtype real world counterparts index resources
901	cs jhu edu annotations existing english tools paper describes set algorithms automatically inducing stand monolingual speech taggers base noun phrase named entity morphological analyzers arbitrary foreign language case studies include french chinese czech spanish text analysis applied bilingual corpora output projected second statistically derived word alignments simple direct annotation projection noisy optimal presents noise robust tagger lemmatizer training procedures capable accurate bootstrapping incomplete initial projections performance induced achieves core tag accuracy corresponding exceeds measure analyzer lemmatization complete verbal achievement particularly noteworthy required absolutely hand annotated data given virtually specific knowledge resources raw significantly obtained place national jj laws applying hong kong nns nnp implementing law dt nn significant producer crude oil important figure projecting tags structure
902	work apply clustering technique integrate contents items item based collaborative filtering framework group rating information obtained result provides way introduce content recommendation solves cold start problem extensive experiments conducted data analyze characteristics results approach contributes improvement prediction quality especially limitations hard provide recommendations selected recommended novices systems effectively using peer opinions predict interests target user matched database discover neighbors historically similar text developed xerox palo alto research center applied project university minnesota popular widely areas recommends music albums movies jokes online radio overcomes suggest users ratings instead improve successfully practice remain challenges
903	present methods learning structure personal names unlabeled data first simply implicit constraints governing gain problem descriptors second model possible coreference information improve performance interested right way named entity recognition noun phrase determination introduction unsupervised wall street journal text specifically consider sequence proper nouns single defense secretary george smith analyze components models henceforth typically individual mentioned times article pattern references mutual help determine correct attracted offer small semantic structural best knowledge
904	dictionary look unknown words particularly japanese complicated writing propose allows learners according expected necessarily correct reading improvement previous systems provide handling incorrect readings preprocessing calculate possible kanji character different types phonological changes occur associate probability using probabilities corpus based frequencies plausibility measure generated given entry naive bayes model response input corresponding display list candidates user choose implemented web environment currently evaluating usefulness major difficulty learner characters hand present bigger obstacle high number presents challenge matter fact frequently unrelated including ta simple combinatorics compound basic considers variation greater presented string first time possibly large potential problem occurrence combinations compositional
905	using svms named entity recognition confronted multi class problem larger number classes severe multiclass especially vs rest method apt drop performance generating unbalanced distribution study tackle phase based dictionary first try identify svm classifier post process identified entities simple look second classify semantic dividing task subtasks identification classification alleviated furthermore select features relevant alternative according experimental results genia corpus proposed effective reduction training cost improvement accuracy introduction knowledge discovery rapidly growing area biomedicine important provided vast texts impossible grasp huge form natural language computational text analysis techniques nlp received bioinformatics recognizing proteins cells fundamental tasks biomedical conceptually consists finds boundaries determines
906	paper presents study effects syntax configuration southern british english using dialogue materials perception experiments carried first subjects heard fragments syntactic completeness contour systematically varied asked expected subsequent turn exchange second presented speaker exchanges material thought intended results suggest completion non main factor predicting behaviour high level tone appears operate holding device regardless utterance grammatically complete similar dutch basis findings overriding predictor possible change effect hypothesised likely signal hoped gain insight similarities differences languages data map task recorded according conventions described collected project chose dialogues cambridge represented closely standard variety analysis introduction studies intonational cues qualitatively theoretical framework
907	paper explores contribution broad range syntactic features wsd grammatical relations coded presence adjuncts arguments isolation subcategorization frames instantiated words tested performance using different ml algorithms senseval data adding basic set traditional improves especially adaboost addition methods build arbitrarily high accuracy systems tried showing allow precision coverage introduction supervised learning successful paradigm word sense disambiguation kind follows step process choosing representation context occurrence target senses applying machine algorithm train extracted tag test current attain performances coarse differences training material available contrast finer grained application needs recent work shows possible exploit trade tags limited number predefined syntactically motivated ranges complements detection specific measured combination local topical decision lists
908	named entity recognition systems need integrate wide variety information optimal performance paper demonstrates maximum entropy tagger effectively encode identify entities high accuracy features obtained languages works english german dutch incorporating diverse set overlapping hmm based complicates smoothing typically taggers contrast easily deal gaussian prior parameters effective large feature space ratnaparkhi pos described curran clark models form exp fi introduction treated tagging problem word sentence assigned label indicating type methods speech chunking ner papers conll shared task reported results significantly lower best zhou su state art muc data using suggests relatively poor largely sets machine learning method demonstrate case improving
909	techniques automatically training modules natural language generator proposed fundamental concern quality utterances produced trainable components compete hand crafted template based rulebased approaches paper experimentally evaluate sentence planner spoken dialogue eliciting subjective human judgments order perform exhaustive comparison generation component rule planners baseline performs better systems baselines handcrafted introduction past years seen large increase commercial dialog typically initiative strategies highly scripted style register recorded voice factors argue continued simple producing conversation first text tospeech improved point viable alternative pre prompts second perceived need flexible support user requires greater flexibility utter ance finally complex planning developed require sophisticated output prerecorded possible string templates current research conceptually straightforward linguistic needed write tedious time consuming task written combination goals discourse contexts issues subject verb
910	propose algorithm automatically induce morphology inflectional languages using text corpora human input combines cues orthography semantics syntactic distributions morphological relationships german dutch english celex gold standard evaluation improvement knowledge free proposed previous approaches introduction nlp tasks building machine readable dictionaries dependent results analysis analyzers existed early current algorithms require labor build rules structure attempt avoid intensive process recent work focused learning large paper structures language corpus produces output set conflation sets indicating various inflected derived forms word abuse contain forth extends earlier induction combining induced information sources semantic relatedness latent approach corpusbased affix frequency context transitive closure hand labeled lexicon version achieves score task identifying outperforming applied evaluated fallen categories differ depending provided goal
911	natural language processing developers face number new challenges increasing real world systems nlp tools techniques quantity text available training dramatically range languages tasks researched continues grow rapidly ideal time consider development experimental frameworks requirements initial design exploratory implementation high performance infrastructure introduction practical grown recent years accuracy fundamental speech tagging named entity recognition broad coverage parsing increase construct address complex problems information extraction question answering progress technology complete spoken dialogue feasible developing involves composing different unfortunately implementations designed components input output standardisation considered finally tune particular task experiencing explosion electronic data manually annotated million words american national corpus corrected pos tags penn treebank currently taggers require efficient learning algorithms greatest raw processed english gigaword work suggested benefit using significantly potential applications involve large databases
912	paper focuses analysis prediction called aware sites defined turns user spoken dialogue first speech recognition error statistical comparisons features train timetable corpus reveal significant prosodic differences compared correct errors normal corrections present machine learning results combination automatically available predict turn correction site exhibit frequent communication breakdowns mainly automatic component systems interactions evidence showing information resource recovery previous work identified new procedures detect particular recognizer distinguish misrecognized better traditional methods asr rejection certain typical identify findings consistent research tend higher longer current study focus category potentially useful handling examine term interacting
913	paper shows linguistic techniques machine learning extract high quality noun phrases purpose providing gist summary email messages set comparative experiments using algorithms task salient phrase extraction main conclusions drawn study modifiers semantically important head gisting filtering improves performance combination classifiers accuracy evaluation models settings indicates equally better ngrams level representation document enhances section outlines aspect extracting emphasizing features classification symbolic presents steps improve discusses stated introduction present applied natural language summarizing topic domain general text unstructured syntactically formed characteristics raise challenges automatic processing especially summarization approach implemented identify first candidate units representing meaning select
914	present evaluation results talk travel spoken dialogue language making air plans telephone fully conversational mixedinitiative allows user specify constraints plan arbitrary order ask questions general english independently evaluated darpa communicator program achieved high success rate meaning task state represented path constraint representation inference component included deduce implicit requirements explicit statements premises change interfaced yahoo flight schedule website access live information queries separate thread manager monitors reports figure architecture byblos recognizer gem nl understander introduction paper describes presents complex research prototype sponsored systems ward seneff common mixed initiative multi city trip including flights rental cars similar european arise project earlier version presented discusses independent conducted section gives brief overview
915	paper presents method develop class variable memory markov models higher capacity traditional structure induced manually annotated corpus decision tree learning algorithm series comparative experiments resulting outperform uniform speech tagging task introduction major nlp tasks regarded problems finding optimal valuation random processes given word sequence involves syntactic classes np chunking iob tag sequences machine techniques developed tackle process include hidden maximum entropy support vector machines svms high performance especially target classification requires consideration various features hand hmms low work classifications tightly related global optimization pos recent comparisons better combined smoothing handling unknown words strong point developers make incorporate improve performances cases certain lexical context hmm based tagger incorporating additional degrade overall coupled
916	wordfreak natural language annotation tool designed extend new domains tasks specifically plug architecture developed allows components added customized visualization specification automatic compilation ins provide mechanisms allow annotators taggers guide future supports active learning present annotate number different types english chinese arabic including constituent parse structure dependent annotations ace named entity coreference java source code distributed public license sourceforge http net site provides web version needs led focus making software easily extensible reusable included integration tools entirely facilitate multi platform support include data scheme define type place implements common interface adding additional requires implementing additionally examine environment run gathers implement interfaces original called viewer user looks perform currently contains display text trees concordance tables respectively particular better
917	pseudoword composite comprised words chosen random individual occurrences original text replaced conflation pseudowords useful mechanism evaluating impact word sense ambiguity nlp applications standard method constructing drawbacks constituent contexts necessarily reflect real ambiguous occur turn leads optimistic upper bound algorithm performance address propose lexical categories create realistic evaluate results different variations idea approach low inter annotator agreement randomly highly likely combine semantically distinct drawback produced using characterize terms types model plausibly motivated pairings introduce category membership generation main note relative frequencies pairs tend represent unambiguous drawn generate remainder paper based process methods disambiguation task mesh medline hierarchy equally applicable domains thesauri ontologies concept assigned descriptor codes corresponding particular positions
918	seek knowledge free method inducing multiword units text corpora machine readable dictionary headwords provide major evaluations existing collocation illustrate continuing need improvement latent semantic analysis make modest gains performance significant challenges encountered trying approach mwu generally satisfy constraints compositional phrase typically excluded hard copy constituent words listed strategies allow dictionaries remain compact mentioned wish space issue mrds desire follow lexicographic practice reducing redundancy sproat indicated simply expanding encompass word likely encounter wrong fails advantage regularities goal identify automatic algorithm finds collocations necessary supply definition means process proceed human input solved problem exist suspect suffice finding verify evaluate best identifies valid using completely separate gold standards wordnet internet web based resources dynamic better coverage scores comparable indicate needed induction attempt improve headword introduce algorithms lsa technique automatically
919	specification performing page layout provide first illustration application prototype multimodal information presentation conclude summarizing main contributions work follow research development leading data driven aggregation visualization natural language generation commonly recognized value presentations lies appropriate overlapping textual graphical differing strengths weaknesses combination achieve powerful conversely simply placing guarantee view supportive perspective graphic text relation result synergy cf discussions authors hovy green means ensuring mutually compatible modes drive communicative intentions automatic generator receive task expressing broadly similar chance resulting perceived affect systems mittal clearly crucial correspondence ways related approach derive elements different components single plan
920	paper presents simple practice efficient technique serving automatic detection positions partof speech tagged corpus error suspected approach based idea learning later application negative bigrams search pairs adjacent tags constitute incorrect configuration text particular language describes generalization grams natural provides powerful tool implementation discussed evaluation results negra german general implications quality statistical taggers illustrative basic command helpful understanding complexity necessary accompanying explanation glossed translated central ideas understandable knowledge errors pos corpora training defined naturally deviation regularities expected learn case means contain assignment ungrammatical constructions body cases present process necessarily confused view probability distribution configurations correct worse positive evidence occur output tagging linguistically texts simultaneously getting
921	objective work disambiguate transducers following form able apply determinization algorithm described approach disambiguating consists first computing composition transducer important consequence result allows compose number contrast previous consisted produce respectively unambiguous present results case representing dictionary phonological rules keywords ambiguity deterministic dependent phones converts sequence context independent mapping implements pronunciations words represents language model sequences restricting possible assigning score speech recognition problem finding path cost acoustic observations inherent correspond word handled adding special symbols remove order
922	paraphrasing critical interpretation generation natural language current systems manual semi automatic methods collect paraphrases present unsupervised learning algorithm identification corpus multiple english translations source text approach yields phrasal single word lexical syntactic introduction alternative ways convey information method acquisition practical linguistic point view diversity expression presents major challenge nlp applications multidocument summarization required repetitive input documents employed create varied fluent manually collected tailored specific application utilize existing resources wordnet identify process collecting time consuming collection reusable include syntactically based questions concern operative definition types relations mechanisms produce linguists agree retain approximate conceptual equivalence limited synonymy extent phrases form question provide insights revealing people paper extraction large parallel novels provides instances preserve meaning original
923	paper describes application state art spoken language technology new problem domain engaging students automated tutorial dialogues order evaluate improve performance training simulator damage wall previous work introduction control refers task containing effects critical events occur naval high stress nature limited opportunities real life make ideal target ai enabled educational technologies tutoring systems dialogue developed student immersive multimedia environment dc train scenarios simulate mixture physical phenomena personnel issues current restricted particular available version future versions plan support critiques modeled eliciting self explanation shown highly effective method reason number currently nlp techniques engage notable medical circsim tutor basic electronics literacy shares features knowledge base encodes relevant supporting intelligent feedback structure called expert session summary summaries encode causal relationships
924	work presented paper concerns information retrieval geographical documents major geographic component final aim response informational query user return ranked list relevant passages selected allowing text browsing consider spatial texts queries idea perform line linguistic analysis document extracting expressions point complex simple place names present analyser recognises performing semantic computing symbolic representations content stored thanks xml annotation act indexes compared matching process needing kinds numeric computations prospective outline described presentation project passage extraction let precise mainly interested human geography phenomena consideration social economic nature massively produced consumed state organisations marketing services private companies set available collection speak anchored space characteristic immediately visible
925	languages word boundary delimiters dictionaries needed segmenting running texts figure makes segmentation accuracy depend significantly quality dictionary analysis sufficiently lead great number unknown unrecognized words certainly reduce solve problem propose method based decision tree models specific information called syntactic attribute applied identify structure thai tool purpose using corpus experiment results outperforms known dependent techniques maximum longest matching methods case keywords trees researches suffer introduce particular process handle preliminary extracted pre segmented form randomly deleted modified result shown percentages different explored drops respectively percentage continuously reflects
926	present minimally supervised methods training testing geographic disambiguation systems train data driven place classifiers using toponyms disambiguated text existing cues ma test texts stripped hand tagged historical experiment english language corpora varying complexity personal narratives th century american west records war accuracy ranges news collections sites unless importance world capital offer principal advantages bootstrapping applications journalistic style prefers identifying persons title first mention names major cities mentioned followed state province country toponym strictly unambiguous labelled provide reader backoff recognition named author maryland doesn recognize situate rough area case goal generalize kinds contexts writers disambiguating label stories tend relatively focused single topic exploit heuristic sense discourse indicated different subsequent mentions story identified
927	paper ontology based text categorization domain ontologies automatically acquired morphological rules statistical methods approach promising way general information retrieval applications knowledge management discovery evaluate quality test method experiments manual editing results satisfactory furthermore developed automatic introduction consisting important concepts relationships useful variety evaluating straightforward reusing practical tool ability categorize news clips traditional ir keyword distribution form training corpus assign testing document using keywords set guarantee authors different believe events categorized previous works shows latent semantic index gram chinese indices lsi grams meaningful semantically implicit understood computers humans exceptions personalization possible reuse identify concept structure sentences
928	paper presents implementation vietnamese generation module multilingual machine translation based government binding theory despite designed generic mechanisms turned task generating posed non trivial problems deviate code make new design important cases developing corresponding bilingual lexicons obtained prototypes french english mt first known prototype kind experience suggests principle parameterized modules contain language specific lexicalized properties attention flexible facilitate integration implementations minor success know similar developed analyse technologie du university geneva construct obtain different european languages poses present main solutions construction noun phrases verb adverbial relative clauses brief description introduction spoken millions people world work translate vice versa german italian
929	paper presents model multiword expression decomposability based latent semantic analysis determine similarity constituent words claim higher similarities indicate greater test english noun compounds verb particles evaluate correlation hyponymy values wordnet mean partitions data ranked evidence calculated correlated relational content introduction concerned empirical expressions defined cohesive lexemes cross word boundaries occur wide variety syntactic configurations different languages description degree semantics mwe parts commonly discussed compositionality coerced idiosyncratic interpretations attain alignment way idiom illustrates process spill beans reveal decomposed interpretation given senses readily available simplex level context particular talk composing form ideally able differentiate classes mwes
930	paper briefly informally illustrate using annotated static dynamic knowledge resources ontological semantics present main motivations desiderata approach discuss issues related making semantic applications feasible judicious stepwise enhancement sources times maintaining working introduction discusses selected implemented computational theory deals extraction representation meaning natural language texts unlike practically work os makes responsible necessary components stages automatic text analysis addresses lexical compositional pragmatics discourse processing heuristics derived syntax morphology preprocessing non incorporated detailed underlying world models include specifications basic events objects properties complex scripts goal manipulation view supporting mt question answering represented representations compositionally primarily meanings words phrases word phrase encoded lexicon ontology metalanguage specification result largely consist instances concepts stored fact repository fr base facts referred proper names personal toponyms organizations specific artifacts
931	results study demonstrate numerous object specific restrictions projective prepositions english russian predicted interactional semantic properties independent perceptual seemingly guide expressions presupposed based findings suggested addition basic geometrical specification representation contain functional information computational procedure matching expression spatial scene include detection determined retrieval objects determining functionally relevant introduction number models semantics developed aim generate references meaning represented terms geometric constructs shapes center mass distance overlapping able appropriately match novel arrangement great disparity real world scenes refer presents problem approach virtually situation usage particular consider preposition mathematical notion inclusion placed described physical boundaries relation lexical entry comment
932	bottleneck development trainable text summarization systems shortage training data constructing tedious task especially general different correct ways summarize fortunately utilize internet source suitable paper present web procedure involves structuring articles downloaded various websites building adequate corpora pairs positive negative automatically learning perform extraction based level comparable best duc introduction sentences make direct comparison algorithms introduced generate expanded inputs explosion world wide accessible billions documents newspaper forms longer build large sets time retrieve texts topic directly news published exception ideally organized orientation temporal nature makes possible impose organization obtain corpus hypothesize weekly sophisticated summaries daily ones shown figure hypothesis accurate extract summarizer train first section formulation evaluation finally future work
933	evaluate empirically scheme combining classifiers known stacked generalization context anti spam filtering novel cost sensitive application text categorization unsolicited commercial email causing frustration bandwidth exposing unsuitable content using public corpus stacking improve efficiency automatically induced filters applications introduction paper presents empirical evaluation increasing popularity low direct thousands users messages advertising rich schemes formally mail extremely annoying connections expose legal simplistic technical keyword based limited effect success machine learning techniques led alternative approaches classifier capable distinguishing non legitimate manually categorized collection identify incoming initial results promising experiments systematic exploiting introduced benchmark corpora measures approach constructing ensembles ensemble committee set individual decisions combined way classify new instances combines multiple induce higher level improved performance thought
934	paper presents new chart parsing algorithm prolog compilation procedure reduces copying run time constant number edge applications unification based grammars large partially ordered categories expensive facilitate sophisticated indexing strategies retrieving cost provides perspective quick checking related heuristics confirm forcing early failure fact best approach preliminary empirical evaluation performance provided introduction addresses edges memoization paths parsers phrasestructure great advances probabilistic methods years probable parses string relative grammar widely development means verifying accuracy syntactically precise given corpus test suite classical context free category information copied normally small size feature structure highly lexicalized considerably popular advent standard algorithms significant ale attempts reduce using carpenter breadth first right left matches rule daughters depth driven loop eliminates need active keeps sizes stack copies candidate efficient phrase
935	propose method generate large scale encyclopedic knowledge valuable nlp research based web first search pages containing term question linguistic patterns html structures extract text fragments describing finally organize extracted descriptions word senses domains addition apply automatically generated encyclopedia answering targeting japanese engineers examination ishikawa university library information science tsukuba japan ac jp introduction reflecting growth utilization world wide number language processing methods proposed natural retrieval artificial intelligence communities sample includes resources retrieve useful response user queries discover latent paper mainly point view explore produce specifically enhance extracts brief searches expressions layouts model discard non clustering divide specific groups hand expected existing encyclopedias vocabulary size relatively limited quantity problems resolved comparable ones terms quality crafted carefully organized
936	sentence maximizes according bayes rule different decoder needed choices lm tm ple probability tables parameterized models conduct search space defined ibm pioneering paper decoding algorithm based left right described introduced syntax utilized syntactic structure channel input showed outperform model alignment quality contrast word works parse tree builds english given foreign language describes reports experimental results statistical machine translation systems produce mechanisms generate languages time obtained parsing mathematically motivated decompose unlike noisy section briefly reviews phrasal extension presents basic idea cope huge assumes applies kinds stochastic operations node reordering children nodes inserting optional extra
937	first section paper headlines captions based observations authors developed approach summarization called selective analysis mimics human abstractors routine components indicative selection informative generation final article issue distinct articles addresses problems speech text sentence extraction determine content summary given informal nature number significant steps order identify useful segments develops techniques removing disfluencies identifying units sense equivalent sentences relations questionanswer turns separate extracted preprocessing yields transcript standard operate successfully abstractive remains researcher success extractive summarizers rapid development similar effectiveness research community address new workable solutions references allan james temporal summaries news topics proceedings th annual international acm conference information retrieval pages aone mary trainable summarizer knowledge acquired robust nlp mani maybury editors advances automatic mit press cambridge barzilay michael elhadad computational linguistics volume
938	parallel corpus texts english inuktitut language presented hansards processed phases sentence alignment phase word correspondence technique achieves precision recall aimed providing coverage collection reliable pairs morphemes dictionary expansion agglutinative entails considering substrings simply words employ pointwise mutual information method attain approaches multiple substring correspondences resulting greater introduction present aligned level follow techniques described literature augmentations suggested specific properties pair lack lexical resources languages fact different script richness morphology guided choice sentences using length based dynamic programming approach gale church enhanced small number non alphabetic anchors identified goal finding extensive high quality candidate glossary crucially algorithm considers consists available public electronic form
939	manually verified pitch data compared output commonly algorithm manual statistically significantly better final rise predictions automatic spite great similarity sets measurements tracking doubling errors described introduction ally captured pros information relevant speech recognition synthesis regarded highly respect study presents comparison hand paper defined perceived loosely correlates fundamental frequency section waveform organization follows first corpus justified describes comparisons corrected results presented detection utterance falls lastly future work connects conclusions specific related perception discourse applications benefit kind description dialogs trains heeman allen concern handle occasional events appears signal readily human listener addresses issue special constraints dynamic programming figure illustrates difficulties making terms plots annotated track
940	method generating sentences keywords headwords consists main parts candidate text construction evaluation generates form dependency trees using complementary information replace missing knowledge gap function words generate natural based particular monolingual corpus model appropriate given considers word gram furthermore string morphological introduction generation important technique applications machine translation summarization human dialogue recent years corpora available surface language estimation statistical source translated target maximizes probability selected represented input bag goal basically reorder point assumption generated merely reordering complete set needs large number bilingual automatically complement needed collect required
941	help developing localization oriented ebmt automatic machine translation evaluation method implemented adopts edit distance cosine correlation dice coefficient criteria experiment shows distinguishes translations ones prove consistent human mt systems scored compared theoretical analysis validate experimental results significance tests level ensure reliability linear regression equations calculated map scoring introduction key problem various methods exist answer questions tell better manual time consuming inconsistent broadly studied using different heuristics jones linguistic information balance parse trees grams semantic occurrence indicators quality compares rankings measures decide involve word frequency pos tagging distribution text features type involves comparison result proposed way based output japanese sentences original sentence identification correctness modification syntactic dependency evaluates measuring similarity candidates parallel corpus multiple distances automatically rank path
942	build robots engage fluid spoken conversations people moving canned responses words actually understanding step addressing question introduce robotic architecture provides basis grounding word meanings perceptual procedural representations line simulator enables shift points view held rich set data structures procedures provide foundations meaning certain classes introduction language talk world past present future real robot ground mediated motor cognitive capacities refer entities grounded sensory associations instance ball includes encode look predictive models behave representation touch include perform action encodings recognize serve labels concepts uttered underlying concept communicated speaker listener maintain similar basic approach underlies work building machines terms concrete situations fact simplest everyday objects events relations run problems consider person table engaged coordinated activity involving manipulation
943	standard pipeline approach semantic processing sentences morphologically syntactically resolved single tree interpreted poor fit applications natural language interfaces environment information form objects events application runtime inform parsing decisions unless input sentence semantically analyzed occur architecture paper describes computational properties alternative analysis performed possible interpretations polynomial time introduction shallow comparing argument structures search patterns filling simple templates achieve respectable results using semantics putting disambiguation ahead evaluation reasonable primarily run content newspaper text dictated speech machine readable contextual readily available provide guidance large ob jects assuming current statistical technique accurate benefit kind based important interface efficiently
944	examine principle underlies current algorithms generation referring expressions investigate extent allows generalized discussion focusses complex boolean descriptions sentence aggregation logic gre key question regarding foundations natural language problem logical form equivalence goes follows nlg systems semantic input formulated governed rules determining count equivalent ideally program ways proper relation appelt argued classical candidate cally argument word formulas differently shieber suggested sophisticated notion needed fewer tic present paper different response explored keeps prevents generator distinguishing inputs logically pragmatic constraints determine words programme called oriented constitute fairly radical departure practice applied power related work main aim modest standard connection specifically semantics guided surprisingly
945	present engine text games player interacts using natural language employs current methods computational linguistics efficient inference description logic make interaction especially useful linguistic modules dealing reference resolution generation rank different readings case referential syntactic ambiguities turns utterances naturally restricted game scenario simplifies processing task introduction dialogue texts world evolves manipulate objects typing commands fig shows sample popular commercially successful eighties gone fashion parsers limited forced user forms attempts overcome limitations input output state art based represent dynamic knows dl prover parsing surface realization supports inferences need particular referring expressions keeping track knowledge separate bases evaluate definite descriptions respect
946	approach knowledge representation multi modal domain dialogue smartkom presented focus ontological representational issues choices helping construct ontology shared multiple components different projects applied various tasks finally highlighting usefulness given section introduce formats pertinent followed description discuss modeling principles underlying presents ways common employed concluding remarks formalism brief outline following efforts originating semantic web brought standards resource framework darpa agent mark language interchange discourse represented encoded using xml based languages oil daml work reported defined syntax detailed characterization formal properties fact reasoning engine ontologies providing automated capabilities class consistency subsumption checking graphical engineering ends visualization tools available editing maintaining visualizing semantics logic extended concrete employs combination frame
947	parsing algorithm unification grammars extension earley context free feature structures paper certain conditions shieber produces nonminimal derivation parse tree contains additional features licensing productions definition allows derivations claim viewed invalid sources problem propose precise minimal modification ensures minimality computational cost introduction grammar term family based formalisms including gpsg patr dcg hpsg effort formalize common elements style developed logic describing define abstract set operations modified unintended spurious parses addition intended ones contain extra license basis operation union preserves correct produce undesirable practice given tell particular model unless reconstruct despite
948	present named entity recognition classification probabilistic character level features classifications multiple orthographic tries combined hidden markov model framework incorporate internal contextual evidence perform preprocessing stage capitalisation restored sentence initial caps words high accuracy report values english german datasets using introduction language independent ner requires development metalinguistic sufficiently broad accommodate languages trained exploit specific target aim paper investigate combination local affix information word classify independently relies determine correct state sequence discriminator misleading text choose makes assumptions scheme set solve problem case novel way removing effects results simpler easier entities remaining strongly efficient data structure capturing statistical differences strings different categories trie path root nodes represents string th node stores occurrences
949	minimal recursion semantics standard formalism large scale hpsg grammars model underspecified present first provably efficient algorithm enumerate readings mrs structures translating normal dominance constraints introduction past years considerable activity development formalisms common idea delay enumeration possible instead work compact representation enumerated need semantic underspecification despite clear relevance obvious questions efficiently published existing implementations practical problem reading npcomplete precise relationship differences distinguish sublanguages nets translation answers question constraint solvers low polynomial time second restricted pure scope shows equivalence fragment corresponding turn equivalent proven additional treatments ellipsis reinterpretation available extensions results subject new proof technique reduces reasoning
950	paper presents study optimizing sentence pair alignment scores bilingual module candidate based perplexity length introduced tested linear regression model candidates proposed trained predict pairs quality human subjects experiments carried data automatically collected internet correlation generated range inter subject agreement score correlations pearson ranges introduction instances multilingual natural language systems machine translation developed parallel corpora faced different unseen text genre performance drops way remedy situation adapt retrain parameters source closely related program crucial adaptation procedure collects document identifies high likelihood correct translations set identified added training parameter reestimation known mined noisy careful html parsing filtering size comparable page contains mismatches content non order aligned large mismatch vocabulary extracted contain number low
951	apply support vector machines identify english base phrases svms known achieve high generalization performance input data dimensional feature spaces furthermore kernel principle carry training smaller computational overhead independent dimensionality weighted voting systems trained distinct chunk representations experimental results approach achieves higher accuracy previous approaches introduction th sample represented class negative label number given second classifying chunks grammatical classes various nlp tasks seen chunking task include noun phrase identification japanese named entity extraction tokenization speech tagging regarded assume character token machine learning techniques applied formulated estimating identifying function information available surrounding context proposed conventional hidden markov model maximum entropy normally require careful selection order provide method automatic sets heuristics selecting effective features combinations new statistical boosting strategy maximizes margin critical samples separating hyperplane particular
952	context nlp systems indicator term syntactic semantic function accuracy dependent quality quantity contextual information available variable longer fixed limited corpus resources given training time computational makes sense invest extracting high effectively text extraction rate representation size need considered thesaurus range tools demonstrate interaction million words introduction plays important role natural language tasks speech taggers word disambiguation depends extract data predicting instance immediately preceding likely previous similar observations pos chunkers crucial lies defining contexts accurate correlated trying determined phenomenon reliable limiting factor people typically worked corpora feasible build larger document collections
953	introduction spoken dialogue systems correctly understand user intentions achieve certain tasks users state appropriately updated utterance means information possesses concerning includes intention recognition results history forth obtaining content using single called speech understanding updating based previous current discourse general result ambiguous currently uniquely decide candidates available syntactic semantic analysis process normally produce multiple hypotheses able determine order respond choose appropriate referring conventional states created corresponding leads ambiguity ignored dis paper concerns enables utterances context obtained
954	ambiguity fundamental property natural language case manifests syntactic level analysis order face high number obtained derivation trees paper describes techniques evaluation figures merit define sort parsing presented methods based specific features languages improve results simple stochastic approaches introduction figure dependence resulting words input sentence rich morphology word forms grammatical unambiguously determined traditional solution problems probabilistic aiming finding probable parse given methodology relative frequencies occurrences possible relations representative corpus best judged term refer function implausible partial analyses measure probabilities complete parses levels representation inherent central problem consequence outputs parser represented labeled average strongly depends background grammar grammars producing hundreds thousands highly ambiguous systems enormous
955	existing studies weighted context free transduction reasonable quality effectively learned paper investigates approximation means rational advantage increased processing speed benefits realtime applications involving spoken language order languages selection appropriate lexical items furthermore limited domains automatic learning transductions reasonably successful practical algorithms computing likely derivation cubic time complexity terms length input string case graph output speech recognizer number nodes certain lexicalized models obtain higher complexities size grammar considered parameter pose problems especially real systems investigated finite state machinery implementing kind general allows faster easily robustness hope approximating model able preserve accuracy section discuss preliminary definitions adapted literature making small changes presentation explain grammars represented ordinary plus phase postprocessing discussed shown process robust way ensuring discusses empirical results end conclusions introduction partly
956	approach tagging monolingual dictionary linguistic features particular annotate entries parts speech number tense information algorithm bilingual corpus statistical lexicon candidate training specific feature values similarity measure space defined data serves define classifier unseen report evaluation results french general applied language pair step proposed framework assign roles extracted morphemes noun plural markers using present simple doing emphasis power ultimately indispensable tasks machine translation similar accuracy studying empirical approaches output resulting systems calls incorporation intuition knowledge notable context introduce syntactic model goes direction avenue infers transfer rules ones human grammar writer produce text learning facilitated usage focus primarily resource rich situations pairs languages resources parser available scope paper rule interested reader refer
